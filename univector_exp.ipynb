{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLBG-xQe59FC",
        "outputId": "5171e5ed-01ae-4589-e21b-d4b87b8feade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segment_anything\n",
        "!pip install datasets\n",
        "!pip install openai\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install pytrec_eval\n",
        "!pip install elasticsearch\n",
        "!pip install tensorflow_text\n",
        "!pip uninstall keras -y\n",
        "!pip install tensorflow\n",
        "!pip install --upgrade tensorflow tensorflow-hub\n",
        "# Uninstall existing packages\n",
        "!pip uninstall -y tensorflow tensorflow-text\n",
        "\n",
        "# Install specific compatible versions\n",
        "!pip install tensorflow==2.9.1 tensorflow-text==2.9.0\n",
        "!pip install transformers\n",
        "!pip install beir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F3aC2kgG6CGd",
        "outputId": "c8a0a54f-69d0-4f9a-b314-18d8b42cd5eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segment_anything\n",
            "  Downloading segment_anything-1.0-py3-none-any.whl.metadata (487 bytes)\n",
            "Downloading segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.48.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.48.0-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.48.0\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.1.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n",
            "Collecting pytrec_eval\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytrec_eval\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308202 sha256=4e82ffe2222f340ab851feabb656d684205116d921e0df73332a622bf3488a50\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "Successfully built pytrec_eval\n",
            "Installing collected packages: pytrec_eval\n",
            "Successfully installed pytrec_eval-0.5\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.15.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.15.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.8.30)\n",
            "Downloading elasticsearch-8.15.1-py3-none-any.whl (524 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.6/524.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elastic_transport-8.15.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.15.0 elasticsearch-8.15.1\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow_text) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow_text) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow_text) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow_text) (0.1.2)\n",
            "Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.17.0\n",
            "Found existing installation: keras 3.4.1\n",
            "Uninstalling keras-3.4.1:\n",
            "  Successfully uninstalled keras-3.4.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "Successfully installed keras-3.5.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Found existing installation: tensorflow 2.17.0\n",
            "Uninstalling tensorflow-2.17.0:\n",
            "  Successfully uninstalled tensorflow-2.17.0\n",
            "Found existing installation: tensorflow-text 2.17.0\n",
            "Uninstalling tensorflow-text-2.17.0:\n",
            "  Successfully uninstalled tensorflow-text-2.17.0\n",
            "Collecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting tensorflow-text==2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.11.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (24.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.9.0) (0.16.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.8.0->tensorflow-text==2.9.0) (2.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.8.0->tensorflow-text==2.9.0)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n",
            "Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tf-keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.67.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.26.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.23.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-text-2.9.0 tf-keras-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "122cb5ddd34d4a2b83af46959c24c1f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting beir\n",
            "  Downloading beir-2.0.0.tar.gz (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from beir) (3.1.1)\n",
            "Requirement already satisfied: pytrec_eval in /usr/local/lib/python3.10/dist-packages (from beir) (0.5)\n",
            "Requirement already satisfied: faiss_cpu in /usr/local/lib/python3.10/dist-packages (from beir) (1.8.0.post1)\n",
            "Collecting elasticsearch==7.9.1 (from beir)\n",
            "  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from beir) (3.0.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->beir) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (6.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets->beir) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->beir) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->beir) (3.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->beir) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->beir) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->beir) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers->beir) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers->beir) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers->beir) (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->beir) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->beir) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers->beir) (1.3.0)\n",
            "Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: beir\n",
            "  Building wheel for beir (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for beir: filename=beir-2.0.0-py3-none-any.whl size=63549 sha256=238622cc1033ab2427295c298873414f69a2aaaddb02d16760f2344ad6419cdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/14/96/c606ede3c10e9300ef771a6183af09d389459195ff5f854862\n",
            "Successfully built beir\n",
            "Installing collected packages: elasticsearch, beir\n",
            "  Attempting uninstall: elasticsearch\n",
            "    Found existing installation: elasticsearch 8.15.1\n",
            "    Uninstalling elasticsearch-8.15.1:\n",
            "      Successfully uninstalled elasticsearch-8.15.1\n",
            "Successfully installed beir-2.0.0 elasticsearch-7.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRpJJk-S9K_l",
        "outputId": "7dbd4e1a-c042-4e77-bcd0-8c8185e48825"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NtUP9-19Nw4",
        "outputId": "39ba2f60-56b6-4d48-b172-a0fd46a53433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llm2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehcLsmMG9Vl-",
        "outputId": "4eeb8dde-5af7-43f3-e21c-0c9ecb6c9b1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llm2vec in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llm2vec) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from llm2vec) (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from llm2vec) (2.4.1+cu121)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from llm2vec) (0.13.0)\n",
            "Requirement already satisfied: transformers<=4.40.2,>=4.39.1 in /usr/local/lib/python3.10/dist-packages (from llm2vec) (4.40.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from llm2vec) (3.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from llm2vec) (0.4.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from llm2vec) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (0.4.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->llm2vec) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (3.10.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->llm2vec) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft->llm2vec) (0.34.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->llm2vec) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->llm2vec) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->llm2vec) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->llm2vec) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->llm2vec) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->llm2vec) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->llm2vec) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->llm2vec) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->llm2vec) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLGqVPKG9q4J",
        "outputId": "182bc281-6975-4c3e-da56-554961fba90e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (11.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/concept_based_retrieval-main-univector/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be_ArCuV-BC8",
        "outputId": "6e00047a-ad32-4d30-f868-2e1d3a9c6c0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/concept_based_retrieval-main-univector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd raptor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXfGoVx1-MPB",
        "outputId": "a15a8473-3623-4a8d-824d-71a51115444d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/concept_based_retrieval-main-univector/raptor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AB9VlbWAM9n",
        "outputId": "e3fbc36e-25e7-4613-90d1-3530982fa455"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.8.0.post1)\n",
            "Collecting numpy==1.26.3 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.3.3 (from -r requirements.txt (line 3))\n",
            "  Downloading openai-1.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.2)\n",
            "Collecting sentence-transformers==2.2.2 (from -r requirements.txt (line 5))\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tenacity==8.2.3 (from -r requirements.txt (line 6))\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting tiktoken==0.5.1 (from -r requirements.txt (line 7))\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.4.1+cu121)\n",
            "Collecting transformers==4.38.1 (from -r requirements.txt (line 9))\n",
            "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn==0.5.5 (from -r requirements.txt (line 10))\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3==1.26.6 (from -r requirements.txt (line 11))\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.3->-r requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.3->-r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.3->-r requirements.txt (line 3)) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.3->-r requirements.txt (line 3)) (2.9.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.3->-r requirements.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.3->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 5)) (0.19.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 5)) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 5)) (0.24.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1->-r requirements.txt (line 7)) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.1->-r requirements.txt (line 9)) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.1->-r requirements.txt (line 9)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.1->-r requirements.txt (line 9)) (6.0.2)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.1->-r requirements.txt (line 9))\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.1->-r requirements.txt (line 9)) (0.4.5)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.5->-r requirements.txt (line 10)) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn==0.5.5->-r requirements.txt (line 10))\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (2024.6.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.3->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.3->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.3->-r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.3->-r requirements.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.3->-r requirements.txt (line 3)) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.3->-r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn==0.5.5->-r requirements.txt (line 10)) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.3.3->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.3.3->-r requirements.txt (line 3)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1->-r requirements.txt (line 7)) (3.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2->-r requirements.txt (line 5)) (10.4.0)\n",
            "Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.3.3-py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sentence-transformers, umap-learn\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=94f278ddee09ba3c302ed2cee44510e0622b98a6024785e4502ba95d21560891\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86834 sha256=353177389715e27dd0bc46beb7708b4532dbacba171696ab7773ef2342c8a327\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "Successfully built sentence-transformers umap-learn\n",
            "Installing collected packages: urllib3, tenacity, numpy, tiktoken, openai, tokenizers, pynndescent, umap-learn, transformers, sentence-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.7.0\n",
            "    Uninstalling tiktoken-0.7.0:\n",
            "      Successfully uninstalled tiktoken-0.7.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.48.0\n",
            "    Uninstalling openai-1.48.0:\n",
            "      Successfully uninstalled openai-1.48.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.1.1\n",
            "    Uninstalling sentence-transformers-3.1.1:\n",
            "      Successfully uninstalled sentence-transformers-3.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "llm2vec 0.2.2 requires transformers<=4.40.2,>=4.39.1, but you have transformers 4.38.1 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.3 openai-1.3.3 pynndescent-0.5.13 sentence-transformers-2.2.2 tenacity-8.2.3 tiktoken-0.5.1 tokenizers-0.15.2 transformers-4.38.1 umap-learn-0.5.5 urllib3-1.26.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pduFA_7TARXM",
        "outputId": "2380b263-e458-40f9-dea3-7785a0f77cf2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-probability==0.17.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tUJsRiqAjIG",
        "outputId": "a15b7390-82e9-4b0c-ae09-0fd40baf35e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-probability==0.17.0\n",
            "  Downloading tensorflow_probability-0.17.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (1.26.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.17.0) (0.1.8)\n",
            "Downloading tensorflow_probability-0.17.0-py2.py3-none-any.whl (6.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/6.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/6.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-probability\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.24.0\n",
            "    Uninstalling tensorflow-probability-0.24.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.24.0\n",
            "Successfully installed tensorflow-probability-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "print(\"Zipping main image files\")\n",
        "zip_file_path = '/content/drive/MyDrive/flickr30k-images.zip'\n",
        "extract_dir = '/content/unzipped_images_fixed/flickr'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_dir)\n",
        "print(\"Finished zipping main image files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H4_CI9S6e9I",
        "outputId": "1606c441-3617-4267-f088-eb42a6516b0d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipping main image files\n",
            "Finished zipping main image files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the name of your file\n",
        "df_30k = pd.read_csv('/content/drive/MyDrive/flickr/flickr_annotations_30k.csv')\n",
        "\n",
        "# Display the dataframe\n",
        "df_30k.head()  # To show the first few rows of the dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "hI6E6307boQW",
        "outputId": "38255892-2d44-4031-9eb1-078612f6ae5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 raw               sentids  \\\n",
              "0  [\"Two young guys with shaggy hair look at thei...       [0, 1, 2, 3, 4]   \n",
              "1  [\"Several men in hard hats are operating a gia...       [5, 6, 7, 8, 9]   \n",
              "2  [\"A child in a pink dress is climbing up a set...  [10, 11, 12, 13, 14]   \n",
              "3  [\"Someone in a blue shirt and hat is standing ...  [15, 16, 17, 18, 19]   \n",
              "4  [\"Two men, one in a gray shirt, one in a black...  [20, 21, 22, 23, 24]   \n",
              "\n",
              "   split        filename  img_id  \n",
              "0  train  1000092795.jpg       0  \n",
              "1  train    10002456.jpg       1  \n",
              "2  train  1000268201.jpg       2  \n",
              "3  train  1000344755.jpg       3  \n",
              "4  train  1000366164.jpg       4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5367b4a-9efc-4f79-8e73-f9433bc8f640\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw</th>\n",
              "      <th>sentids</th>\n",
              "      <th>split</th>\n",
              "      <th>filename</th>\n",
              "      <th>img_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[\"Two young guys with shaggy hair look at thei...</td>\n",
              "      <td>[0, 1, 2, 3, 4]</td>\n",
              "      <td>train</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[\"Several men in hard hats are operating a gia...</td>\n",
              "      <td>[5, 6, 7, 8, 9]</td>\n",
              "      <td>train</td>\n",
              "      <td>10002456.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[\"A child in a pink dress is climbing up a set...</td>\n",
              "      <td>[10, 11, 12, 13, 14]</td>\n",
              "      <td>train</td>\n",
              "      <td>1000268201.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\"Someone in a blue shirt and hat is standing ...</td>\n",
              "      <td>[15, 16, 17, 18, 19]</td>\n",
              "      <td>train</td>\n",
              "      <td>1000344755.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[\"Two men, one in a gray shirt, one in a black...</td>\n",
              "      <td>[20, 21, 22, 23, 24]</td>\n",
              "      <td>train</td>\n",
              "      <td>1000366164.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5367b4a-9efc-4f79-8e73-f9433bc8f640')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5367b4a-9efc-4f79-8e73-f9433bc8f640 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5367b4a-9efc-4f79-8e73-f9433bc8f640');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acf779ab-0039-408c-966a-f9792ebab8bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acf779ab-0039-408c-966a-f9792ebab8bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acf779ab-0039-408c-966a-f9792ebab8bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_30k",
              "summary": "{\n  \"name\": \"df_30k\",\n  \"rows\": 31014,\n  \"fields\": [\n    {\n      \"column\": \"raw\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31014,\n        \"samples\": [\n          \"[\\\"A man in black leather pants is holding something in his hand over the water, while standing on a bridge.\\\", \\\"A man standing in front of a gate wearing black pants and a red shirt.\\\", \\\"An African American man is standing on a bridge wearing a pink shirt.\\\", \\\"The man wearing the red shirt is looking over the walkway.\\\", \\\"A man on a bridge holds a blue object over the rail.\\\"]\",\n          \"[\\\"The man in the plaid shorts is building a large sand sculpture while two other men buried in sand are looking on from beneath a blue umbrella.\\\", \\\"A man wearing shorts but no shirt works on a sand sculpture at the beach while two people buried in the sand watch underneath a blue umbrella.\\\", \\\"A shirtless man is working on a sand sculpture on a beach full of people.\\\", \\\"A tan man working on a sand castle on the beach.\\\", \\\"A guy with long hair is making a sand sculpture\\\"]\",\n          \"[\\\"A man in a dark, long-sleeved shirt is playing a wooden flute, while under the crook of his left arm is a large pole, at the top of which are dozens of flutes that are similar to the one he is playing, fanned out above his head like a flower.\\\", \\\"A man wearing a button-up shirt plays a flute while carrying a bottle and a large stick with many flutes on one end.\\\", \\\"A colorful arrangement of flutes and novelties sit atop a vendors display pole as he demonstrates his product.\\\", \\\"A man is playing a recorder while he holds a carrier containing many more of the same instrument.\\\", \\\"A man with a bouquet of recorders is playing one of them.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31014,\n        \"samples\": [\n          \"[110650, 110651, 110652, 110653, 110654]\",\n          \"[78155, 78156, 78157, 78158, 78159]\",\n          \"[88105, 88106, 88107, 88108, 88109]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"test\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31014,\n        \"samples\": [\n          \"4733768667.jpg\",\n          \"3669472958.jpg\",\n          \"4068478227.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8953,\n        \"min\": 0,\n        \"max\": 31013,\n        \"num_unique_values\": 31014,\n        \"samples\": [\n          22130,\n          15631,\n          17621\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_30k.iloc[2]['raw'].split('\", \"')[0][2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9kUB351xb-w8",
        "outputId": "0bad5ba8-7bb5-43a7-d452-7695f8c5967d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A child in a pink dress is climbing up a set of stairs in an entry way.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the name of your file\n",
        "df_500 = pd.read_csv('/content/drive/MyDrive/flickr_500_choose.csv')\n",
        "\n",
        "# Display the dataframe\n",
        "df_500.head()  # To show the first few rows of the dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "GVcLO2xEbgMb",
        "outputId": "e56b9a7c-4b34-47cd-c62d-274eab275c6d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              choose  \\\n",
              "0  Two young guys with shaggy hair look at their ...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2  Two men, one in a gray shirt, one in a black s...   \n",
              "3  Two men in Germany jumping over a rail at the ...   \n",
              "4  Five ballet dancers caught mid jump in a danci...   \n",
              "\n",
              "                                                 raw               sentids  \\\n",
              "0  [\"Two young guys with shaggy hair look at thei...       [0, 1, 2, 3, 4]   \n",
              "1  [\"Several men in hard hats are operating a gia...       [5, 6, 7, 8, 9]   \n",
              "2  [\"Two men, one in a gray shirt, one in a black...  [20, 21, 22, 23, 24]   \n",
              "3  [\"Two men in Germany jumping over a rail at th...  [45, 46, 47, 48, 49]   \n",
              "4  [\"Five ballet dancers caught mid jump in a dan...  [50, 51, 52, 53, 54]   \n",
              "\n",
              "   split        filename  img_id  \n",
              "0  train  1000092795.jpg       0  \n",
              "1  train    10002456.jpg       1  \n",
              "2  train  1000366164.jpg       4  \n",
              "3  train  1001545525.jpg       9  \n",
              "4  train  1001573224.jpg      10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d78ba08d-b289-4fe4-a2e3-35e86017167b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>choose</th>\n",
              "      <th>raw</th>\n",
              "      <th>sentids</th>\n",
              "      <th>split</th>\n",
              "      <th>filename</th>\n",
              "      <th>img_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young guys with shaggy hair look at their ...</td>\n",
              "      <td>[\"Two young guys with shaggy hair look at thei...</td>\n",
              "      <td>[0, 1, 2, 3, 4]</td>\n",
              "      <td>train</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>[\"Several men in hard hats are operating a gia...</td>\n",
              "      <td>[5, 6, 7, 8, 9]</td>\n",
              "      <td>train</td>\n",
              "      <td>10002456.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Two men, one in a gray shirt, one in a black s...</td>\n",
              "      <td>[\"Two men, one in a gray shirt, one in a black...</td>\n",
              "      <td>[20, 21, 22, 23, 24]</td>\n",
              "      <td>train</td>\n",
              "      <td>1000366164.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two men in Germany jumping over a rail at the ...</td>\n",
              "      <td>[\"Two men in Germany jumping over a rail at th...</td>\n",
              "      <td>[45, 46, 47, 48, 49]</td>\n",
              "      <td>train</td>\n",
              "      <td>1001545525.jpg</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Five ballet dancers caught mid jump in a danci...</td>\n",
              "      <td>[\"Five ballet dancers caught mid jump in a dan...</td>\n",
              "      <td>[50, 51, 52, 53, 54]</td>\n",
              "      <td>train</td>\n",
              "      <td>1001573224.jpg</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d78ba08d-b289-4fe4-a2e3-35e86017167b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d78ba08d-b289-4fe4-a2e3-35e86017167b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d78ba08d-b289-4fe4-a2e3-35e86017167b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75c79ef1-0bc6-46c3-a360-dcf43ec55b1b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75c79ef1-0bc6-46c3-a360-dcf43ec55b1b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75c79ef1-0bc6-46c3-a360-dcf43ec55b1b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_500",
              "summary": "{\n  \"name\": \"df_500\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"choose\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"A group of people, some of whom are standing and using chopsticks, surround a table which is laden with plates of food.\",\n          \"Two buildings beyond a concrete wall facing a walkway with a woman talking on a cellphone.\",\n          \"Two men, one in blue and one in brown, are sitting on a boat.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"[\\\"A group of people, some of whom are standing and using chopsticks, surround a table which is laden with plates of food.\\\", \\\"A group of young people are standing and sitting around a table eating and drinking with one another.\\\", \\\"A group of young people dressed in mostly black are around a table getting ready to eat.\\\", \\\"Eleven people of both genders are either sitting or standing at a table eating food\\\", \\\"People are standing and sitting around a table and eating.\\\"]\",\n          \"[\\\"Two buildings beyond a concrete wall facing a walkway with a woman talking on a cellphone.\\\", \\\"A girl in a red winter coat walks down the city sidewalk as she speaks on the phone.\\\", \\\"Two modern buildings made of glass and stone accent the setting.\\\", \\\"A woman is walking at dusk down an urban street.\\\", \\\"Someone walking along a wall.\\\"]\",\n          \"[\\\"Two men, one in blue and one in brown, are sitting on a boat.\\\", \\\"An elderly man in a blue jacket sits with others on a boat.\\\", \\\"Three people are having a conversation on a white boat.\\\", \\\"Two men sit next to each other on the water in a boat.\\\", \\\"Three men sitting in a boat\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"[7465, 7466, 7467, 7468, 7469]\",\n          \"[1430, 1431, 1432, 1433, 1434]\",\n          \"[7850, 7851, 7852, 7853, 7854]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"test\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"1434147314.jpg\",\n          \"109770830.jpg\",\n          \"145424240.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 608,\n        \"min\": 0,\n        \"max\": 2067,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          1493,\n          286,\n          1570\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_indices = df_500['img_id'].tolist()"
      ],
      "metadata": {
        "id": "J6vJFbO_cZlU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(selected_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azlXOLDNcn34",
        "outputId": "df12c7eb-a0cb-4f68-c35e-9368626ba0de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2067"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_30k.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "_TA8VdAYeDw7",
        "outputId": "02d31998-5962-469b-fb2f-f620c88196ac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw         object\n",
              "sentids     object\n",
              "split       object\n",
              "filename    object\n",
              "img_id       int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>raw</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentids</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img_id</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcgK3AB7d_vC",
        "outputId": "48768fcc-4686-4e11-c746-8c10a74cc51a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 14,\n",
              " 19,\n",
              " 23,\n",
              " 32,\n",
              " 37,\n",
              " 41,\n",
              " 45,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 52,\n",
              " 53,\n",
              " 55,\n",
              " 58,\n",
              " 64,\n",
              " 75,\n",
              " 77,\n",
              " 81,\n",
              " 84,\n",
              " 86,\n",
              " 89,\n",
              " 97,\n",
              " 98,\n",
              " 101,\n",
              " 104,\n",
              " 109,\n",
              " 110,\n",
              " 127,\n",
              " 140,\n",
              " 151,\n",
              " 152,\n",
              " 156,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 166,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 175,\n",
              " 179,\n",
              " 180,\n",
              " 186,\n",
              " 189,\n",
              " 198,\n",
              " 202,\n",
              " 204,\n",
              " 205,\n",
              " 216,\n",
              " 217,\n",
              " 223,\n",
              " 226,\n",
              " 231,\n",
              " 239,\n",
              " 241,\n",
              " 242,\n",
              " 244,\n",
              " 249,\n",
              " 252,\n",
              " 253,\n",
              " 256,\n",
              " 259,\n",
              " 260,\n",
              " 262,\n",
              " 263,\n",
              " 273,\n",
              " 283,\n",
              " 286,\n",
              " 288,\n",
              " 294,\n",
              " 295,\n",
              " 298,\n",
              " 302,\n",
              " 308,\n",
              " 315,\n",
              " 325,\n",
              " 329,\n",
              " 330,\n",
              " 334,\n",
              " 337,\n",
              " 339,\n",
              " 345,\n",
              " 348,\n",
              " 353,\n",
              " 362,\n",
              " 364,\n",
              " 370,\n",
              " 381,\n",
              " 383,\n",
              " 390,\n",
              " 394,\n",
              " 395,\n",
              " 401,\n",
              " 406,\n",
              " 411,\n",
              " 421,\n",
              " 424,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 440,\n",
              " 444,\n",
              " 447,\n",
              " 452,\n",
              " 463,\n",
              " 466,\n",
              " 471,\n",
              " 474,\n",
              " 476,\n",
              " 479,\n",
              " 482,\n",
              " 492,\n",
              " 494,\n",
              " 503,\n",
              " 507,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 531,\n",
              " 536,\n",
              " 537,\n",
              " 540,\n",
              " 541,\n",
              " 544,\n",
              " 549,\n",
              " 551,\n",
              " 555,\n",
              " 562,\n",
              " 563,\n",
              " 569,\n",
              " 575,\n",
              " 580,\n",
              " 585,\n",
              " 587,\n",
              " 589,\n",
              " 594,\n",
              " 595,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 603,\n",
              " 604,\n",
              " 606,\n",
              " 608,\n",
              " 613,\n",
              " 616,\n",
              " 625,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 636,\n",
              " 637,\n",
              " 639,\n",
              " 640,\n",
              " 642,\n",
              " 643,\n",
              " 647,\n",
              " 648,\n",
              " 650,\n",
              " 651,\n",
              " 654,\n",
              " 660,\n",
              " 665,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 675,\n",
              " 676,\n",
              " 680,\n",
              " 683,\n",
              " 686,\n",
              " 695,\n",
              " 696,\n",
              " 700,\n",
              " 704,\n",
              " 708,\n",
              " 714,\n",
              " 716,\n",
              " 723,\n",
              " 726,\n",
              " 729,\n",
              " 731,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 742,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 755,\n",
              " 757,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 763,\n",
              " 773,\n",
              " 800,\n",
              " 803,\n",
              " 806,\n",
              " 809,\n",
              " 813,\n",
              " 822,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 836,\n",
              " 837,\n",
              " 842,\n",
              " 845,\n",
              " 852,\n",
              " 860,\n",
              " 870,\n",
              " 872,\n",
              " 873,\n",
              " 896,\n",
              " 900,\n",
              " 902,\n",
              " 911,\n",
              " 915,\n",
              " 918,\n",
              " 934,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 943,\n",
              " 944,\n",
              " 948,\n",
              " 949,\n",
              " 957,\n",
              " 960,\n",
              " 962,\n",
              " 963,\n",
              " 966,\n",
              " 967,\n",
              " 970,\n",
              " 982,\n",
              " 994,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 1008,\n",
              " 1009,\n",
              " 1011,\n",
              " 1019,\n",
              " 1020,\n",
              " 1033,\n",
              " 1035,\n",
              " 1036,\n",
              " 1038,\n",
              " 1049,\n",
              " 1051,\n",
              " 1053,\n",
              " 1065,\n",
              " 1070,\n",
              " 1073,\n",
              " 1076,\n",
              " 1084,\n",
              " 1091,\n",
              " 1093,\n",
              " 1097,\n",
              " 1117,\n",
              " 1121,\n",
              " 1123,\n",
              " 1132,\n",
              " 1137,\n",
              " 1145,\n",
              " 1146,\n",
              " 1159,\n",
              " 1168,\n",
              " 1170,\n",
              " 1179,\n",
              " 1181,\n",
              " 1183,\n",
              " 1187,\n",
              " 1194,\n",
              " 1209,\n",
              " 1210,\n",
              " 1213,\n",
              " 1224,\n",
              " 1228,\n",
              " 1229,\n",
              " 1230,\n",
              " 1231,\n",
              " 1232,\n",
              " 1234,\n",
              " 1239,\n",
              " 1240,\n",
              " 1241,\n",
              " 1242,\n",
              " 1254,\n",
              " 1261,\n",
              " 1262,\n",
              " 1264,\n",
              " 1269,\n",
              " 1270,\n",
              " 1271,\n",
              " 1274,\n",
              " 1276,\n",
              " 1286,\n",
              " 1287,\n",
              " 1288,\n",
              " 1290,\n",
              " 1291,\n",
              " 1293,\n",
              " 1298,\n",
              " 1304,\n",
              " 1305,\n",
              " 1310,\n",
              " 1312,\n",
              " 1317,\n",
              " 1319,\n",
              " 1324,\n",
              " 1330,\n",
              " 1338,\n",
              " 1345,\n",
              " 1348,\n",
              " 1349,\n",
              " 1352,\n",
              " 1355,\n",
              " 1366,\n",
              " 1367,\n",
              " 1369,\n",
              " 1370,\n",
              " 1385,\n",
              " 1389,\n",
              " 1392,\n",
              " 1394,\n",
              " 1396,\n",
              " 1397,\n",
              " 1398,\n",
              " 1403,\n",
              " 1404,\n",
              " 1407,\n",
              " 1412,\n",
              " 1416,\n",
              " 1417,\n",
              " 1430,\n",
              " 1438,\n",
              " 1439,\n",
              " 1443,\n",
              " 1445,\n",
              " 1446,\n",
              " 1467,\n",
              " 1473,\n",
              " 1477,\n",
              " 1480,\n",
              " 1482,\n",
              " 1493,\n",
              " 1503,\n",
              " 1507,\n",
              " 1521,\n",
              " 1524,\n",
              " 1526,\n",
              " 1535,\n",
              " 1539,\n",
              " 1548,\n",
              " 1554,\n",
              " 1556,\n",
              " 1563,\n",
              " 1566,\n",
              " 1570,\n",
              " 1571,\n",
              " 1573,\n",
              " 1576,\n",
              " 1585,\n",
              " 1594,\n",
              " 1595,\n",
              " 1596,\n",
              " 1598,\n",
              " 1601,\n",
              " 1603,\n",
              " 1611,\n",
              " 1624,\n",
              " 1630,\n",
              " 1633,\n",
              " 1635,\n",
              " 1640,\n",
              " 1648,\n",
              " 1650,\n",
              " 1653,\n",
              " 1662,\n",
              " 1663,\n",
              " 1665,\n",
              " 1674,\n",
              " 1676,\n",
              " 1677,\n",
              " 1679,\n",
              " 1683,\n",
              " 1696,\n",
              " 1700,\n",
              " 1701,\n",
              " 1703,\n",
              " 1705,\n",
              " 1709,\n",
              " 1712,\n",
              " 1713,\n",
              " 1716,\n",
              " 1720,\n",
              " 1721,\n",
              " 1724,\n",
              " 1727,\n",
              " 1728,\n",
              " 1731,\n",
              " 1734,\n",
              " 1740,\n",
              " 1748,\n",
              " 1749,\n",
              " 1750,\n",
              " 1755,\n",
              " 1768,\n",
              " 1771,\n",
              " 1777,\n",
              " 1787,\n",
              " 1788,\n",
              " 1792,\n",
              " 1793,\n",
              " 1795,\n",
              " 1799,\n",
              " 1800,\n",
              " 1806,\n",
              " 1808,\n",
              " 1813,\n",
              " 1814,\n",
              " 1822,\n",
              " 1824,\n",
              " 1825,\n",
              " 1827,\n",
              " 1842,\n",
              " 1843,\n",
              " 1854,\n",
              " 1857,\n",
              " 1858,\n",
              " 1872,\n",
              " 1876,\n",
              " 1877,\n",
              " 1879,\n",
              " 1880,\n",
              " 1883,\n",
              " 1884,\n",
              " 1888,\n",
              " 1889,\n",
              " 1892,\n",
              " 1897,\n",
              " 1901,\n",
              " 1902,\n",
              " 1919,\n",
              " 1926,\n",
              " 1927,\n",
              " 1928,\n",
              " 1929,\n",
              " 1934,\n",
              " 1935,\n",
              " 1939,\n",
              " 1949,\n",
              " 1950,\n",
              " 1952,\n",
              " 1954,\n",
              " 1955,\n",
              " 1962,\n",
              " 1963,\n",
              " 1969,\n",
              " 1976,\n",
              " 1977,\n",
              " 1983,\n",
              " 1986,\n",
              " 1987,\n",
              " 1989,\n",
              " 1990,\n",
              " 1993,\n",
              " 1994,\n",
              " 2003,\n",
              " 2008,\n",
              " 2010,\n",
              " 2011,\n",
              " 2016,\n",
              " 2017,\n",
              " 2023,\n",
              " 2025,\n",
              " 2026,\n",
              " 2033,\n",
              " 2035,\n",
              " 2043,\n",
              " 2044,\n",
              " 2049,\n",
              " 2057,\n",
              " 2067]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main-univector/main.py --dataset_name flickr --data_path /content/drive/MyDrive/ --query_count 1 --total_count 5000 --subset_img_id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDoxTVO7bf1",
        "outputId": "ffc43de4-23c6-4cca-c66e-f6fc2543984c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-25 22:12:54.306279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "Namespace(data_path='/content/drive/MyDrive/', dataset_name='flickr', model_name='default', query_count=1, random_seed=0, query_concept=False, img_concept=False, total_count=5000, parallel=False, save_mask_bbox=False, search_by_cluster=False, algebra_method='one', closeness_threshold=0.1, subset_img_id=0, prob_agg='prod', segmentation_method='default', dependency_topk=20, clustering_topk=500, add_sparse_index=False, retrieval_method='ours', index_method='default', hashes_per_table=5, num_tables=100, clustering_doc_count_factor=1, clustering_number=0.1, nprobe_query=2, subset_patch_count=-1, cached_file_suffix='', is_test=False, store_res=False, use_phi=False, use_raptor=False)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 4.52k/4.52k [00:00<00:00, 25.3MB/s]\n",
            "model.safetensors: 100% 1.71G/1.71G [00:06<00:00, 263MB/s]\n",
            "preprocessor_config.json: 100% 316/316 [00:00<00:00, 3.22MB/s]\n",
            "tokenizer_config.json: 100% 905/905 [00:00<00:00, 7.29MB/s]\n",
            "vocab.json: 100% 961k/961k [00:00<00:00, 15.1MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 27.9MB/s]\n",
            "tokenizer.json: 100% 2.22M/2.22M [00:00<00:00, 26.7MB/s]\n",
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 3.59MB/s]\n",
            "The selected img id is: 0\n",
            "This is the full query: Two young guys with shaggy hair look at their hands while hanging out in the yard.\n",
            "With image path /content/unzipped_images_fixed/flickr/flickr30k-images/1000092795.jpg\n",
            "100% 31014/31014 [00:04<00:00, 7541.27it/s]\n",
            "Loading cached patches\n",
            "f8b472c8ea4e2212f285d3218db43232cbc264b17497f39e152adcbd86a780ce\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "Loading cached patches\n",
            "f8b472c8ea4e2212f285d3218db43232cbc264b17497f39e152adcbd86a780ce\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "Loading cached patches\n",
            "f8b472c8ea4e2212f285d3218db43232cbc264b17497f39e152adcbd86a780ce\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "Loading cached patches\n",
            "f8b472c8ea4e2212f285d3218db43232cbc264b17497f39e152adcbd86a780ce\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "sample hash:: f8b472c8ea4e2212f285d3218db43232cbc264b17497f39e152adcbd86a780ce\n",
            "results with decomposition::\n",
            "2024-09-25 22:13:49,671 - Encoding Queries...\n",
            "2024-09-25 22:13:49,671 - Sorting Corpus by document length (Longest first)...\n",
            "2024-09-25 22:13:49,671 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-09-25 22:13:49,671 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 1/1 [00:00<00:00,  7.98it/s]\n",
            "torch.Size([1, 1])\n",
            "Time taken: 0.13s\n",
            "These are the queries:\n",
            "['Two young guys with shaggy hair look at their hands while hanging out in the yard.']\n",
            "These are the sub-queries:\n",
            "None\n",
            "Option 1: count of words\n",
            "This is query_lengths:\n",
            "[16]\n",
            "These are the percentiles:\n",
            "[9.9]\n",
            "defaultdict(<class 'list'>, {9: [0], 9.5: [0], 9.9: [0]})\n",
            "Percentile range 90-100:\n",
            "1 queries in this percentile range\n",
            "2024-09-25 22:13:49,810 - \n",
            "\n",
            "2024-09-25 22:13:49,810 - NDCG@1: 1.0000\n",
            "2024-09-25 22:13:49,810 - NDCG@3: 1.0000\n",
            "2024-09-25 22:13:49,811 - NDCG@5: 1.0000\n",
            "2024-09-25 22:13:49,811 - NDCG@10: 1.0000\n",
            "2024-09-25 22:13:49,811 - NDCG@100: 1.0000\n",
            "2024-09-25 22:13:49,811 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:13:49,811 - \n",
            "\n",
            "2024-09-25 22:13:49,811 - MAP@1: 1.0000\n",
            "2024-09-25 22:13:49,811 - MAP@3: 1.0000\n",
            "2024-09-25 22:13:49,811 - MAP@5: 1.0000\n",
            "2024-09-25 22:13:49,811 - MAP@10: 1.0000\n",
            "2024-09-25 22:13:49,811 - MAP@100: 1.0000\n",
            "2024-09-25 22:13:49,811 - MAP@1000: 1.0000\n",
            "2024-09-25 22:13:49,811 - \n",
            "\n",
            "2024-09-25 22:13:49,811 - Recall@1: 1.0000\n",
            "2024-09-25 22:13:49,811 - Recall@3: 1.0000\n",
            "2024-09-25 22:13:49,811 - Recall@5: 1.0000\n",
            "2024-09-25 22:13:49,811 - Recall@10: 1.0000\n",
            "2024-09-25 22:13:49,811 - Recall@100: 1.0000\n",
            "2024-09-25 22:13:49,811 - Recall@1000: 1.0000\n",
            "2024-09-25 22:13:49,811 - \n",
            "\n",
            "2024-09-25 22:13:49,811 - P@1: 1.0000\n",
            "2024-09-25 22:13:49,811 - P@3: 0.3333\n",
            "2024-09-25 22:13:49,811 - P@5: 0.2000\n",
            "2024-09-25 22:13:49,811 - P@10: 0.1000\n",
            "2024-09-25 22:13:49,811 - P@100: 0.0100\n",
            "2024-09-25 22:13:49,811 - P@1000: 0.0010\n",
            "Percentile range 95-100:\n",
            "1 queries in this percentile range\n",
            "2024-09-25 22:13:49,811 - \n",
            "\n",
            "2024-09-25 22:13:49,812 - NDCG@1: 1.0000\n",
            "2024-09-25 22:13:49,812 - NDCG@3: 1.0000\n",
            "2024-09-25 22:13:49,812 - NDCG@5: 1.0000\n",
            "2024-09-25 22:13:49,812 - NDCG@10: 1.0000\n",
            "2024-09-25 22:13:49,812 - NDCG@100: 1.0000\n",
            "2024-09-25 22:13:49,812 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:13:49,812 - \n",
            "\n",
            "2024-09-25 22:13:49,812 - MAP@1: 1.0000\n",
            "2024-09-25 22:13:49,812 - MAP@3: 1.0000\n",
            "2024-09-25 22:13:49,812 - MAP@5: 1.0000\n",
            "2024-09-25 22:13:49,812 - MAP@10: 1.0000\n",
            "2024-09-25 22:13:49,812 - MAP@100: 1.0000\n",
            "2024-09-25 22:13:49,812 - MAP@1000: 1.0000\n",
            "2024-09-25 22:13:49,812 - \n",
            "\n",
            "2024-09-25 22:13:49,812 - Recall@1: 1.0000\n",
            "2024-09-25 22:13:49,812 - Recall@3: 1.0000\n",
            "2024-09-25 22:13:49,812 - Recall@5: 1.0000\n",
            "2024-09-25 22:13:49,812 - Recall@10: 1.0000\n",
            "2024-09-25 22:13:49,812 - Recall@100: 1.0000\n",
            "2024-09-25 22:13:49,812 - Recall@1000: 1.0000\n",
            "2024-09-25 22:13:49,812 - \n",
            "\n",
            "2024-09-25 22:13:49,812 - P@1: 1.0000\n",
            "2024-09-25 22:13:49,812 - P@3: 0.3333\n",
            "2024-09-25 22:13:49,812 - P@5: 0.2000\n",
            "2024-09-25 22:13:49,812 - P@10: 0.1000\n",
            "2024-09-25 22:13:49,812 - P@100: 0.0100\n",
            "2024-09-25 22:13:49,812 - P@1000: 0.0010\n",
            "Percentile range 99-100:\n",
            "1 queries in this percentile range\n",
            "2024-09-25 22:13:49,812 - \n",
            "\n",
            "2024-09-25 22:13:49,813 - NDCG@1: 1.0000\n",
            "2024-09-25 22:13:49,813 - NDCG@3: 1.0000\n",
            "2024-09-25 22:13:49,813 - NDCG@5: 1.0000\n",
            "2024-09-25 22:13:49,813 - NDCG@10: 1.0000\n",
            "2024-09-25 22:13:49,813 - NDCG@100: 1.0000\n",
            "2024-09-25 22:13:49,813 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:13:49,813 - \n",
            "\n",
            "2024-09-25 22:13:49,813 - MAP@1: 1.0000\n",
            "2024-09-25 22:13:49,813 - MAP@3: 1.0000\n",
            "2024-09-25 22:13:49,813 - MAP@5: 1.0000\n",
            "2024-09-25 22:13:49,813 - MAP@10: 1.0000\n",
            "2024-09-25 22:13:49,813 - MAP@100: 1.0000\n",
            "2024-09-25 22:13:49,813 - MAP@1000: 1.0000\n",
            "2024-09-25 22:13:49,813 - \n",
            "\n",
            "2024-09-25 22:13:49,813 - Recall@1: 1.0000\n",
            "2024-09-25 22:13:49,813 - Recall@3: 1.0000\n",
            "2024-09-25 22:13:49,813 - Recall@5: 1.0000\n",
            "2024-09-25 22:13:49,813 - Recall@10: 1.0000\n",
            "2024-09-25 22:13:49,813 - Recall@100: 1.0000\n",
            "2024-09-25 22:13:49,813 - Recall@1000: 1.0000\n",
            "2024-09-25 22:13:49,813 - \n",
            "\n",
            "2024-09-25 22:13:49,813 - P@1: 1.0000\n",
            "2024-09-25 22:13:49,813 - P@3: 0.3333\n",
            "2024-09-25 22:13:49,813 - P@5: 0.2000\n",
            "2024-09-25 22:13:49,813 - P@10: 0.1000\n",
            "2024-09-25 22:13:49,813 - P@100: 0.0100\n",
            "2024-09-25 22:13:49,813 - P@1000: 0.0010\n",
            "Overall recall by buckets:\n",
            "90-100: {'Recall@1': 1.0, 'Recall@3': 1.0, 'Recall@5': 1.0, 'Recall@10': 1.0, 'Recall@100': 1.0, 'Recall@1000': 1.0}\n",
            "95-100: {'Recall@1': 1.0, 'Recall@3': 1.0, 'Recall@5': 1.0, 'Recall@10': 1.0, 'Recall@100': 1.0, 'Recall@1000': 1.0}\n",
            "99-100: {'Recall@1': 1.0, 'Recall@3': 1.0, 'Recall@5': 1.0, 'Recall@10': 1.0, 'Recall@100': 1.0, 'Recall@1000': 1.0}\n",
            "Here are the results: {'1': {'1': 0.3151973485946655}}\n",
            "Here are the qrels: {'1': {'1': 2}}\n",
            "Overall scores:\n",
            "2024-09-25 22:13:49,813 - \n",
            "\n",
            "2024-09-25 22:13:49,814 - NDCG@1: 1.0000\n",
            "2024-09-25 22:13:49,814 - NDCG@3: 1.0000\n",
            "2024-09-25 22:13:49,814 - NDCG@5: 1.0000\n",
            "2024-09-25 22:13:49,814 - NDCG@10: 1.0000\n",
            "2024-09-25 22:13:49,814 - NDCG@100: 1.0000\n",
            "2024-09-25 22:13:49,814 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:13:49,814 - \n",
            "\n",
            "2024-09-25 22:13:49,814 - MAP@1: 1.0000\n",
            "2024-09-25 22:13:49,814 - MAP@3: 1.0000\n",
            "2024-09-25 22:13:49,814 - MAP@5: 1.0000\n",
            "2024-09-25 22:13:49,814 - MAP@10: 1.0000\n",
            "2024-09-25 22:13:49,814 - MAP@100: 1.0000\n",
            "2024-09-25 22:13:49,814 - MAP@1000: 1.0000\n",
            "2024-09-25 22:13:49,814 - \n",
            "\n",
            "2024-09-25 22:13:49,814 - Recall@1: 1.0000\n",
            "2024-09-25 22:13:49,814 - Recall@3: 1.0000\n",
            "2024-09-25 22:13:49,814 - Recall@5: 1.0000\n",
            "2024-09-25 22:13:49,814 - Recall@10: 1.0000\n",
            "2024-09-25 22:13:49,814 - Recall@100: 1.0000\n",
            "2024-09-25 22:13:49,814 - Recall@1000: 1.0000\n",
            "2024-09-25 22:13:49,814 - \n",
            "\n",
            "2024-09-25 22:13:49,814 - P@1: 1.0000\n",
            "2024-09-25 22:13:49,814 - P@3: 0.3333\n",
            "2024-09-25 22:13:49,814 - P@5: 0.2000\n",
            "2024-09-25 22:13:49,814 - P@10: 0.1000\n",
            "2024-09-25 22:13:49,814 - P@100: 0.0100\n",
            "2024-09-25 22:13:49,814 - P@1000: 0.0010\n",
            "used CPU memory:: 2.845775604248047\n",
            "used GPU memory:: -9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main-univector/main.py --dataset_name flickr --data_path /content/drive/MyDrive/ --query_count 1 --total_count 5000 --subset_img_id 150"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKwmkpUUXcR7",
        "outputId": "0a9bbc2c-bd72-4b2c-d0bc-39f99033bb7f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-25 22:25:53.474847: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "Namespace(data_path='/content/drive/MyDrive/', dataset_name='flickr', model_name='default', query_count=1, random_seed=0, query_concept=False, img_concept=False, total_count=100, parallel=False, save_mask_bbox=False, search_by_cluster=False, algebra_method='one', closeness_threshold=0.1, subset_img_id=150, prob_agg='prod', segmentation_method='default', dependency_topk=20, clustering_topk=500, add_sparse_index=False, retrieval_method='ours', index_method='default', hashes_per_table=5, num_tables=100, clustering_doc_count_factor=1, clustering_number=0.1, nprobe_query=2, subset_patch_count=-1, cached_file_suffix='', is_test=False, store_res=False, use_phi=False, use_raptor=False)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "The selected img id is: 150\n",
            "This is the full query: A man with a badge is standing on a wood floor next to a structure.\n",
            "With image path /content/unzipped_images_fixed/flickr/flickr30k-images/105077209.jpg\n",
            "100% 31014/31014 [00:04<00:00, 7066.09it/s]\n",
            "Loading cached patches\n",
            "58c9542bf43034189ee2104d3406ec391a90772527700d4f67947790ea347427\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "Loading cached patches\n",
            "58c9542bf43034189ee2104d3406ec391a90772527700d4f67947790ea347427\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "Loading cached patches\n",
            "58c9542bf43034189ee2104d3406ec391a90772527700d4f67947790ea347427\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "Loading cached patches\n",
            "58c9542bf43034189ee2104d3406ec391a90772527700d4f67947790ea347427\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "no need to separate\n",
            "sample hash:: 58c9542bf43034189ee2104d3406ec391a90772527700d4f67947790ea347427\n",
            "results with decomposition::\n",
            "2024-09-25 22:26:12,638 - Encoding Queries...\n",
            "2024-09-25 22:26:12,638 - Sorting Corpus by document length (Longest first)...\n",
            "2024-09-25 22:26:12,638 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-09-25 22:26:12,638 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 1/1 [00:00<00:00, 29.59it/s]\n",
            "torch.Size([1, 1])\n",
            "Time taken: 0.03s\n",
            "These are the queries:\n",
            "['A man with a badge is standing on a wood floor next to a structure.']\n",
            "These are the sub-queries:\n",
            "None\n",
            "These are the results\n",
            "{'1': {'1': 0.19198545813560486}}\n",
            "Option 1: count of words\n",
            "This is query_lengths:\n",
            "[15]\n",
            "These are the percentiles:\n",
            "[9.9]\n",
            "defaultdict(<class 'list'>, {9: [0], 9.5: [0], 9.9: [0]})\n",
            "Percentile range 90-100:\n",
            "1 queries in this percentile range\n",
            "2024-09-25 22:26:12,679 - \n",
            "\n",
            "2024-09-25 22:26:12,679 - NDCG@1: 1.0000\n",
            "2024-09-25 22:26:12,679 - NDCG@3: 1.0000\n",
            "2024-09-25 22:26:12,680 - NDCG@5: 1.0000\n",
            "2024-09-25 22:26:12,680 - NDCG@10: 1.0000\n",
            "2024-09-25 22:26:12,680 - NDCG@100: 1.0000\n",
            "2024-09-25 22:26:12,680 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:26:12,680 - \n",
            "\n",
            "2024-09-25 22:26:12,680 - MAP@1: 1.0000\n",
            "2024-09-25 22:26:12,680 - MAP@3: 1.0000\n",
            "2024-09-25 22:26:12,680 - MAP@5: 1.0000\n",
            "2024-09-25 22:26:12,680 - MAP@10: 1.0000\n",
            "2024-09-25 22:26:12,680 - MAP@100: 1.0000\n",
            "2024-09-25 22:26:12,680 - MAP@1000: 1.0000\n",
            "2024-09-25 22:26:12,680 - \n",
            "\n",
            "2024-09-25 22:26:12,680 - Recall@1: 1.0000\n",
            "2024-09-25 22:26:12,680 - Recall@3: 1.0000\n",
            "2024-09-25 22:26:12,680 - Recall@5: 1.0000\n",
            "2024-09-25 22:26:12,680 - Recall@10: 1.0000\n",
            "2024-09-25 22:26:12,680 - Recall@100: 1.0000\n",
            "2024-09-25 22:26:12,680 - Recall@1000: 1.0000\n",
            "2024-09-25 22:26:12,680 - \n",
            "\n",
            "2024-09-25 22:26:12,680 - P@1: 1.0000\n",
            "2024-09-25 22:26:12,680 - P@3: 0.3333\n",
            "2024-09-25 22:26:12,680 - P@5: 0.2000\n",
            "2024-09-25 22:26:12,680 - P@10: 0.1000\n",
            "2024-09-25 22:26:12,680 - P@100: 0.0100\n",
            "2024-09-25 22:26:12,680 - P@1000: 0.0010\n",
            "Percentile range 95-100:\n",
            "1 queries in this percentile range\n",
            "2024-09-25 22:26:12,681 - \n",
            "\n",
            "2024-09-25 22:26:12,681 - NDCG@1: 1.0000\n",
            "2024-09-25 22:26:12,681 - NDCG@3: 1.0000\n",
            "2024-09-25 22:26:12,681 - NDCG@5: 1.0000\n",
            "2024-09-25 22:26:12,681 - NDCG@10: 1.0000\n",
            "2024-09-25 22:26:12,681 - NDCG@100: 1.0000\n",
            "2024-09-25 22:26:12,681 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:26:12,681 - \n",
            "\n",
            "2024-09-25 22:26:12,681 - MAP@1: 1.0000\n",
            "2024-09-25 22:26:12,681 - MAP@3: 1.0000\n",
            "2024-09-25 22:26:12,681 - MAP@5: 1.0000\n",
            "2024-09-25 22:26:12,681 - MAP@10: 1.0000\n",
            "2024-09-25 22:26:12,681 - MAP@100: 1.0000\n",
            "2024-09-25 22:26:12,681 - MAP@1000: 1.0000\n",
            "2024-09-25 22:26:12,681 - \n",
            "\n",
            "2024-09-25 22:26:12,681 - Recall@1: 1.0000\n",
            "2024-09-25 22:26:12,681 - Recall@3: 1.0000\n",
            "2024-09-25 22:26:12,681 - Recall@5: 1.0000\n",
            "2024-09-25 22:26:12,681 - Recall@10: 1.0000\n",
            "2024-09-25 22:26:12,681 - Recall@100: 1.0000\n",
            "2024-09-25 22:26:12,681 - Recall@1000: 1.0000\n",
            "2024-09-25 22:26:12,681 - \n",
            "\n",
            "2024-09-25 22:26:12,681 - P@1: 1.0000\n",
            "2024-09-25 22:26:12,681 - P@3: 0.3333\n",
            "2024-09-25 22:26:12,681 - P@5: 0.2000\n",
            "2024-09-25 22:26:12,681 - P@10: 0.1000\n",
            "2024-09-25 22:26:12,681 - P@100: 0.0100\n",
            "2024-09-25 22:26:12,681 - P@1000: 0.0010\n",
            "Percentile range 99-100:\n",
            "1 queries in this percentile range\n",
            "2024-09-25 22:26:12,682 - \n",
            "\n",
            "2024-09-25 22:26:12,682 - NDCG@1: 1.0000\n",
            "2024-09-25 22:26:12,682 - NDCG@3: 1.0000\n",
            "2024-09-25 22:26:12,682 - NDCG@5: 1.0000\n",
            "2024-09-25 22:26:12,682 - NDCG@10: 1.0000\n",
            "2024-09-25 22:26:12,682 - NDCG@100: 1.0000\n",
            "2024-09-25 22:26:12,682 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:26:12,682 - \n",
            "\n",
            "2024-09-25 22:26:12,682 - MAP@1: 1.0000\n",
            "2024-09-25 22:26:12,682 - MAP@3: 1.0000\n",
            "2024-09-25 22:26:12,682 - MAP@5: 1.0000\n",
            "2024-09-25 22:26:12,682 - MAP@10: 1.0000\n",
            "2024-09-25 22:26:12,682 - MAP@100: 1.0000\n",
            "2024-09-25 22:26:12,682 - MAP@1000: 1.0000\n",
            "2024-09-25 22:26:12,682 - \n",
            "\n",
            "2024-09-25 22:26:12,682 - Recall@1: 1.0000\n",
            "2024-09-25 22:26:12,682 - Recall@3: 1.0000\n",
            "2024-09-25 22:26:12,682 - Recall@5: 1.0000\n",
            "2024-09-25 22:26:12,682 - Recall@10: 1.0000\n",
            "2024-09-25 22:26:12,682 - Recall@100: 1.0000\n",
            "2024-09-25 22:26:12,682 - Recall@1000: 1.0000\n",
            "2024-09-25 22:26:12,682 - \n",
            "\n",
            "2024-09-25 22:26:12,682 - P@1: 1.0000\n",
            "2024-09-25 22:26:12,682 - P@3: 0.3333\n",
            "2024-09-25 22:26:12,682 - P@5: 0.2000\n",
            "2024-09-25 22:26:12,682 - P@10: 0.1000\n",
            "2024-09-25 22:26:12,682 - P@100: 0.0100\n",
            "2024-09-25 22:26:12,682 - P@1000: 0.0010\n",
            "Overall recall by buckets:\n",
            "90-100: {'Recall@1': 1.0, 'Recall@3': 1.0, 'Recall@5': 1.0, 'Recall@10': 1.0, 'Recall@100': 1.0, 'Recall@1000': 1.0}\n",
            "95-100: {'Recall@1': 1.0, 'Recall@3': 1.0, 'Recall@5': 1.0, 'Recall@10': 1.0, 'Recall@100': 1.0, 'Recall@1000': 1.0}\n",
            "99-100: {'Recall@1': 1.0, 'Recall@3': 1.0, 'Recall@5': 1.0, 'Recall@10': 1.0, 'Recall@100': 1.0, 'Recall@1000': 1.0}\n",
            "Here are the results: {'1': {'1': 0.19198545813560486}}\n",
            "Here are the qrels: {'1': {'1': 2}}\n",
            "Overall scores:\n",
            "2024-09-25 22:26:12,683 - \n",
            "\n",
            "2024-09-25 22:26:12,683 - NDCG@1: 1.0000\n",
            "2024-09-25 22:26:12,683 - NDCG@3: 1.0000\n",
            "2024-09-25 22:26:12,683 - NDCG@5: 1.0000\n",
            "2024-09-25 22:26:12,683 - NDCG@10: 1.0000\n",
            "2024-09-25 22:26:12,683 - NDCG@100: 1.0000\n",
            "2024-09-25 22:26:12,683 - NDCG@1000: 1.0000\n",
            "2024-09-25 22:26:12,683 - \n",
            "\n",
            "2024-09-25 22:26:12,683 - MAP@1: 1.0000\n",
            "2024-09-25 22:26:12,683 - MAP@3: 1.0000\n",
            "2024-09-25 22:26:12,683 - MAP@5: 1.0000\n",
            "2024-09-25 22:26:12,683 - MAP@10: 1.0000\n",
            "2024-09-25 22:26:12,683 - MAP@100: 1.0000\n",
            "2024-09-25 22:26:12,683 - MAP@1000: 1.0000\n",
            "2024-09-25 22:26:12,683 - \n",
            "\n",
            "2024-09-25 22:26:12,683 - Recall@1: 1.0000\n",
            "2024-09-25 22:26:12,683 - Recall@3: 1.0000\n",
            "2024-09-25 22:26:12,683 - Recall@5: 1.0000\n",
            "2024-09-25 22:26:12,683 - Recall@10: 1.0000\n",
            "2024-09-25 22:26:12,683 - Recall@100: 1.0000\n",
            "2024-09-25 22:26:12,683 - Recall@1000: 1.0000\n",
            "2024-09-25 22:26:12,683 - \n",
            "\n",
            "2024-09-25 22:26:12,683 - P@1: 1.0000\n",
            "2024-09-25 22:26:12,683 - P@3: 0.3333\n",
            "2024-09-25 22:26:12,683 - P@5: 0.2000\n",
            "2024-09-25 22:26:12,683 - P@10: 0.1000\n",
            "2024-09-25 22:26:12,683 - P@100: 0.0100\n",
            "2024-09-25 22:26:12,683 - P@1000: 0.0010\n",
            "used CPU memory:: 2.829273223876953\n",
            "used GPU memory:: -9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# List of `subset_img_id` values (5 values as an example)\n",
        "subset_img_id_list = df_500['img_id'].tolist()\n",
        "iter = 0\n",
        "\n",
        "# Path to save the output on Google Drive\n",
        "output_file_path = '/content/drive/MyDrive/output_log_500_univector_0.txt'\n",
        "\n",
        "# Open the file in append mode\n",
        "with open(output_file_path, 'a') as file:\n",
        "    # Loop to run the command for each subset_img_id\n",
        "    for subset_img_id in subset_img_id_list:\n",
        "        print(f\"Running iteration {iter} with subset_img_id={subset_img_id}...\")\n",
        "        iter += 1\n",
        "\n",
        "        # Construct the command\n",
        "        command = [\n",
        "            'python3', '/content/drive/MyDrive/concept_based_retrieval-main-univector/main.py',\n",
        "            '--dataset_name', 'flickr',\n",
        "            '--data_path', '/content/drive/MyDrive/',\n",
        "            '--query_count', '1',\n",
        "            '--total_count', '2000',\n",
        "            '--subset_img_id', str(subset_img_id)\n",
        "        ]\n",
        "\n",
        "        # Run the command\n",
        "        result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "        # Log output of the current run\n",
        "        file.write(f\"Output of run {iter} with subset_img_id={subset_img_id}:\\n\")\n",
        "        file.write(result.stdout)\n",
        "        file.write(\"=\"*50 + \"\\n\")  # Separator between runs\n",
        "\n",
        "print(f\"All outputs have been saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU1XgX-ZX0WD",
        "outputId": "9f4a5fdd-54cb-4de1-d466-5fe586158493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0 with subset_img_id=0...\n",
            "Running iteration 1 with subset_img_id=1...\n",
            "Running iteration 2 with subset_img_id=4...\n",
            "Running iteration 3 with subset_img_id=9...\n",
            "Running iteration 4 with subset_img_id=10...\n",
            "Running iteration 5 with subset_img_id=11...\n",
            "Running iteration 6 with subset_img_id=14...\n",
            "Running iteration 7 with subset_img_id=19...\n",
            "Running iteration 8 with subset_img_id=23...\n",
            "Running iteration 9 with subset_img_id=32...\n",
            "Running iteration 10 with subset_img_id=37...\n",
            "Running iteration 11 with subset_img_id=41...\n",
            "Running iteration 12 with subset_img_id=45...\n",
            "Running iteration 13 with subset_img_id=48...\n",
            "Running iteration 14 with subset_img_id=49...\n",
            "Running iteration 15 with subset_img_id=50...\n",
            "Running iteration 16 with subset_img_id=52...\n",
            "Running iteration 17 with subset_img_id=53...\n",
            "Running iteration 18 with subset_img_id=55...\n",
            "Running iteration 19 with subset_img_id=58...\n",
            "Running iteration 20 with subset_img_id=64...\n",
            "Running iteration 21 with subset_img_id=75...\n",
            "Running iteration 22 with subset_img_id=77...\n",
            "Running iteration 23 with subset_img_id=81...\n",
            "Running iteration 24 with subset_img_id=84...\n",
            "Running iteration 25 with subset_img_id=86...\n",
            "Running iteration 26 with subset_img_id=89...\n",
            "Running iteration 27 with subset_img_id=97...\n",
            "Running iteration 28 with subset_img_id=98...\n",
            "Running iteration 29 with subset_img_id=101...\n",
            "Running iteration 30 with subset_img_id=104...\n",
            "Running iteration 31 with subset_img_id=109...\n",
            "Running iteration 32 with subset_img_id=110...\n",
            "Running iteration 33 with subset_img_id=127...\n",
            "Running iteration 34 with subset_img_id=140...\n",
            "Running iteration 35 with subset_img_id=151...\n",
            "Running iteration 36 with subset_img_id=152...\n",
            "Running iteration 37 with subset_img_id=156...\n",
            "Running iteration 38 with subset_img_id=162...\n",
            "Running iteration 39 with subset_img_id=163...\n",
            "Running iteration 40 with subset_img_id=164...\n",
            "Running iteration 41 with subset_img_id=166...\n",
            "Running iteration 42 with subset_img_id=168...\n",
            "Running iteration 43 with subset_img_id=169...\n",
            "Running iteration 44 with subset_img_id=170...\n",
            "Running iteration 45 with subset_img_id=175...\n",
            "Running iteration 46 with subset_img_id=179...\n",
            "Running iteration 47 with subset_img_id=180...\n",
            "Running iteration 48 with subset_img_id=186...\n",
            "Running iteration 49 with subset_img_id=189...\n",
            "Running iteration 50 with subset_img_id=198...\n",
            "Running iteration 51 with subset_img_id=202...\n",
            "Running iteration 52 with subset_img_id=204...\n",
            "Running iteration 53 with subset_img_id=205...\n",
            "Running iteration 54 with subset_img_id=216...\n",
            "Running iteration 55 with subset_img_id=217...\n",
            "Running iteration 56 with subset_img_id=223...\n",
            "Running iteration 57 with subset_img_id=226...\n",
            "Running iteration 58 with subset_img_id=231...\n",
            "Running iteration 59 with subset_img_id=239...\n",
            "Running iteration 60 with subset_img_id=241...\n",
            "Running iteration 61 with subset_img_id=242...\n",
            "Running iteration 62 with subset_img_id=244...\n",
            "Running iteration 63 with subset_img_id=249...\n",
            "Running iteration 64 with subset_img_id=252...\n",
            "Running iteration 65 with subset_img_id=253...\n",
            "Running iteration 66 with subset_img_id=256...\n",
            "Running iteration 67 with subset_img_id=259...\n",
            "Running iteration 68 with subset_img_id=260...\n",
            "Running iteration 69 with subset_img_id=262...\n",
            "Running iteration 70 with subset_img_id=263...\n",
            "Running iteration 71 with subset_img_id=273...\n",
            "Running iteration 72 with subset_img_id=283...\n",
            "Running iteration 73 with subset_img_id=286...\n",
            "Running iteration 74 with subset_img_id=288...\n",
            "Running iteration 75 with subset_img_id=294...\n",
            "Running iteration 76 with subset_img_id=295...\n",
            "Running iteration 77 with subset_img_id=298...\n",
            "Running iteration 78 with subset_img_id=302...\n",
            "Running iteration 79 with subset_img_id=308...\n",
            "Running iteration 80 with subset_img_id=315...\n",
            "Running iteration 81 with subset_img_id=325...\n",
            "Running iteration 82 with subset_img_id=329...\n",
            "Running iteration 83 with subset_img_id=330...\n",
            "Running iteration 84 with subset_img_id=334...\n",
            "Running iteration 85 with subset_img_id=337...\n",
            "Running iteration 86 with subset_img_id=339...\n",
            "Running iteration 87 with subset_img_id=345...\n",
            "Running iteration 88 with subset_img_id=348...\n",
            "Running iteration 89 with subset_img_id=353...\n",
            "Running iteration 90 with subset_img_id=362...\n",
            "Running iteration 91 with subset_img_id=364...\n",
            "Running iteration 92 with subset_img_id=370...\n",
            "Running iteration 93 with subset_img_id=381...\n",
            "Running iteration 94 with subset_img_id=383...\n",
            "Running iteration 95 with subset_img_id=390...\n",
            "Running iteration 96 with subset_img_id=394...\n",
            "Running iteration 97 with subset_img_id=395...\n",
            "Running iteration 98 with subset_img_id=401...\n",
            "Running iteration 99 with subset_img_id=406...\n",
            "Running iteration 100 with subset_img_id=411...\n",
            "Running iteration 101 with subset_img_id=421...\n",
            "Running iteration 102 with subset_img_id=424...\n",
            "Running iteration 103 with subset_img_id=434...\n",
            "Running iteration 104 with subset_img_id=435...\n",
            "Running iteration 105 with subset_img_id=436...\n",
            "Running iteration 106 with subset_img_id=440...\n",
            "Running iteration 107 with subset_img_id=444...\n",
            "Running iteration 108 with subset_img_id=447...\n",
            "Running iteration 109 with subset_img_id=452...\n",
            "Running iteration 110 with subset_img_id=463...\n",
            "Running iteration 111 with subset_img_id=466...\n",
            "Running iteration 112 with subset_img_id=471...\n",
            "Running iteration 113 with subset_img_id=474...\n",
            "Running iteration 114 with subset_img_id=476...\n",
            "Running iteration 115 with subset_img_id=479...\n",
            "Running iteration 116 with subset_img_id=482...\n",
            "Running iteration 117 with subset_img_id=492...\n",
            "Running iteration 118 with subset_img_id=494...\n",
            "Running iteration 119 with subset_img_id=503...\n",
            "Running iteration 120 with subset_img_id=507...\n",
            "Running iteration 121 with subset_img_id=510...\n",
            "Running iteration 122 with subset_img_id=511...\n",
            "Running iteration 123 with subset_img_id=512...\n",
            "Running iteration 124 with subset_img_id=524...\n",
            "Running iteration 125 with subset_img_id=525...\n",
            "Running iteration 126 with subset_img_id=526...\n",
            "Running iteration 127 with subset_img_id=531...\n",
            "Running iteration 128 with subset_img_id=536...\n",
            "Running iteration 129 with subset_img_id=537...\n",
            "Running iteration 130 with subset_img_id=540...\n",
            "Running iteration 131 with subset_img_id=541...\n",
            "Running iteration 132 with subset_img_id=544...\n",
            "Running iteration 133 with subset_img_id=549...\n",
            "Running iteration 134 with subset_img_id=551...\n",
            "Running iteration 135 with subset_img_id=555...\n",
            "Running iteration 136 with subset_img_id=562...\n",
            "Running iteration 137 with subset_img_id=563...\n",
            "Running iteration 138 with subset_img_id=569...\n",
            "Running iteration 139 with subset_img_id=575...\n",
            "Running iteration 140 with subset_img_id=580...\n",
            "Running iteration 141 with subset_img_id=585...\n",
            "Running iteration 142 with subset_img_id=587...\n",
            "Running iteration 143 with subset_img_id=589...\n",
            "Running iteration 144 with subset_img_id=594...\n",
            "Running iteration 145 with subset_img_id=595...\n",
            "Running iteration 146 with subset_img_id=597...\n",
            "Running iteration 147 with subset_img_id=598...\n",
            "Running iteration 148 with subset_img_id=599...\n",
            "Running iteration 149 with subset_img_id=603...\n",
            "Running iteration 150 with subset_img_id=604...\n",
            "Running iteration 151 with subset_img_id=606...\n",
            "Running iteration 152 with subset_img_id=608...\n",
            "Running iteration 153 with subset_img_id=613...\n",
            "Running iteration 154 with subset_img_id=616...\n",
            "Running iteration 155 with subset_img_id=625...\n",
            "Running iteration 156 with subset_img_id=627...\n",
            "Running iteration 157 with subset_img_id=628...\n",
            "Running iteration 158 with subset_img_id=629...\n",
            "Running iteration 159 with subset_img_id=631...\n",
            "Running iteration 160 with subset_img_id=632...\n",
            "Running iteration 161 with subset_img_id=633...\n",
            "Running iteration 162 with subset_img_id=636...\n",
            "Running iteration 163 with subset_img_id=637...\n",
            "Running iteration 164 with subset_img_id=639...\n",
            "Running iteration 165 with subset_img_id=640...\n",
            "Running iteration 166 with subset_img_id=642...\n",
            "Running iteration 167 with subset_img_id=643...\n",
            "Running iteration 168 with subset_img_id=647...\n",
            "Running iteration 169 with subset_img_id=648...\n",
            "Running iteration 170 with subset_img_id=650...\n",
            "Running iteration 171 with subset_img_id=651...\n",
            "Running iteration 172 with subset_img_id=654...\n",
            "Running iteration 173 with subset_img_id=660...\n",
            "Running iteration 174 with subset_img_id=665...\n",
            "Running iteration 175 with subset_img_id=671...\n",
            "Running iteration 176 with subset_img_id=672...\n",
            "Running iteration 177 with subset_img_id=673...\n",
            "Running iteration 178 with subset_img_id=675...\n",
            "Running iteration 179 with subset_img_id=676...\n",
            "Running iteration 180 with subset_img_id=680...\n",
            "Running iteration 181 with subset_img_id=683...\n",
            "Running iteration 182 with subset_img_id=686...\n",
            "Running iteration 183 with subset_img_id=695...\n",
            "Running iteration 184 with subset_img_id=696...\n",
            "Running iteration 185 with subset_img_id=700...\n",
            "Running iteration 186 with subset_img_id=704...\n",
            "Running iteration 187 with subset_img_id=708...\n",
            "Running iteration 188 with subset_img_id=714...\n",
            "Running iteration 189 with subset_img_id=716...\n",
            "Running iteration 190 with subset_img_id=723...\n",
            "Running iteration 191 with subset_img_id=726...\n",
            "Running iteration 192 with subset_img_id=729...\n",
            "Running iteration 193 with subset_img_id=731...\n",
            "Running iteration 194 with subset_img_id=734...\n",
            "Running iteration 195 with subset_img_id=735...\n",
            "Running iteration 196 with subset_img_id=736...\n",
            "Running iteration 197 with subset_img_id=742...\n",
            "Running iteration 198 with subset_img_id=746...\n",
            "Running iteration 199 with subset_img_id=747...\n",
            "Running iteration 200 with subset_img_id=748...\n",
            "Running iteration 201 with subset_img_id=749...\n",
            "Running iteration 202 with subset_img_id=755...\n",
            "Running iteration 203 with subset_img_id=757...\n",
            "Running iteration 204 with subset_img_id=759...\n",
            "Running iteration 205 with subset_img_id=760...\n",
            "Running iteration 206 with subset_img_id=761...\n",
            "Running iteration 207 with subset_img_id=763...\n",
            "Running iteration 208 with subset_img_id=773...\n",
            "Running iteration 209 with subset_img_id=800...\n",
            "Running iteration 210 with subset_img_id=803...\n",
            "Running iteration 211 with subset_img_id=806...\n",
            "Running iteration 212 with subset_img_id=809...\n",
            "Running iteration 213 with subset_img_id=813...\n",
            "Running iteration 214 with subset_img_id=822...\n",
            "Running iteration 215 with subset_img_id=828...\n",
            "Running iteration 216 with subset_img_id=829...\n",
            "Running iteration 217 with subset_img_id=830...\n",
            "Running iteration 218 with subset_img_id=836...\n",
            "Running iteration 219 with subset_img_id=837...\n",
            "Running iteration 220 with subset_img_id=842...\n",
            "Running iteration 221 with subset_img_id=845...\n",
            "Running iteration 222 with subset_img_id=852...\n",
            "Running iteration 223 with subset_img_id=860...\n",
            "Running iteration 224 with subset_img_id=870...\n",
            "Running iteration 225 with subset_img_id=872...\n",
            "Running iteration 226 with subset_img_id=873...\n",
            "Running iteration 227 with subset_img_id=896...\n",
            "Running iteration 228 with subset_img_id=900...\n",
            "Running iteration 229 with subset_img_id=902...\n",
            "Running iteration 230 with subset_img_id=911...\n",
            "Running iteration 231 with subset_img_id=915...\n",
            "Running iteration 232 with subset_img_id=918...\n",
            "Running iteration 233 with subset_img_id=934...\n",
            "Running iteration 234 with subset_img_id=938...\n",
            "Running iteration 235 with subset_img_id=939...\n",
            "Running iteration 236 with subset_img_id=940...\n",
            "Running iteration 237 with subset_img_id=941...\n",
            "Running iteration 238 with subset_img_id=943...\n",
            "Running iteration 239 with subset_img_id=944...\n",
            "Running iteration 240 with subset_img_id=948...\n",
            "Running iteration 241 with subset_img_id=949...\n",
            "Running iteration 242 with subset_img_id=957...\n",
            "Running iteration 243 with subset_img_id=960...\n",
            "Running iteration 244 with subset_img_id=962...\n",
            "Running iteration 245 with subset_img_id=963...\n",
            "Running iteration 246 with subset_img_id=966...\n",
            "Running iteration 247 with subset_img_id=967...\n",
            "Running iteration 248 with subset_img_id=970...\n",
            "Running iteration 249 with subset_img_id=982...\n",
            "Running iteration 250 with subset_img_id=994...\n",
            "Running iteration 251 with subset_img_id=996...\n",
            "Running iteration 252 with subset_img_id=997...\n",
            "Running iteration 253 with subset_img_id=998...\n",
            "Running iteration 254 with subset_img_id=1008...\n",
            "Running iteration 255 with subset_img_id=1009...\n",
            "Running iteration 256 with subset_img_id=1011...\n",
            "Running iteration 257 with subset_img_id=1019...\n",
            "Running iteration 258 with subset_img_id=1020...\n",
            "Running iteration 259 with subset_img_id=1033...\n",
            "Running iteration 260 with subset_img_id=1035...\n",
            "Running iteration 261 with subset_img_id=1036...\n",
            "Running iteration 262 with subset_img_id=1038...\n",
            "Running iteration 263 with subset_img_id=1049...\n",
            "Running iteration 264 with subset_img_id=1051...\n",
            "Running iteration 265 with subset_img_id=1053...\n",
            "Running iteration 266 with subset_img_id=1065...\n",
            "Running iteration 267 with subset_img_id=1070...\n",
            "Running iteration 268 with subset_img_id=1073...\n",
            "Running iteration 269 with subset_img_id=1076...\n",
            "Running iteration 270 with subset_img_id=1084...\n",
            "Running iteration 271 with subset_img_id=1091...\n",
            "Running iteration 272 with subset_img_id=1093...\n",
            "Running iteration 273 with subset_img_id=1097...\n",
            "Running iteration 274 with subset_img_id=1117...\n",
            "Running iteration 275 with subset_img_id=1121...\n",
            "Running iteration 276 with subset_img_id=1123...\n",
            "Running iteration 277 with subset_img_id=1132...\n",
            "Running iteration 278 with subset_img_id=1137...\n",
            "Running iteration 279 with subset_img_id=1145...\n",
            "Running iteration 280 with subset_img_id=1146...\n",
            "Running iteration 281 with subset_img_id=1159...\n",
            "Running iteration 282 with subset_img_id=1168...\n",
            "Running iteration 283 with subset_img_id=1170...\n",
            "Running iteration 284 with subset_img_id=1179...\n",
            "Running iteration 285 with subset_img_id=1181...\n",
            "Running iteration 286 with subset_img_id=1183...\n",
            "Running iteration 287 with subset_img_id=1187...\n",
            "Running iteration 288 with subset_img_id=1194...\n",
            "Running iteration 289 with subset_img_id=1209...\n",
            "Running iteration 290 with subset_img_id=1210...\n",
            "Running iteration 291 with subset_img_id=1213...\n",
            "Running iteration 292 with subset_img_id=1224...\n",
            "Running iteration 293 with subset_img_id=1228...\n",
            "Running iteration 294 with subset_img_id=1229...\n",
            "Running iteration 295 with subset_img_id=1230...\n",
            "Running iteration 296 with subset_img_id=1231...\n",
            "Running iteration 297 with subset_img_id=1232...\n",
            "Running iteration 298 with subset_img_id=1234...\n",
            "Running iteration 299 with subset_img_id=1239...\n",
            "Running iteration 300 with subset_img_id=1240...\n",
            "Running iteration 301 with subset_img_id=1241...\n",
            "Running iteration 302 with subset_img_id=1242...\n",
            "Running iteration 303 with subset_img_id=1254...\n",
            "Running iteration 304 with subset_img_id=1261...\n",
            "Running iteration 305 with subset_img_id=1262...\n",
            "Running iteration 306 with subset_img_id=1264...\n",
            "Running iteration 307 with subset_img_id=1269...\n",
            "Running iteration 308 with subset_img_id=1270...\n",
            "Running iteration 309 with subset_img_id=1271...\n",
            "Running iteration 310 with subset_img_id=1274...\n",
            "Running iteration 311 with subset_img_id=1276...\n",
            "Running iteration 312 with subset_img_id=1286...\n",
            "Running iteration 313 with subset_img_id=1287...\n",
            "Running iteration 314 with subset_img_id=1288...\n",
            "Running iteration 315 with subset_img_id=1290...\n",
            "Running iteration 316 with subset_img_id=1291...\n",
            "Running iteration 317 with subset_img_id=1293...\n",
            "Running iteration 318 with subset_img_id=1298...\n",
            "Running iteration 319 with subset_img_id=1304...\n",
            "Running iteration 320 with subset_img_id=1305...\n",
            "Running iteration 321 with subset_img_id=1310...\n",
            "Running iteration 322 with subset_img_id=1312...\n",
            "Running iteration 323 with subset_img_id=1317...\n",
            "Running iteration 324 with subset_img_id=1319...\n",
            "Running iteration 325 with subset_img_id=1324...\n",
            "Running iteration 326 with subset_img_id=1330...\n",
            "Running iteration 327 with subset_img_id=1338...\n",
            "Running iteration 328 with subset_img_id=1345...\n",
            "Running iteration 329 with subset_img_id=1348...\n",
            "Running iteration 330 with subset_img_id=1349...\n",
            "Running iteration 331 with subset_img_id=1352...\n",
            "Running iteration 332 with subset_img_id=1355...\n",
            "Running iteration 333 with subset_img_id=1366...\n",
            "Running iteration 334 with subset_img_id=1367...\n",
            "Running iteration 335 with subset_img_id=1369...\n",
            "Running iteration 336 with subset_img_id=1370...\n",
            "Running iteration 337 with subset_img_id=1385...\n",
            "Running iteration 338 with subset_img_id=1389...\n",
            "Running iteration 339 with subset_img_id=1392...\n",
            "Running iteration 340 with subset_img_id=1394...\n",
            "Running iteration 341 with subset_img_id=1396...\n",
            "Running iteration 342 with subset_img_id=1397...\n",
            "Running iteration 343 with subset_img_id=1398...\n",
            "Running iteration 344 with subset_img_id=1403...\n",
            "Running iteration 345 with subset_img_id=1404...\n",
            "Running iteration 346 with subset_img_id=1407...\n",
            "Running iteration 347 with subset_img_id=1412...\n",
            "Running iteration 348 with subset_img_id=1416...\n",
            "Running iteration 349 with subset_img_id=1417...\n",
            "Running iteration 350 with subset_img_id=1430...\n",
            "Running iteration 351 with subset_img_id=1438...\n",
            "Running iteration 352 with subset_img_id=1439...\n",
            "Running iteration 353 with subset_img_id=1443...\n",
            "Running iteration 354 with subset_img_id=1445...\n",
            "Running iteration 355 with subset_img_id=1446...\n",
            "Running iteration 356 with subset_img_id=1467...\n",
            "Running iteration 357 with subset_img_id=1473...\n",
            "Running iteration 358 with subset_img_id=1477...\n",
            "Running iteration 359 with subset_img_id=1480...\n",
            "Running iteration 360 with subset_img_id=1482...\n",
            "Running iteration 361 with subset_img_id=1493...\n",
            "Running iteration 362 with subset_img_id=1503...\n",
            "Running iteration 363 with subset_img_id=1507...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YH6CJionbrt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}