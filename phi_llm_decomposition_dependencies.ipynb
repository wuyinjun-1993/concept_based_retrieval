{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5001d9cf4224da78f6832c89ead5d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d2b802b94e242ffb96bdb707ec940ac",
              "IPY_MODEL_f539224c9b9a4e3cbcf4799ffdb3fff2",
              "IPY_MODEL_baf5952a598d44c590fb305274bef384"
            ],
            "layout": "IPY_MODEL_ac315b752b0a4eb49c53dc7b50a8e5db"
          }
        },
        "5d2b802b94e242ffb96bdb707ec940ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cedb74c897a44de8c921272862da381",
            "placeholder": "​",
            "style": "IPY_MODEL_9c6aa2992f424b649c9c2cbaecf9e787",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f539224c9b9a4e3cbcf4799ffdb3fff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2150afdb688a45eb9e0cf38b0c5dcfd8",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a23d9fd04954767bc441bbfd13fef22",
            "value": 6
          }
        },
        "baf5952a598d44c590fb305274bef384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd103934c5454725a422d2a689a08d7d",
            "placeholder": "​",
            "style": "IPY_MODEL_81097ae0725f4d4692ad3c76a26413ac",
            "value": " 6/6 [00:11&lt;00:00,  1.80s/it]"
          }
        },
        "ac315b752b0a4eb49c53dc7b50a8e5db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cedb74c897a44de8c921272862da381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6aa2992f424b649c9c2cbaecf9e787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2150afdb688a45eb9e0cf38b0c5dcfd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a23d9fd04954767bc441bbfd13fef22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd103934c5454725a422d2a689a08d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81097ae0725f4d4692ad3c76a26413ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzdb-s54lVcF",
        "outputId": "d6f66f1b-3251-4989-9f63-e60ca2bb5818"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GehOC-TKtkuW",
        "outputId": "6452ff23-2399-44bd-c79e-e712f902d23a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.32.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "img_caption_file_name = '/content/drive/MyDrive/mscoco_40k_clustered.pkl'\n",
        "\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  df_mscoco = pickle.load(f)"
      ],
      "metadata": {
        "id": "NJaNaPPSls-K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "d5001d9cf4224da78f6832c89ead5d92",
            "5d2b802b94e242ffb96bdb707ec940ac",
            "f539224c9b9a4e3cbcf4799ffdb3fff2",
            "baf5952a598d44c590fb305274bef384",
            "ac315b752b0a4eb49c53dc7b50a8e5db",
            "4cedb74c897a44de8c921272862da381",
            "9c6aa2992f424b649c9c2cbaecf9e787",
            "2150afdb688a45eb9e0cf38b0c5dcfd8",
            "9a23d9fd04954767bc441bbfd13fef22",
            "fd103934c5454725a422d2a689a08d7d",
            "81097ae0725f4d4692ad3c76a26413ac"
          ]
        },
        "id": "juetNFPQs_RQ",
        "outputId": "af3031e8-4bb8-4d76-bbfa-aaac33163587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-medium-4k-instruct.d194e4e74ffad5a5e193e26af25bcfc80c7f1ffc.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-medium-4k-instruct.d194e4e74ffad5a5e193e26af25bcfc80c7f1ffc.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5001d9cf4224da78f6832c89ead5d92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-medium-4k-instruct.d194e4e74ffad5a5e193e26af25bcfc80c7f1ffc.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " To solve the equation 2x + 3 = 7, you need to isolate the variable x. Here's how you can do it step by step:\n",
            "\n",
            "1. Subtract 3 from both sides of the equation:\n",
            "   2x + 3 - 3 = 7 - 3\n",
            "   2x = 4\n",
            "\n",
            "2. Divide both sides of the equation by 2:\n",
            "   2x / 2 = 4 / 2\n",
            "   x = 2\n",
            "\n",
            "So, the solution to the equation 2x + 3 = 7 is x = 2.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "model_id = \"microsoft/Phi-3-medium-4k-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
        "]\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}\n",
        "\n",
        "output = pipe(messages, **generation_args)\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decompose_sentence(sentence):\n",
        "    messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"Example 1:\\nOriginal: An institutional looking room holds an exit sign, chairs, recording equipment and a man with one arm aloft that appears to be demonstrating something with a device in the held-up hand for the benefit of a woman behind him that is watching closely.\\n\\nDecomposed form: \\\"An exit sign.\\\"|\\\"Chairs.\\\"|\\\"Recording equipment.\\\"|\\\"A man with one arm aloft appears to be demonstrating with a device in the held-up hand.\\\"|\\\"A woman behind a man is watching him closely.\\\"\\n\\nExample 2:\\nOriginal: Black night, a blurry shot shows a tall fence that angles, in a kind of Z shape, around what appears to be a parking area with a large building fronting it, as a kid with a red helmet takes a fierce swing in the batting area, inside the fence.\\n\\nDecomposed form: \\\"In a black night, a blurry shot shows a tall fence that angles, in a kind of Z shape.\\\"|\\\"Around appears to be a parking area with a large building fronting it.\\\"|\\\"A kid with a red helmet takes a fierce swing in the batting area, inside the fence.\\\"\\n\\nExample 3:\\nOriginal: An older looking model computer components; two disk drive boxes stacked, a keyboard unit, and a more modern looking computer monitor with apple logo center bottom, and on screen at top centered in light blue font letters is printed \\\"APPLE II\\\"\\n\\nDecomposed form: \\\"An older looking model computer components.\\\"|\\\"Computer disk drive boxes stacked.\\\"|\\\"A keyboard unit.\\\"|\\\"A modern computer monitor with apple logo at the center bottom.\\\"|\\\"On the screen of a modern computer monitor, at the top center, light blue font letters print the words APPLE II.\\\"\\n\\nExample 4:\\nOriginal: A motel-like room features all of its furniture in rows, including a sofa, double bed, stuffed chair, desk chair, desk, bureau and television, all of which, like the one piece of artwork, carpet, linen and window drapes, are all in neutrals.\\n\\nDecomposed form: \\\"A motel room.\\\"|\\\"A neutral colored sofa.\\\"|\\\"A neutral colored double bed.\\\"|\\\"A neutral colored stuffed chair.\\\"|\\\"A desk chair.\\\"|\\\"A desk.\\\"|\\\"A bureau.\\\"|\\\"A television.\\\"|\\\"One piece of artwork.\\\"|\\\"Neutral colored linen.\\\"|\\\"Neutral colored window drapes.\\\"\\n\\nExample 5:\\nOriginal: A room shows a twin bed, crib, double bed, and a round bed, all featuring checks and pillows, either white, or checked, high windows, a brick wall, a piece of art against a white wall, and a separate vertical surface with framed items on it.\\n\\nDecomposed form: \\\"A room.\\\"|\\\"A twin bed featuring checks and pillows, either white, or checked.\\\"|\\\"A crib.\\\"|\\\"A double bed featuring checks and pillows, either white, or checked.\\\"|\\\"A round bed featuring checks and pillows, either white, or checked.\\\"|\\\"High windows.\\\"|\\\"A brick wall.\\\"|\\\"A piece of art against a white wall.\\\"|\\\"A vertical surface with framed items on it.\\\"\\n\\nExample 6:\\nOriginal: A street view shows a building entrance and traffic, including a bus, in the background, and to the foreground, a black iron fence, and a bench with an older, seated person, looking at a flock of pigeons scattered on the ground and bench.\\n\\nDecomposed form: \\\"A street view shows a building entrance.\\\"|\\\"A street view shows traffic, including a bus in the background.\\\"|\\\"In the foreground is a black iron fence.\\\"|\\\"In the foreground is a bench with an older person sitting on it\\\"|\\\"A flock of pigeons scattered on the ground and bench.\\\"\\n\\nExample 7:\\nOriginal: Off in the distance, a few people dot the stands and the fenced in area bordering a ball field, while an umpire and three uniformed baseball players, including a batter, catcher and outfielder, strike playing poses in the foreground.\\n\\nDecomposed form: \\\"A few people dot the stands bordering a ball field.\\\"|\\\"A few people dot the fenced-in area bordering a ball field.\\\"|\\\"A baseball umpire.\\\"|\\\"A baseball batter.\\\"|\\\"A baseball catcher.\\\"|\\\"An outfielder.\\\"\\n\\nExample 8:\\nOriginal: A counter top with a plate with a fork and few scraps of food and a teddy bear lying on side with arm outstretched on plate near fork, with another plate with an apple and two bowls with produce, a canister and some metal objects.\\n\\nDecomposed form: \\\"A counter top.\\\"|\\\"A plate with a fork and few scraps of food.\\\"|\\\"A teddy bear lying with arm outstretched on plate near fork.\\\"|\\\"A plate with an apple.\\\"|\\\"Bowls with apples.\\\"|\\\"A canister.\\\"|\\\"Metal objects.\\\"\\n\\nExample 9:\\nOriginal: Indirect lighting in a darkened room plays across a table covered with the remains of a meal, thereby giving everything, including the table, a basket, plates with uneaten food, utensils and glasses with liquid, a reddish patina.\\n\\nDecomposed form: \\\"Indirect lighting in a darkened room shines across a table covered with the remains of a meal.\\\"|\\\"The table has a reddish patina.\\\"|\\\"The basket has a reddish patina.\\\"|\\\"The plates with uneaten food have a reddish patina.\\\"|\\\"Utensils have a reddish patina.\\\"|\\\"Glasses with liquid have a reddish patina.\\\"\\n\\nExample 10:\\nOriginal: the long view of a parking lot shows a row of parked vehicles, including a bus, which appears to be the destination of a number of similarly dressed women with luggage that are moving towards it from the immediate foreground.\\n\\nDecomposed form: \\\"A parking lot shows a row of parked vehicles.\\\"|\\\"A bus.\\\"|\\\"Similarly dressed women with luggages.\\\"\\n\\nExample 11:\\nOriginal: Corner view of a table with plaid cloth, red and white checkerboard napkins, a pizza, a container of green leafy vegetable, and some bottles, with the hips of a person wearing an apron standing beside table in green grass.\\n\\nDecomposed form: \\\"Corner view of a table with plaid cloth.\\\"|\\\"Red and white checkerboard napkins.\\\"|\\\"A pizza.\\\"|\\\"A container of green leafy vegetables.\\\"|\\\"Some bottles.\\\"|\\\"The hips of a person wearing an apron standing beside a table in green grass.\\\"\\n\\nExample 12:\\nOriginal: A room with natural, unfinished, pale wood walls and built in shelves, also has curtained sliding doors that open onto a patio with a lounge chair, a big double bed with a blue blanket, and various framed photos and books.\\n\\nDecomposed form: \\\"A room.\\\"|\\\"Natural, unfinished, pale wood walls.\\\"|\\\"Built-in shelves.\\\"|\\\"Curtained sliding doors.\\\"|\\\"Sliding doors that open onto a patio with a lounge chair.\\\"|\\\"A big double bed with a blue blanket.\\\"|\\\"Framed photos.\\\"|\\\"Books.\\\"\\n\\nExample 13:\\nOriginal: A minimally furnished room shows small window pairs with blinds and no curtains, an unmade double bed with a heavy, taupe duvet, and a white border near the ceiling with colorful birds trailing in both directions.\\n\\nDecomposed form: \\\"A minimally furnished room.\\\"|\\\"Small window pairs with blinds and no curtains.\\\"|\\\"An unmade double bed with a heavy, taupe duvet.\\\"|\\\"A white border near the ceiling with colorful birds trailing in both directions.\\\"\\n\\nExample 14:\\nOriginal: A blurry night-time street scene shows a higher and lower roadway with overpasses and lots of traffic going the same way, while to the left an area of red glare with an arrow and number, suggests a caution area.\\n\\nDecomposed form: \\\"A blurry night-time street scene shows a higher and lower roadway with overpasses and lots of traffic going the same way.\\\"|\\\"An area of red glare with an arrow and number, suggests a caution area.\\\"\\n\\nExample 15:\\nOriginal: Several people are standing, or sitting, in the vicinity of a scoreboard, to the front of which lies a tennis court, featuring a player with his knees bent, who is also grasping a racquet with both hands.\\n\\nDecomposed form: \\\"Several people are standing, or sitting, in the vicinity of a scoreboard.\\\"|\\\"In front of the scoreboard lies a tennis court.\\\"|\\\"A tennis player with his knees bent, who is grasping a racquet with both hands.\\\"\\n\\nExample 16:\\nOriginal: Black and white of a blacksmith interior with a horse, a man standing with arm out to it, and a man ducking under it's head and holding a long metal file in both hands, with horses on poles on the wall.\\n\\nDecomposed form: \\\"Black and white photo of a blacksmith interior with a horse.\\\"|\\\"Black and white photo of a man standing with arm out to a horse.\\\"|\\\"Black and white photo of a man ducking under a horses head and holding a long metal file in both hands.\\\"|\\\"Black and white photo with horse poles on the wall.\\\"\\n\\nExample 17:\\nOriginal: A blurry living room scene suggests a wide screen TV with a game playing, bookshelves, a low cluttered table, a couch, and closest and clearest, a sports t-shirt with the number thirty-five on it.\\n\\nDecomposed form: \\\"A blurry living room scene.\\\"|\\\"A wide screen TV with a sports game playing.\\\"|\\\"Bookshelves.\\\"|\\\"A low cluttered table.\\\"|\\\"A couch.\\\"|\\\"A sports t-shirt with the number 35 on it.\\\"\\n\\nExample 18:\\nOriginal: In the first picture a boy is flipping his skateboard, in the second picture is skating and lifting the board slightly off the ground, and in the third he is jumping into the air onto the skateboard.\\n\\nDecomposed form: \\\"A boy is flipping his skateboard.\\\"|\\\"A boy is skating and lifting the skateboard slightly off the ground.\\\"|\\\"A boy is jumping into the air onto the skateboard.\\\"\\n\\nExample 19:\\nOriginal: A table with a person holding a sandwich in hand over a plate with a knife on it, and another plate with a knife, napkin, and french bread sandwich, along with a bottle and a glass with beverages.\\n\\nDecomposed form: \\\"A table with a person holding a sandwich in hand.\\\"|\\\"A sandwich in hand over a plate with a knife on it.\\\"|\\\"A plate with a knife, napkin, and french bread sandwich.\\\"|\\\"A bottle.\\\"|\\\"A glass with beverages.\\\"\\n\\nExample 20:\\nOriginal: An impressive array of motorcycles recedes into the distance between a driveway and a building fronted with cars and a grassy area, as lots of people mill about the driveway, around the bikes.\\n\\nDecomposed form: \\\"An array of motorcycles between a driveway and a building.\\\"|\\\"A building fronted with cars and a grassy area.\\\"|\\\"Lots of people mill about the driveway, around the bikes.\\\"\\n\\nGiven these examples of decomposing original sentences into their decomposed forms, decompose the given sentence:\\n{sentence}\\nPlease response in the same format, outputing only the decomposed sentences.\"}\n",
        "    ]\n",
        "    output = pipe(messages, **generation_args)\n",
        "    print(output[0]['generated_text'])\n",
        "    return output[0]['generated_text']"
      ],
      "metadata": {
        "id": "GfHowh0Vp9ih"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "class UnionFind:\n",
        "    def __init__(self, size):\n",
        "        self.parent = list(range(size))\n",
        "        self.rank = [1] * size\n",
        "\n",
        "    def find(self, p):\n",
        "        if self.parent[p] != p:\n",
        "            self.parent[p] = self.find(self.parent[p])  # Path compression\n",
        "        return self.parent[p]\n",
        "\n",
        "    def union(self, p, q):\n",
        "        rootP = self.find(p)\n",
        "        rootQ = self.find(q)\n",
        "        if rootP != rootQ:\n",
        "            # Union by rank\n",
        "            if self.rank[rootP] > self.rank[rootQ]:\n",
        "                self.parent[rootQ] = rootP\n",
        "            elif self.rank[rootP] < self.rank[rootQ]:\n",
        "                self.parent[rootP] = rootQ\n",
        "            else:\n",
        "                self.parent[rootQ] = rootP\n",
        "                self.rank[rootP] += 1\n",
        "\n",
        "def check_dependency(sentence, segment1, segment2):\n",
        "    messages = [\n",
        "          {\"role\": \"system\", \"content\": \"Example 1:\\nOverall sentence: An institutional looking room holds an exit sign, chairs, recording equipment and a man with one arm aloft that appears to be demonstrating something with a device in the held-up hand for the benefit of a woman behind him that is watching closely.\\nDecomposed sentence: [\\\"An exit sign.\\\"]|[\\\"Chairs.\\\"]|[\\\"Recording equipment.\\\"]|[\\\"A man with one arm aloft appears to be demonstrating with a device in the held-up hand.\\\",\\\"A woman behind a man is watching him closely.\\\"]\\nExample 2:\\nOverall sentence: Black night, a blurry shot shows a tall fence that angles, in a kind of Z shape, around what appears to be a parking area with a large building fronting it, as a kid with a red helmet takes a fierce swing in the batting area, inside the fence.\\nDecomposed sentence: [\\\"In a black night, a blurry shot shows a tall fence that angles, in a kind of Z shape.\\\",\\\"Around appears to be a parking area with a large building fronting it.\\\",\\\"A kid with a red helmet takes a fierce swing in the batting area, inside the fence.\\\"]\\nExample 3:\\nOverall sentence: An older looking model computer components; two disk drive boxes stacked, a keyboard unit, and a more modern looking computer monitor with apple logo center bottom, and on screen at top centered in light blue font letters is printed APPLE II\\nDecomposed sentence: [\\\"An older looking model computer components.\\\",\\\"Computer disk drive boxes stacked.\\\",\\\"A keyboard unit.\\\"]|[\\\"A modern computer monitor with apple logo at the center bottom.\\\",\\\"On the screen of a modern computer monitor, at the top center, light blue font letters print the words APPLE II.\\\"]\\nExample 4:\\nOverall sentence: A motel-like room features all of its furniture in rows, including a sofa, double bed, stuffed chair, desk chair, desk, bureau and television, all of which, like the one piece of artwork, carpet, linen and window drapes, are all in neutrals.\\nDecomposed sentence: [\\\"A motel room.\\\"]|[\\\"A neutral colored sofa.\\\"]|[\\\"A neutral colored double bed.\\\"]|[\\\"A neutral colored stuffed chair.\\\"]|[\\\"A desk chair.\\\",\\\"A desk.\\\"]|[\\\"A bureau.\\\"]|[\\\"A television.\\\"]|[\\\"One piece of artwork.\\\"]|[\\\"Neutral colored linen.\\\"]|[\\\"Neutral colored window drapes.\\\"]\\nExample 5:\\nOverall sentence: A room shows a twin bed, crib, double bed, and a round bed, all featuring checks and pillows, either white, or checked, high windows, a brick wall, a piece of art against a white wall, and a separate vertical surface with framed items on it.\\nDecomposed sentence: [\\\"A room.\\\"]|[\\\"A twin bed featuring checks and pillows, either white, or checked.\\\"]|[\\\"A crib.\\\"]|[\\\"A double bed featuring checks and pillows, either white, or checked.\\\"]|[\\\"A round bed featuring checks and pillows, either white, or checked.\\\"]|[\\\"High windows.\\\"]|[\\\"A brick wall.\\\"]|[\\\"A piece of art against a white wall.\\\"]|[\\\"A vertical surface with framed items on it.\\\"]\\nExample 6:\\nOverall sentence: A street view shows a building entrance and traffic, including a bus, in the background, and to the foreground, a black iron fence, and a bench with an older, seated person, looking at a flock of pigeons scattered on the ground and bench.\\nDecomposed sentence: [\\\"A street view shows a building entrance.\\\",\\\"A street view shows traffic, including a bus in the background.\\\"]|[\\\"In the foreground is a black iron fence.\\\"]|[\\\"In the foreground is a bench with an older person sitting on it\\\",\\\"A flock of pigeons scattered on the ground and bench.\\\"]\\nExample 7:\\nOverall sentence: Off in the distance, a few people dot the stands and the fenced in area bordering a ball field, while an umpire and three uniformed baseball players, including a batter, catcher and outfielder, strike playing poses in the foreground.\\nDecomposed form: [\\\"A few people dot the stands bordering a ball field.\\\"]|[\\\"A few people dot the fenced-in area bordering a ball field.\\\"]|[\\\"A baseball umpire.\\\",\\\"A baseball batter.\\\",\\\"A baseball catcher.\\\",\\\"An outfielder.\\\"]\\nExample 8:\\nOverall sentence: A counter top with a plate with a fork and few scraps of food and a teddy bear lying on side with arm outstretched on plate near fork, with another plate with an apple and two bowls with produce, a canister and some metal objects.\\nDecomposed sentence: [\\\"A counter top.\\\"]|[\\\"A plate with a fork and few scraps of food.\\\",\\\"A teddy bear lying with arm outstretched on plate near fork.\\\"]|[\\\"A plate with an apple.\\\"]|[\\\"Bowls with apples.\\\"]|[\\\"A canister.\\\"]|[\\\"Metal objects.\\\"]\\nExample 9:\\nOverall sentence: Indirect lighting in a darkened room plays across a table covered with the remains of a meal, thereby giving everything, including the table, a basket, plates with uneaten food, utensils and glasses with liquid, a reddish patina.\\nDecomposed sentence: [\\\"Indirect lighting in a darkened room shines across a table covered with the remains of a meal.\\\",\\\"The table has a reddish patina.\\\",\\\"The basket has a reddish patina.\\\",\\\"The plates with uneaten food have a reddish patina.\\\",\\\"Utensils have a reddish patina.\\\",\\\"Glasses with liquid have a reddish patina.\\\"]\\nExample 10:\\nOverall sentence: the long view of a parking lot shows a row of parked vehicles, including a bus, which appears to be the destination of a number of similarly dressed women with luggage that are moving towards it from the immediate foreground.\\nDecomposed sentence: [\\\"A parking lot shows a row of parked vehicles.\\\",\\\"A bus.\\\"]|[\\\"Similarly dressed women with luggages.\\\"]\\nExample 11:\\nOverall sentence: Corner view of a table with plaid cloth, red and white checkerboard napkins, a pizza, a container of green leafy vegetable, and some bottles, with the hips of a person wearing an apron standing beside table in green grass.\\nDecomposed sentence: [\\\"Corner view of a table with plaid cloth.\\\",\\\"The hips of a person wearing an apron standing beside a table in green grass.\\\"]|[\\\"Red and white checkerboard napkins.\\\"]|[\\\"A pizza.\\\"]|[\\\"A container of green leafy vegetables.\\\"]|[\\\"Some bottles.\\\"]\\nExample 12:\\nOverall sentence: A room with natural, unfinished, pale wood walls and built in shelves, also has curtained sliding doors that open onto a patio with a lounge chair, a big double bed with a blue blanket, and various framed photos and books.\\nDecomposed sentence: [\\\"A room.\\\"]|[\\\"Natural, unfinished, pale wood walls.\\\"]|[\\\"Built-in shelves.\\\"]|[\\\"Curtained sliding doors.\\\",\\\"Sliding doors that open onto a patio with a lounge chair.\\\"]|[\\\"A big double bed with a blue blanket.\\\"]|[\\\"Framed photos.\\\"]|[\\\"Books.\\\"]\\nExample 13:\\nOverall sentence: A minimally furnished room shows small window pairs with blinds and no curtains, an unmade double bed with a heavy, taupe duvet, and a white border near the ceiling with colorful birds trailing in both directions.\\nDecomposed sentence: [\\\"A minimally furnished room.\\\"]|[\\\"Small window pairs with blinds and no curtains.\\\"]|[\\\"An unmade double bed with a heavy, taupe duvet.\\\"]|[\\\"A white border near the ceiling with colorful birds trailing in both directions.\\\"]\\nExample 14:\\nOverall sentence: A blurry night-time street scene shows a higher and lower roadway with overpasses and lots of traffic going the same way, while to the left an area of red glare with an arrow and number, suggests a caution area.\\nDecomposed sentence: [\\\"A blurry night-time street scene shows a higher and lower roadway with overpasses and lots of traffic going the same way.\\\"]|[\\\"An area of red glare with an arrow and number, suggests a caution area.\\\"]\\nExample 15:\\nOverall sentence: Several people are standing, or sitting, in the vicinity of a scoreboard, to the front of which lies a tennis court, featuring a player with his knees bent, who is also grasping a racquet with both hands,\\nDecomposed sentence: [\\\"Several people are standing, or sitting, in the vicinity of a scoreboard.\\\",\\\"In front of the scoreboard lies a tennis court.\\\"]|[\\\"A tennis player with his knees bent, who is grasping a racquet with both hands.\\\"]\\nExample 16:\\nOverall sentence: Black and white of a blacksmith interior with a horse, a man standing with arm out to it, and a man ducking under it's head and holding a long metal file in both hands, with horses on poles on the wall.\\nDecomposed sentence: [\\\"Black and white photo of a blacksmith interior with a horse.\\\",\\\"Black and white photo of a man standing with arm out to a horse.\\\",\\\"Black and white photo of a man ducking under a horses head and holding a long metal file in both hands.\\\"]|[\\\"Black and white photo with horse poles on the wall.\\\"]\\nExample 17:\\nOverall sentence: A blurry living room scene suggests a wide screen T,V. with a game playing, bookshelves, a low cluttered table, a couch, and closest and clearest, a sports t-shirt with the number thirty-five on it.\\nDecomposed sentence: [\\\"A blurry living room scene.\\\"]|[\\\"A wide screen TV with a sports game playing.\\\"]|[\\\"Bookshelves.\\\"]|[\\\"A low cluttered table.\\\"]|[\\\"A couch.\\\"]|[\\\"A sports t-shirt with the number 35 on it.\\\"]\\nExample 18:\\nOverall sentence: In the first picture a boy is flipping his skateboard, in the second picture is skating and lifting the board slightly off the ground, and in the third he is jumping into the air onto the skateboard.\\nDecomposed sentence: [\\\"A boy is flipping his skateboard.\\\",\\\"A boy is skating and lifting the skateboard slightly off the ground.\\\",\\\"A boy is jumping into the air onto the skateboard.\\\"]\\nExample 19:\\nOverall sentence: A table with a person holding a sandwich in hand over a plate with a knife on it, and another plate with a knife, napkin, and french bread sandwich, along with a bottle and a glass with beverages.\\nDecomposed sentence: [\\\"A table with a person holding a sandwich in hand.\\\",\\\"A sandwich in hand over a plate with a knife on it.\\\"]|[\\\"A plate with a knife, napkin, and french bread sandwich.\\\",\\\"A bottle.\\\",\\\"A glass with beverages.\\\"]\\nExample 20:\\nOverall sentence: An impressive array of motorcycles recedes into the distance between a driveway and a building fronted with cars and a grassy area, as lots of people mill about the driveway, around the bikes.\\nDecomposed sentence: [\\\"An array of motorcycles between a driveway and a building.\\\",\\\"A building fronted with cars and a grassy area.\\\",\\\"Lots of people mill about the driveway, around the bikes.\\\"]\\nIn the provided 20 examples, with overall sentence and their decomposed phrases, dependent phrases are grouped in the same set of brackets, while independent phrases are not grouped under the same set of brackets. Note that we define two sentences as dependent when the two phrases share an explicitly defined physical and material object between them in the overall sentence. Given an overall sentence and two decomposed phrases from user input, output whether the two decomposed phrases are dependent or independent. You may answer in only one digit, 1 meaning dependent, 0 meaning independent. Only output 1 if you are 100% certain. Do not consider any vague dependencies.\"},\n",
        "          {\"role\": \"user\", \"content\": f\"Overall sentence:{sentence}\\n And two decomposed phrases: {segment1}, {segment2}\\nPlease output 1 or 0, 1 meaning they are dependent phrases, 0 meaning they are independent phrases.\"}\n",
        "    ]\n",
        "    response = pipe(messages, **generation_args)\n",
        "    result = response[0]['generated_text'].strip()\n",
        "    #print(result)\n",
        "    if result in {'1', '0'}:\n",
        "      print(result)\n",
        "      return int(result)\n",
        "    else:\n",
        "      print(\"non identified\")\n",
        "      return 0\n",
        "\n",
        "def group_dependent_segments(sentence, segments):\n",
        "    segments_list = segments.split('|')\n",
        "    print(segments_list)\n",
        "    n = len(segments_list)\n",
        "\n",
        "    # Initialize Union-Find\n",
        "    uf = UnionFind(n)\n",
        "\n",
        "    # Perform pairwise comparisons sequentially\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            if uf.find(i) != uf.find(j):  # Check if i and j are already in the same group\n",
        "                result = check_dependency(sentence, segments_list[i].strip(), segments_list[j].strip())\n",
        "                if result == 1:\n",
        "                    uf.union(i, j)\n",
        "            else:\n",
        "              print('already in same group')\n",
        "\n",
        "    # Group segments based on union-find results\n",
        "    groups = {}\n",
        "    for i in range(n):\n",
        "        root = uf.find(i)\n",
        "        if root not in groups:\n",
        "            groups[root] = []\n",
        "        groups[root].append(i)\n",
        "\n",
        "    # Convert indices back to segments\n",
        "    grouped_indices = [\",\".join(map(str, sorted(group))) for group in groups.values()]\n",
        "    return \" | \".join(grouped_indices)"
      ],
      "metadata": {
        "id": "BbIEJx2uoOJ2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "jtOraFJwwTJM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_decomp_and_dep(df_input):\n",
        "  df = df_input\n",
        "  df['caption_triples_ls'] = df['caption_mscoco'].apply(decompose_sentence)\n",
        "  # Filter rows that do not start and end with \"\n",
        "  filtered_df = df[~(df['caption_triples_ls'].str.startswith('\"') & df['caption_triples_ls'].str.endswith('\"'))].copy()\n",
        "  # Apply the lambda function to those rows only\n",
        "  filtered_df['caption_triples_ls'] = filtered_df['caption_triples_ls'].apply(lambda x: '\"' + x.split('\"', 1)[-1].rsplit('\"', 1)[0] + '\"')\n",
        "  # Combine the processed rows back with the original DataFrame\n",
        "  result_df = pd.concat([df[(df['caption_triples_ls'].str.startswith('\"') & df['caption_triples_ls'].str.endswith('\"'))], filtered_df]).sort_index()\n",
        "  result_df['groups'] = result_df.apply(lambda row: group_dependent_segments(row['caption_mscoco'], row['caption_triples_ls']), axis=1)\n",
        "  return result_df"
      ],
      "metadata": {
        "id": "CpnsJ0BiyQcQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "result = generate_decomp_and_dep(df_mscoco[0:10])\n",
        "end_time = time.time()\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jhM2-xgtBhd",
        "outputId": "688dc923-1936-49ab-8725-a12c011f9d4b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"An institutional looking room.\"|\"An exit sign.\"|\"Chairs.\"|\"Recording equipment.\"|\"A man with one arm aloft.\"|\"The man appears to be demonstrating something.\"|\"A device in the held-up hand.\"|\"For the benefit of a woman behind him.\"|\"A woman is watching closely.\"\n",
            " \"A black night.\"|\"A blurry shot.\"|\"A tall fence that angles in a kind of Z shape.\"|\"Around what appears to be a parking area.\"|\"A large building fronting the parking area.\"|\"A kid with a red helmet.\"|\"Takes a fierce swing in the batting area.\"|\"Inside the fence.\"\n",
            " \"An older looking model computer components.\"|\"Two disk drive boxes stacked.\"|\"A keyboard unit.\"|\"A more modern looking computer monitor.\"|\"Apple logo center bottom.\"|\"On screen at top centered in light blue font letters is printed 'APPLE II'.\"\n",
            " \"A motel-like room.\"|\"The room features all of its furniture in rows.\"|\"A sofa.\"|\"A double bed.\"|\"A stuffed chair.\"|\"A desk chair.\"|\"A desk.\"|\"A bureau.\"|\"A television.\"|\"All of the furniture and one piece of artwork are in neutrals.\"|\"The carpet is in neutrals.\"|\"The linen is in neutrals.\"|\"The window drapes are in neutrals.\"\n",
            " \"A room.\"|\"A twin bed.\"|\"A crib.\"|\"A double bed.\"|\"A round bed.\"|\"All beds feature checks and pillows.\"|\"Beds with white pillows.\"|\"Beds with checked pillows.\"|\"High windows.\"|\"A brick wall.\"|\"A piece of art against a white wall.\"|\"A separate vertical surface with framed items on it.\"\n",
            " \"A street view.\"|\"A building entrance.\"|\"Traffic, including a bus, in the background.\"|\"In the foreground is a black iron fence.\"|\"In the foreground is a bench with an older, seated person.\"|\"The older, seated person is looking at a flock of pigeons.\"|\"Pigeons scattered on the ground and bench.\"\n",
            " \"Off in the distance, a few people dot the stands.\"|\"Off in the distance, a few people dot the fenced-in area bordering a ball field.\"|\"An umpire and three uniformed baseball players are in the foreground.\"|\"A uniformed baseball player is posing as a batter.\"|\"A uniformed baseball player is posing as a catcher.\"|\"A uniformed baseball player is posing as an outfielder.\"\n",
            " \"A counter top.\"|\"A plate with a fork and few scraps of food.\"|\"A teddy bear lying on side with arm outstretched on plate near fork.\"|\"Another plate with an apple.\"|\"Two bowls with produce.\"|\"A canister.\"|\"Some metal objects.\"\n",
            " \"Indirect lighting in a darkened room.\"|\"Lighting plays across a table.\"|\"The table is covered with the remains of a meal.\"|\"The remains of a meal give everything a reddish patina.\"|\"The table has a reddish patina.\"|\"A basket has a reddish patina.\"|\"Plates with uneaten food have a reddish patina.\"|\"Utensils have a reddish patina.\"|\"Glasses with liquid have a reddish patina.\"\n",
            " \"The long view of a parking lot.\"|\"Shows a row of parked vehicles.\"|\"Including a bus.\"|\"The bus appears to be the destination.\"|\"Of a number of similarly dressed women with luggage.\"|\"Moving towards it from the immediate foreground.\"\n",
            "['\"An institutional looking room.\"', '\"An exit sign.\"', '\"Chairs.\"', '\"Recording equipment.\"', '\"A man with one arm aloft.\"', '\"The man appears to be demonstrating something.\"', '\"A device in the held-up hand.\"', '\"For the benefit of a woman behind him.\"', '\"A woman is watching closely.\"']\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-d6fe5eee9cad>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['caption_triples_ls'] = df['caption_mscoco'].apply(decompose_sentence)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "['\"A black night.\"', '\"A blurry shot.\"', '\"A tall fence that angles in a kind of Z shape.\"', '\"Around what appears to be a parking area.\"', '\"A large building fronting the parking area.\"', '\"A kid with a red helmet.\"', '\"Takes a fierce swing in the batting area.\"', '\"Inside the fence.\"']\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "1\n",
            "0\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "['\"An older looking model computer components.\"', '\"Two disk drive boxes stacked.\"', '\"A keyboard unit.\"', '\"A more modern looking computer monitor.\"', '\"Apple logo center bottom.\"', '\"On screen at top centered in light blue font letters is printed \\'APPLE II\\'.\"']\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "['\"A motel-like room.\"', '\"The room features all of its furniture in rows.\"', '\"A sofa.\"', '\"A double bed.\"', '\"A stuffed chair.\"', '\"A desk chair.\"', '\"A desk.\"', '\"A bureau.\"', '\"A television.\"', '\"All of the furniture and one piece of artwork are in neutrals.\"', '\"The carpet is in neutrals.\"', '\"The linen is in neutrals.\"', '\"The window drapes are in neutrals.\"']\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "['\"A room.\"', '\"A twin bed.\"', '\"A crib.\"', '\"A double bed.\"', '\"A round bed.\"', '\"All beds feature checks and pillows.\"', '\"Beds with white pillows.\"', '\"Beds with checked pillows.\"', '\"High windows.\"', '\"A brick wall.\"', '\"A piece of art against a white wall.\"', '\"A separate vertical surface with framed items on it.\"']\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "['\"A street view.\"', '\"A building entrance.\"', '\"Traffic, including a bus, in the background.\"', '\"In the foreground is a black iron fence.\"', '\"In the foreground is a bench with an older, seated person.\"', '\"The older, seated person is looking at a flock of pigeons.\"', '\"Pigeons scattered on the ground and bench.\"']\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "['\"Off in the distance, a few people dot the stands.\"', '\"Off in the distance, a few people dot the fenced-in area bordering a ball field.\"', '\"An umpire and three uniformed baseball players are in the foreground.\"', '\"A uniformed baseball player is posing as a batter.\"', '\"A uniformed baseball player is posing as a catcher.\"', '\"A uniformed baseball player is posing as an outfielder.\"']\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "['\"A counter top.\"', '\"A plate with a fork and few scraps of food.\"', '\"A teddy bear lying on side with arm outstretched on plate near fork.\"', '\"Another plate with an apple.\"', '\"Two bowls with produce.\"', '\"A canister.\"', '\"Some metal objects.\"']\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "already in same group\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "['\"Indirect lighting in a darkened room.\"', '\"Lighting plays across a table.\"', '\"The table is covered with the remains of a meal.\"', '\"The remains of a meal give everything a reddish patina.\"', '\"The table has a reddish patina.\"', '\"A basket has a reddish patina.\"', '\"Plates with uneaten food have a reddish patina.\"', '\"Utensils have a reddish patina.\"', '\"Glasses with liquid have a reddish patina.\"']\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "0\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "['\"The long view of a parking lot.\"', '\"Shows a row of parked vehicles.\"', '\"Including a bus.\"', '\"The bus appears to be the destination.\"', '\"Of a number of similarly dressed women with luggage.\"', '\"Moving towards it from the immediate foreground.\"']\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "already in same group\n",
            "Time taken: 97.47424650192261 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "a_PHnHAGtodH",
        "outputId": "76e57483-c13c-42e5-8ee2-a3e7923e4273"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id             image  \\\n",
              "0  553992  000000553992.jpg   \n",
              "1   39270  000000039270.jpg   \n",
              "2  277161  000000277161.jpg   \n",
              "3  380070  000000380070.jpg   \n",
              "4  357272  000000357272.jpg   \n",
              "5  480770  000000480770.jpg   \n",
              "6  515241  000000515241.jpg   \n",
              "7  560604  000000560604.jpg   \n",
              "8  158005  000000158005.jpg   \n",
              "9  449712  000000449712.jpg   \n",
              "\n",
              "                                  caption_sharegpt4v  \\\n",
              "0  In the image, a man and a woman are standing i...   \n",
              "1  In the image, there is a man who is in the mid...   \n",
              "2  In the center of the image, a vintage Apple II...   \n",
              "3  The image captures a cozy hotel room, bathed i...   \n",
              "4  The image captures a room that exudes a vintag...   \n",
              "5  In the heart of a bustling city, an elderly wo...   \n",
              "6  The image captures a dynamic moment in a baseb...   \n",
              "7  In the center of the image, a black stuffed an...   \n",
              "8  In the dimly lit ambiance of the room, a dinne...   \n",
              "9  In the image, a group of people are seen walki...   \n",
              "\n",
              "                                      caption_mscoco  \\\n",
              "0  An institutional looking room holds an exit si...   \n",
              "1  Black night, a blurry shot shows a tall fence ...   \n",
              "2  An older looking model computer components; tw...   \n",
              "3  A motel-like room  features all of its furnitu...   \n",
              "4  A room shows a twin bed, crib, double bed, and...   \n",
              "5  A street view shows a building entrance and tr...   \n",
              "6  Off in the distance, a few people dot the stan...   \n",
              "7  A counter top with a plate with a fork and few...   \n",
              "8  Indirect lighting in a darkened room plays acr...   \n",
              "9  the long view of a parking lot shows a row of ...   \n",
              "\n",
              "                                           embedding  \\\n",
              "0  [0.25389287, 0.2295701, -0.108173296, -0.07395...   \n",
              "1  [0.044150963, 0.17922473, -0.14461896, -0.1534...   \n",
              "2  [-0.41152698, -0.29223415, 0.025055759, -0.164...   \n",
              "3  [0.23270163, 0.07637343, 0.36209187, -0.012398...   \n",
              "4  [0.45787933, 0.13048139, 0.11703592, 0.0351443...   \n",
              "5  [0.20354465, -0.0718597, -0.27712327, -0.49626...   \n",
              "6  [-0.029054046, 0.23667967, 0.111569144, 0.0622...   \n",
              "7  [-0.29823345, 0.32871175, -0.07593347, -0.1097...   \n",
              "8  [-0.18686089, 0.35955262, 0.008806132, -0.3130...   \n",
              "9  [0.19945762, -0.1157327, -0.03143066, 0.023830...   \n",
              "\n",
              "   original_mscoco_caption_length  \\\n",
              "0                             249   \n",
              "1                             246   \n",
              "2                             244   \n",
              "3                             243   \n",
              "4                             242   \n",
              "5                             241   \n",
              "6                             235   \n",
              "7                             230   \n",
              "8                             229   \n",
              "9                             226   \n",
              "\n",
              "                                  caption_triples_ls  \\\n",
              "0  \"An institutional looking room.\"|\"An exit sign...   \n",
              "1  \"A black night.\"|\"A blurry shot.\"|\"A tall fenc...   \n",
              "2  \"An older looking model computer components.\"|...   \n",
              "3  \"A motel-like room.\"|\"The room features all of...   \n",
              "4  \"A room.\"|\"A twin bed.\"|\"A crib.\"|\"A double be...   \n",
              "5  \"A street view.\"|\"A building entrance.\"|\"Traff...   \n",
              "6  \"Off in the distance, a few people dot the sta...   \n",
              "7  \"A counter top.\"|\"A plate with a fork and few ...   \n",
              "8  \"Indirect lighting in a darkened room.\"|\"Light...   \n",
              "9  \"The long view of a parking lot.\"|\"Shows a row...   \n",
              "\n",
              "                              groups  \n",
              "0                  0,1,2,3,4,5,6,7,8  \n",
              "1                    0,1,2,3,4,5,6,7  \n",
              "2                        0,1,2,3,4,5  \n",
              "3       0,1,2,3,4,5,6,7,8,9,10,11,12  \n",
              "4  0,1,2,3,4,5,6,7 | 8 | 9 | 10 | 11  \n",
              "5                      0,1,2,3,4,5,6  \n",
              "6                        0,1,2,3,4,5  \n",
              "7              0,1,2 | 3 | 4 | 5 | 6  \n",
              "8                  0,1,2,3,4,5,6,7,8  \n",
              "9                        0,1,2,3,4,5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3910b6d2-6472-471d-9078-bfbcd59cfe85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>embedding</th>\n",
              "      <th>original_mscoco_caption_length</th>\n",
              "      <th>caption_triples_ls</th>\n",
              "      <th>groups</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>553992</td>\n",
              "      <td>000000553992.jpg</td>\n",
              "      <td>In the image, a man and a woman are standing i...</td>\n",
              "      <td>An institutional looking room holds an exit si...</td>\n",
              "      <td>[0.25389287, 0.2295701, -0.108173296, -0.07395...</td>\n",
              "      <td>249</td>\n",
              "      <td>\"An institutional looking room.\"|\"An exit sign...</td>\n",
              "      <td>0,1,2,3,4,5,6,7,8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39270</td>\n",
              "      <td>000000039270.jpg</td>\n",
              "      <td>In the image, there is a man who is in the mid...</td>\n",
              "      <td>Black night, a blurry shot shows a tall fence ...</td>\n",
              "      <td>[0.044150963, 0.17922473, -0.14461896, -0.1534...</td>\n",
              "      <td>246</td>\n",
              "      <td>\"A black night.\"|\"A blurry shot.\"|\"A tall fenc...</td>\n",
              "      <td>0,1,2,3,4,5,6,7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>277161</td>\n",
              "      <td>000000277161.jpg</td>\n",
              "      <td>In the center of the image, a vintage Apple II...</td>\n",
              "      <td>An older looking model computer components; tw...</td>\n",
              "      <td>[-0.41152698, -0.29223415, 0.025055759, -0.164...</td>\n",
              "      <td>244</td>\n",
              "      <td>\"An older looking model computer components.\"|...</td>\n",
              "      <td>0,1,2,3,4,5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380070</td>\n",
              "      <td>000000380070.jpg</td>\n",
              "      <td>The image captures a cozy hotel room, bathed i...</td>\n",
              "      <td>A motel-like room  features all of its furnitu...</td>\n",
              "      <td>[0.23270163, 0.07637343, 0.36209187, -0.012398...</td>\n",
              "      <td>243</td>\n",
              "      <td>\"A motel-like room.\"|\"The room features all of...</td>\n",
              "      <td>0,1,2,3,4,5,6,7,8,9,10,11,12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>357272</td>\n",
              "      <td>000000357272.jpg</td>\n",
              "      <td>The image captures a room that exudes a vintag...</td>\n",
              "      <td>A room shows a twin bed, crib, double bed, and...</td>\n",
              "      <td>[0.45787933, 0.13048139, 0.11703592, 0.0351443...</td>\n",
              "      <td>242</td>\n",
              "      <td>\"A room.\"|\"A twin bed.\"|\"A crib.\"|\"A double be...</td>\n",
              "      <td>0,1,2,3,4,5,6,7 | 8 | 9 | 10 | 11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>480770</td>\n",
              "      <td>000000480770.jpg</td>\n",
              "      <td>In the heart of a bustling city, an elderly wo...</td>\n",
              "      <td>A street view shows a building entrance and tr...</td>\n",
              "      <td>[0.20354465, -0.0718597, -0.27712327, -0.49626...</td>\n",
              "      <td>241</td>\n",
              "      <td>\"A street view.\"|\"A building entrance.\"|\"Traff...</td>\n",
              "      <td>0,1,2,3,4,5,6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>515241</td>\n",
              "      <td>000000515241.jpg</td>\n",
              "      <td>The image captures a dynamic moment in a baseb...</td>\n",
              "      <td>Off in the distance, a few people dot the stan...</td>\n",
              "      <td>[-0.029054046, 0.23667967, 0.111569144, 0.0622...</td>\n",
              "      <td>235</td>\n",
              "      <td>\"Off in the distance, a few people dot the sta...</td>\n",
              "      <td>0,1,2,3,4,5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>560604</td>\n",
              "      <td>000000560604.jpg</td>\n",
              "      <td>In the center of the image, a black stuffed an...</td>\n",
              "      <td>A counter top with a plate with a fork and few...</td>\n",
              "      <td>[-0.29823345, 0.32871175, -0.07593347, -0.1097...</td>\n",
              "      <td>230</td>\n",
              "      <td>\"A counter top.\"|\"A plate with a fork and few ...</td>\n",
              "      <td>0,1,2 | 3 | 4 | 5 | 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>158005</td>\n",
              "      <td>000000158005.jpg</td>\n",
              "      <td>In the dimly lit ambiance of the room, a dinne...</td>\n",
              "      <td>Indirect lighting in a darkened room plays acr...</td>\n",
              "      <td>[-0.18686089, 0.35955262, 0.008806132, -0.3130...</td>\n",
              "      <td>229</td>\n",
              "      <td>\"Indirect lighting in a darkened room.\"|\"Light...</td>\n",
              "      <td>0,1,2,3,4,5,6,7,8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>449712</td>\n",
              "      <td>000000449712.jpg</td>\n",
              "      <td>In the image, a group of people are seen walki...</td>\n",
              "      <td>the long view of a parking lot shows a row of ...</td>\n",
              "      <td>[0.19945762, -0.1157327, -0.03143066, 0.023830...</td>\n",
              "      <td>226</td>\n",
              "      <td>\"The long view of a parking lot.\"|\"Shows a row...</td>\n",
              "      <td>0,1,2,3,4,5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3910b6d2-6472-471d-9078-bfbcd59cfe85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3910b6d2-6472-471d-9078-bfbcd59cfe85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3910b6d2-6472-471d-9078-bfbcd59cfe85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84c91728-bec5-4870-b74e-d1131128aa0a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84c91728-bec5-4870-b74e-d1131128aa0a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84c91728-bec5-4870-b74e-d1131128aa0a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2adda9d3-b6f6-4195-bec2-b010eaf01e14\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2adda9d3-b6f6-4195-bec2-b010eaf01e14 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174033,\n        \"min\": 39270,\n        \"max\": 560604,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          158005,\n          39270,\n          480770\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"000000158005.jpg\",\n          \"000000039270.jpg\",\n          \"000000480770.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_sharegpt4v\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"In the dimly lit ambiance of the room, a dinner table takes center stage, draped in a vibrant red tablecloth. The centerpiece of the table is a plate filled with an assortment of colorful dishes, their hues muted under the soft lighting. To the left and right of the plate are two glasses filled with water, their surfaces gleaming subtly in the light. \\n\\nOn the left side of the table, a basket filled with bread adds a rustic touch to the setting. The background fades into a dark and blurry abyss, drawing focus to the meal laid out on the table. The entire scene paints a picture of a quiet, intimate dinner, waiting to be savored.\",\n          \"In the image, there is a man who is in the midst of a powerful swing at a batting cage. He is dressed in a black shirt and is wearing a red helmet, indicating that he is prepared for the sport. The man's stance and the blur of the bat suggest that he is in action, possibly hitting a baseball.\\n\\nThe image captures him from behind and slightly to the right, providing a clear view of his swing and posture. The batting cage, surrounded by a chain link fence, is the main setting of this scene. Despite the darkness of the surroundings, one can make out faint lights and buildings in the distance, suggesting that this could be an urban setting or a sports complex.\\n\\nThe focus of the image is clearly on the batter and his action, with the background elements serving to provide context to the scene. The image does not contain any text or other discernible objects. The overall atmosphere suggests an intense practice session or perhaps even a late-night game.\",\n          \"In the heart of a bustling city, an elderly woman finds solace on a wooden bench. She's dressed in a beige jacket and blue jeans, her eyes shielded from the sun by a pair of sunglasses. The bench, her temporary haven, is surrounded by a group of pigeons, their feathers a mix of gray, black, and white. They peck at the ground, perhaps in search of food or simply enjoying the day.\\n\\nBehind the bench, a black fence stands guard, separating the woman from the world beyond. A blue car is parked on the street, its vibrant color contrasting with the muted tones of the cityscape. In the distance, a building with a red awning adds a splash of color to the scene. The woman, the pigeons, the car, and the building - each element tells a story of city life.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_mscoco\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Indirect lighting in a darkened room plays across a table covered with the remains of a meal, thereby giving everything, including the table, a basket, plates with uneaten food, utensils and glasses with liquid, a reddish patina.\",\n          \"Black night, a blurry shot shows a tall fence that angles, in a kind of Z shape, around what appears to be  a parking area  with a large building fronting it, as a kid with a red helmet takes a fierce swing in the batting area, inside the fence. \",\n          \"A street view shows a building entrance and traffic, including a bus, in the background, and to the foreground, a black iron fence, and a  bench with an older, seated person, looking at a flock of pigeons scattered on the ground and bench.  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_mscoco_caption_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 226,\n        \"max\": 249,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          229,\n          246,\n          241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_triples_ls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\\"Indirect lighting in a darkened room.\\\"|\\\"Lighting plays across a table.\\\"|\\\"The table is covered with the remains of a meal.\\\"|\\\"The remains of a meal give everything a reddish patina.\\\"|\\\"The table has a reddish patina.\\\"|\\\"A basket has a reddish patina.\\\"|\\\"Plates with uneaten food have a reddish patina.\\\"|\\\"Utensils have a reddish patina.\\\"|\\\"Glasses with liquid have a reddish patina.\\\"\",\n          \"\\\"A black night.\\\"|\\\"A blurry shot.\\\"|\\\"A tall fence that angles in a kind of Z shape.\\\"|\\\"Around what appears to be a parking area.\\\"|\\\"A large building fronting the parking area.\\\"|\\\"A kid with a red helmet.\\\"|\\\"Takes a fierce swing in the batting area.\\\"|\\\"Inside the fence.\\\"\",\n          \"\\\"A street view.\\\"|\\\"A building entrance.\\\"|\\\"Traffic, including a bus, in the background.\\\"|\\\"In the foreground is a black iron fence.\\\"|\\\"In the foreground is a bench with an older, seated person.\\\"|\\\"The older, seated person is looking at a flock of pigeons.\\\"|\\\"Pigeons scattered on the ground and bench.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groups\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"0,1,2,3,4,5,6,7,8\",\n          \"0,1,2,3,4,5,6,7\",\n          \"0,1,2,3,4,5,6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8bYVwbjvadD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}