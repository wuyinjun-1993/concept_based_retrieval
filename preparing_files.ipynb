{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSKDur5tBxaV"
      },
      "source": [
        "Main files:\n",
        "\n",
        "\n",
        "1.   train2017.zip contains all 120k MSCOCO images in .jpg format.\n",
        "2.   mscoco_40k_clustered.pkl contains 40k image paths, captions (both long and short), ids, and embeddings of the clustered results from 120k MSCOCO original captions. It is sorted in descending order by original mscoco caption length.\n",
        "3. mscoco_120k.pkl contains all 120k image paths, captions (both long and short), ids, and embeddings of the 120k MSCOCO images.\n",
        "4. sharegpt4v_imgpaths_paragraph_20queries.pkl are the 20 sharegpt4v queries that are decomposed at paragraph level in caption_triples_ls.\n",
        "5. sharegpt4v_imgpaths_patch_2_4_20queries.pkl are the 20 sharegpt4v queries that are decomposed at patch 2 and 4 sentence level in caption_triples_ls.\n",
        "6. mscoco_imgpaths_longest_20queries.pkl are\n",
        "the 20 original mscoco queries that are decomposed by hand in caption_triples_ls. These queries are longer than average length.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bry6GbqCDTIG"
      },
      "source": [
        "This file also contains a section of the functions used to create sliding windows on longer captions in sharegpt4v to generate patch 2 and 4 sentence level decomposed queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXEI60ElDehl"
      },
      "source": [
        "The end of the file shows example commands in order to run the MSCOCO and Sharegpt4v experiments, with decomposition, no decomposition, and with clustering. Note: A new variable called dataset_path was added in order to provide the option of using mscoco_40k_clustered.pkl or mscoco_120k_clustered.pkl on the experiments. Also, make sure to change image_dir from '/content/unzipped_images/train2017/train2017/' to whatever the root directory for the MSCOCO .jpg images are in image_utils.py before running the experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz_lox-jsJRZ"
      },
      "source": [
        "Unzipping MSCOCO images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wND2dHmiZFxg",
        "outputId": "7e2d8925-be8c-4151-fba3-371d5dc035c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping main image files\n",
            "Finished unzipping main image files\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "print(\"Unzipping main image files\")\n",
        "#zip_file_path is whereever the train2017.zip file is stored at, this path would then be used to downlod the zip file into local disk for faster retrieval\n",
        "#zip_file_path = '/content/drive/MyDrive/ShareGPT4V/data/coco/train2017.zip'\n",
        "zip_file_path = 'C:/Users/YourUsername/Downloads/train2017.zip'\n",
        "#extract_dir holds the directory path where the extracted files will be stored\n",
        "#extract_dir = '/content/unzipped_images/train2017'\n",
        "extract_dir = 'C:/Users/YourUsername/Documents/unzipped_images/train2017'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_dir)\n",
        "print(\"Finished unzipping main image files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlKgOvDosMle"
      },
      "source": [
        "The Clustered MSCOCO captions dataset, 40k images, sorted in descending order according to mscoco's original caption length, includes CLIP embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9upBdMTzoWZM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ucKOZyfGoj24"
      },
      "outputs": [],
      "source": [
        "img_caption_file_name = '/content/drive/MyDrive/mscoco_40k_clustered.pkl'\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  df_mscoco = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "-Bzb1zmnpsoo",
        "outputId": "06ea9d99-d4cd-4324-8ee1-1d72cbfd9cd5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_mscoco\",\n  \"rows\": 43820,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170915,\n        \"min\": 9,\n        \"max\": 581921,\n        \"num_unique_values\": 43820,\n        \"samples\": [\n          274860,\n          294814,\n          401428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43820,\n        \"samples\": [\n          \"000000274860.jpg\",\n          \"000000294814.jpg\",\n          \"000000401428.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_sharegpt4v\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43818,\n        \"samples\": [\n          \"The image captures a vibrant scene at the Grand Canyon National Park. Dominating the foreground are three motorcycles, each a different color - blue, black, and red. They are parked in a neat row, with the blue motorcycle on the left, the black one in the middle, and the red one on the right. Each motorcycle is equipped with a sidecar, adding to the sense of adventure.\\n\\nA man stands next to the red motorcycle, perhaps preparing for a journey or simply admiring the view. His presence adds a human element to the scene.\\n\\nIn the background, several flags flutter in the breeze. Among them are the flags of the United States and the Navajo Nation, symbolizing the diverse cultures that call this place home.\\n\\nThe sky above is a clear blue, dotted with fluffy white clouds. The sun shines brightly, casting a warm glow on the scene below.\\n\\nOverall, this image paints a picture of a day at the Grand Canyon National Park, filled with anticipation for the journey ahead.\",\n          \"In the tranquil setting of a park, two majestic black horses are quenching their thirst from a stone trough. The horses, adorned with black harnesses and bridle, stand side by side, their heads lowered in unison to drink from the trough. The trough, filled with water, is situated on a stone platform, adding a rustic charm to the scene.\\n\\nIn the background, a solitary tree stands tall, its leaves rustling gently in the breeze. Nearby, a bench invites passersby to sit and enjoy the peaceful ambiance. The relative positions of these elements create a harmonious balance in the image, each object contributing to the overall serene atmosphere. The horses, the trough, the tree, and the bench all coexist in this snapshot of a moment, each playing their part in this picturesque tableau.\",\n          \"The image captures a thrilling moment of a kiteboarder in action. The kiteboarder, clad in a black wetsuit, is suspended in mid-air above the choppy, light blue ocean. The kiteboarder's arms are outstretched, as if reaching for the sky, and their legs are bent at the knees, ready for landing. \\n\\nThe kiteboarder is holding onto a control bar, which is connected to a large kite soaring high above. The kite, a vibrant mix of red and white, stands out against the clear sky. \\n\\nIn the background, other kiteboarders can be seen, each engaged in their own dance with the wind and waves. The scene is a testament to the exhilarating sport of kiteboarding.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_mscoco\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43380,\n        \"samples\": [\n          \"A bathroom that has a lot of exposed pipes.\",\n          \"A blonde woman sitting in a chair wearing glasses.\",\n          \"A clean living room is shown with an exercise ball in the corner.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_mscoco_caption_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 25,\n        \"max\": 249,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          84,\n          111,\n          98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_mscoco"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-025f9d5d-a59b-46b4-a791-106d7153909d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>embedding</th>\n",
              "      <th>original_mscoco_caption_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>553992</td>\n",
              "      <td>000000553992.jpg</td>\n",
              "      <td>In the image, a man and a woman are standing i...</td>\n",
              "      <td>An institutional looking room holds an exit si...</td>\n",
              "      <td>[0.25389287, 0.2295701, -0.108173296, -0.07395...</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39270</td>\n",
              "      <td>000000039270.jpg</td>\n",
              "      <td>In the image, there is a man who is in the mid...</td>\n",
              "      <td>Black night, a blurry shot shows a tall fence ...</td>\n",
              "      <td>[0.044150963, 0.17922473, -0.14461896, -0.1534...</td>\n",
              "      <td>246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>277161</td>\n",
              "      <td>000000277161.jpg</td>\n",
              "      <td>In the center of the image, a vintage Apple II...</td>\n",
              "      <td>An older looking model computer components; tw...</td>\n",
              "      <td>[-0.41152698, -0.29223415, 0.025055759, -0.164...</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380070</td>\n",
              "      <td>000000380070.jpg</td>\n",
              "      <td>The image captures a cozy hotel room, bathed i...</td>\n",
              "      <td>A motel-like room  features all of its furnitu...</td>\n",
              "      <td>[0.23270163, 0.07637343, 0.36209187, -0.012398...</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>357272</td>\n",
              "      <td>000000357272.jpg</td>\n",
              "      <td>The image captures a room that exudes a vintag...</td>\n",
              "      <td>A room shows a twin bed, crib, double bed, and...</td>\n",
              "      <td>[0.45787933, 0.13048139, 0.11703592, 0.0351443...</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43815</th>\n",
              "      <td>394474</td>\n",
              "      <td>000000394474.jpg</td>\n",
              "      <td>In the heart of a cozy living room, a mother a...</td>\n",
              "      <td>A woman and a kid in a room.</td>\n",
              "      <td>[-0.01980976, -0.083586425, -0.07760212, 0.066...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43816</th>\n",
              "      <td>106344</td>\n",
              "      <td>000000106344.jpg</td>\n",
              "      <td>In the heart of a bustling crowd, a man stands...</td>\n",
              "      <td>a man in a hat is in a crowd</td>\n",
              "      <td>[0.095746905, 0.24212533, -0.2920563, 0.131121...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43817</th>\n",
              "      <td>10466</td>\n",
              "      <td>000000010466.jpg</td>\n",
              "      <td>This image captures a serene and modern bedroo...</td>\n",
              "      <td>A bed and a couch in a room</td>\n",
              "      <td>[0.19666442, -0.009278011, -0.17982888, -0.074...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43818</th>\n",
              "      <td>254600</td>\n",
              "      <td>000000254600.jpg</td>\n",
              "      <td>In the center of the image, a Sony flat screen...</td>\n",
              "      <td>A scene of a show on a tv.</td>\n",
              "      <td>[0.010409161, 0.16379094, 0.017552432, -0.0025...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43819</th>\n",
              "      <td>55607</td>\n",
              "      <td>000000055607.jpg</td>\n",
              "      <td>In the tranquil setting of this image, a golde...</td>\n",
              "      <td>a cat and a dog on a bed</td>\n",
              "      <td>[0.20394087, 0.12499958, -0.39399546, -0.16349...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43820 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-025f9d5d-a59b-46b4-a791-106d7153909d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-025f9d5d-a59b-46b4-a791-106d7153909d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-025f9d5d-a59b-46b4-a791-106d7153909d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-267a789d-8cfb-4be9-914e-8362377018ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-267a789d-8cfb-4be9-914e-8362377018ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-267a789d-8cfb-4be9-914e-8362377018ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2d8239d5-9517-4880-9547-09176f93404a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_mscoco')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d8239d5-9517-4880-9547-09176f93404a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_mscoco');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           id             image  \\\n",
              "0      553992  000000553992.jpg   \n",
              "1       39270  000000039270.jpg   \n",
              "2      277161  000000277161.jpg   \n",
              "3      380070  000000380070.jpg   \n",
              "4      357272  000000357272.jpg   \n",
              "...       ...               ...   \n",
              "43815  394474  000000394474.jpg   \n",
              "43816  106344  000000106344.jpg   \n",
              "43817   10466  000000010466.jpg   \n",
              "43818  254600  000000254600.jpg   \n",
              "43819   55607  000000055607.jpg   \n",
              "\n",
              "                                      caption_sharegpt4v  \\\n",
              "0      In the image, a man and a woman are standing i...   \n",
              "1      In the image, there is a man who is in the mid...   \n",
              "2      In the center of the image, a vintage Apple II...   \n",
              "3      The image captures a cozy hotel room, bathed i...   \n",
              "4      The image captures a room that exudes a vintag...   \n",
              "...                                                  ...   \n",
              "43815  In the heart of a cozy living room, a mother a...   \n",
              "43816  In the heart of a bustling crowd, a man stands...   \n",
              "43817  This image captures a serene and modern bedroo...   \n",
              "43818  In the center of the image, a Sony flat screen...   \n",
              "43819  In the tranquil setting of this image, a golde...   \n",
              "\n",
              "                                          caption_mscoco  \\\n",
              "0      An institutional looking room holds an exit si...   \n",
              "1      Black night, a blurry shot shows a tall fence ...   \n",
              "2      An older looking model computer components; tw...   \n",
              "3      A motel-like room  features all of its furnitu...   \n",
              "4      A room shows a twin bed, crib, double bed, and...   \n",
              "...                                                  ...   \n",
              "43815                       A woman and a kid in a room.   \n",
              "43816                       a man in a hat is in a crowd   \n",
              "43817                        A bed and a couch in a room   \n",
              "43818                         A scene of a show on a tv.   \n",
              "43819                          a cat and a dog on a bed    \n",
              "\n",
              "                                               embedding  \\\n",
              "0      [0.25389287, 0.2295701, -0.108173296, -0.07395...   \n",
              "1      [0.044150963, 0.17922473, -0.14461896, -0.1534...   \n",
              "2      [-0.41152698, -0.29223415, 0.025055759, -0.164...   \n",
              "3      [0.23270163, 0.07637343, 0.36209187, -0.012398...   \n",
              "4      [0.45787933, 0.13048139, 0.11703592, 0.0351443...   \n",
              "...                                                  ...   \n",
              "43815  [-0.01980976, -0.083586425, -0.07760212, 0.066...   \n",
              "43816  [0.095746905, 0.24212533, -0.2920563, 0.131121...   \n",
              "43817  [0.19666442, -0.009278011, -0.17982888, -0.074...   \n",
              "43818  [0.010409161, 0.16379094, 0.017552432, -0.0025...   \n",
              "43819  [0.20394087, 0.12499958, -0.39399546, -0.16349...   \n",
              "\n",
              "       original_mscoco_caption_length  \n",
              "0                                 249  \n",
              "1                                 246  \n",
              "2                                 244  \n",
              "3                                 243  \n",
              "4                                 242  \n",
              "...                               ...  \n",
              "43815                              28  \n",
              "43816                              28  \n",
              "43817                              27  \n",
              "43818                              26  \n",
              "43819                              25  \n",
              "\n",
              "[43820 rows x 6 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_mscoco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTJeR4mrsaxh"
      },
      "source": [
        "The full MSCOCO captions dataset, 120k images with CLIP embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4efqnlKfrAMs"
      },
      "outputs": [],
      "source": [
        "img_caption_file_name = '/content/drive/MyDrive/mscoco_120k.pkl'\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  df_sharegpt4v = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "5X8qtnu8rK_j",
        "outputId": "c2ac1fcf-d55e-414b-9035-87fa8a77b1e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sharegpt4v"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8fcd21a6-d960-49e2-9428-ecd6470a120e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>000000000009.jpg</td>\n",
              "      <td>In the center of the image, a vibrant blue lun...</td>\n",
              "      <td>Closeup of bins of food that include broccoli ...</td>\n",
              "      <td>[0.196618, -0.1124176, -0.16870016, 0.03273408...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>000000000025.jpg</td>\n",
              "      <td>This image captures a serene moment in a zoo e...</td>\n",
              "      <td>A giraffe eating food from the top of the tree.</td>\n",
              "      <td>[0.3378602, 0.00365863, -0.32199287, 0.1653291...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>000000000030.jpg</td>\n",
              "      <td>The image presents a serene garden scene, cent...</td>\n",
              "      <td>A flower vase is sitting on a porch stand.</td>\n",
              "      <td>[-0.034444228, 0.29082185, -0.022862792, -0.42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34</td>\n",
              "      <td>000000000034.jpg</td>\n",
              "      <td>This is a detailed description of the image:\\n...</td>\n",
              "      <td>A zebra grazing on lush green grass in a field.</td>\n",
              "      <td>[-0.12711053, -0.30761, 0.0056521297, -0.01875...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>000000000036.jpg</td>\n",
              "      <td>In the image, there is a woman standing in fro...</td>\n",
              "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
              "      <td>[0.2885676, -0.18000656, -0.5650209, 0.0151512...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118282</th>\n",
              "      <td>265622</td>\n",
              "      <td>000000265622.jpg</td>\n",
              "      <td>In the heart of a cozy living room, two men ar...</td>\n",
              "      <td>Two men in black shirts playing a game with Ni...</td>\n",
              "      <td>[0.07771664, 0.108801916, -0.4778169, 0.281325...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118283</th>\n",
              "      <td>478857</td>\n",
              "      <td>000000478857.jpg</td>\n",
              "      <td>The image captures a serene suburban scene. Do...</td>\n",
              "      <td>Stop signs on the side of the street near vehi...</td>\n",
              "      <td>[0.39890462, -0.24824393, 0.27765816, -0.44707...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118284</th>\n",
              "      <td>467198</td>\n",
              "      <td>000000467198.jpg</td>\n",
              "      <td>The image captures a small, somewhat neglected...</td>\n",
              "      <td>A dirty and gross public restroom that needs t...</td>\n",
              "      <td>[-0.3209242, 0.16469006, 0.29011577, 0.1682263...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118285</th>\n",
              "      <td>302094</td>\n",
              "      <td>000000302094.jpg</td>\n",
              "      <td>The image captures a vibrant scene from a Chin...</td>\n",
              "      <td>a very nice draw showing a vase with flowers</td>\n",
              "      <td>[-0.19526501, -0.095813915, -0.23475075, -0.11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118286</th>\n",
              "      <td>408923</td>\n",
              "      <td>000000408923.jpg</td>\n",
              "      <td>The image captures a lively scene on a tennis ...</td>\n",
              "      <td>There are some people playing on a community t...</td>\n",
              "      <td>[-0.36754537, -0.18036996, 0.22526744, -0.1092...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>118287 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fcd21a6-d960-49e2-9428-ecd6470a120e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8fcd21a6-d960-49e2-9428-ecd6470a120e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8fcd21a6-d960-49e2-9428-ecd6470a120e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4da7cb01-6da1-4e32-b18a-e08be2d4fa16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4da7cb01-6da1-4e32-b18a-e08be2d4fa16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4da7cb01-6da1-4e32-b18a-e08be2d4fa16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ab2f5513-0726-4035-85b1-8767aebadf1e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sharegpt4v')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab2f5513-0726-4035-85b1-8767aebadf1e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sharegpt4v');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            id             image  \\\n",
              "0            9  000000000009.jpg   \n",
              "1           25  000000000025.jpg   \n",
              "2           30  000000000030.jpg   \n",
              "3           34  000000000034.jpg   \n",
              "4           36  000000000036.jpg   \n",
              "...        ...               ...   \n",
              "118282  265622  000000265622.jpg   \n",
              "118283  478857  000000478857.jpg   \n",
              "118284  467198  000000467198.jpg   \n",
              "118285  302094  000000302094.jpg   \n",
              "118286  408923  000000408923.jpg   \n",
              "\n",
              "                                       caption_sharegpt4v  \\\n",
              "0       In the center of the image, a vibrant blue lun...   \n",
              "1       This image captures a serene moment in a zoo e...   \n",
              "2       The image presents a serene garden scene, cent...   \n",
              "3       This is a detailed description of the image:\\n...   \n",
              "4       In the image, there is a woman standing in fro...   \n",
              "...                                                   ...   \n",
              "118282  In the heart of a cozy living room, two men ar...   \n",
              "118283  The image captures a serene suburban scene. Do...   \n",
              "118284  The image captures a small, somewhat neglected...   \n",
              "118285  The image captures a vibrant scene from a Chin...   \n",
              "118286  The image captures a lively scene on a tennis ...   \n",
              "\n",
              "                                           caption_mscoco  \\\n",
              "0       Closeup of bins of food that include broccoli ...   \n",
              "1         A giraffe eating food from the top of the tree.   \n",
              "2              A flower vase is sitting on a porch stand.   \n",
              "3         A zebra grazing on lush green grass in a field.   \n",
              "4        Woman in swim suit holding parasol on sunny day.   \n",
              "...                                                   ...   \n",
              "118282  Two men in black shirts playing a game with Ni...   \n",
              "118283  Stop signs on the side of the street near vehi...   \n",
              "118284  A dirty and gross public restroom that needs t...   \n",
              "118285       a very nice draw showing a vase with flowers   \n",
              "118286  There are some people playing on a community t...   \n",
              "\n",
              "                                                embedding  \n",
              "0       [0.196618, -0.1124176, -0.16870016, 0.03273408...  \n",
              "1       [0.3378602, 0.00365863, -0.32199287, 0.1653291...  \n",
              "2       [-0.034444228, 0.29082185, -0.022862792, -0.42...  \n",
              "3       [-0.12711053, -0.30761, 0.0056521297, -0.01875...  \n",
              "4       [0.2885676, -0.18000656, -0.5650209, 0.0151512...  \n",
              "...                                                   ...  \n",
              "118282  [0.07771664, 0.108801916, -0.4778169, 0.281325...  \n",
              "118283  [0.39890462, -0.24824393, 0.27765816, -0.44707...  \n",
              "118284  [-0.3209242, 0.16469006, 0.29011577, 0.1682263...  \n",
              "118285  [-0.19526501, -0.095813915, -0.23475075, -0.11...  \n",
              "118286  [-0.36754537, -0.18036996, 0.22526744, -0.1092...  \n",
              "\n",
              "[118287 rows x 5 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sharegpt4v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHxQ6mpGsxu5"
      },
      "source": [
        "Sliding Window functions for long captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Si0xx75drL2S"
      },
      "outputs": [],
      "source": [
        "def partition_paragraph(paragraph, n):\n",
        "    paragraph = paragraph.replace('\\n', '')\n",
        "    # Split the paragraph into phrases\n",
        "    phrases = paragraph.split('.')\n",
        "\n",
        "    # Remove any empty phrases caused by trailing periods\n",
        "    phrases = [phrase.strip() for phrase in phrases if phrase.strip()]\n",
        "\n",
        "    # Perform the sliding window operation\n",
        "    sliding_phrases = []\n",
        "    for i in range(len(phrases) - n + 1):\n",
        "        # Join phrases with a period and space, handling period correctly\n",
        "        sliding_window = '. '.join(phrases[i:i + n])\n",
        "        if not sliding_window.endswith('.'):\n",
        "            sliding_window += '.'\n",
        "        sliding_phrases.append(f\"\\\"{sliding_window}\\\"\")\n",
        "\n",
        "    return \"|\".join(sliding_phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BtTUTWKetdTl"
      },
      "outputs": [],
      "source": [
        "def partition_for_sliding_windows(paragraph, window_sizes):\n",
        "    # List to store results for each window size\n",
        "    all_results = []\n",
        "\n",
        "    phrases = paragraph.split('. ')\n",
        "    num_sentences = len(phrases)\n",
        "\n",
        "    for n in window_sizes:\n",
        "        if n <= num_sentences:\n",
        "            result = partition_paragraph(paragraph, n)\n",
        "            all_results.append(result)\n",
        "        else:\n",
        "            # If the window size exceeds the number of sentences, append the entire paragraph\n",
        "            all_results.append(f\"\\\"{paragraph.strip()}\\\"\")\n",
        "\n",
        "    # Join all results with ' # ' separator\n",
        "    final_result = \" # \".join(all_results)\n",
        "\n",
        "    return final_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZvGaVv0ty-l"
      },
      "source": [
        "An example usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b306E5L6tp20"
      },
      "outputs": [],
      "source": [
        "window_sizes = [2,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hDW0RcaBt-Xk"
      },
      "outputs": [],
      "source": [
        "df = df_sharegpt4v[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8EZaKGDt08E",
        "outputId": "1e122ad0-51fd-4953-a506-aa600891ec2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-45d770dba640>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['caption_triples_ls'] = df['caption_sharegpt4v'].apply(lambda x: partition_for_sliding_windows(x, window_sizes))\n"
          ]
        }
      ],
      "source": [
        "df['caption_triples_ls'] = df['caption_sharegpt4v'].apply(lambda x: partition_for_sliding_windows(x, window_sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jFBfbWThuC0H",
        "outputId": "b6aa21ef-ce28-4127-d0f5-b89911076918"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 9,\n        \"max\": 94,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          9,\n          89,\n          81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"000000000009.jpg\",\n          \"000000000089.jpg\",\n          \"000000000081.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_sharegpt4v\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid.\\n\\nIn the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\n\\nAdjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\n\\nBelow these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\n\\nFinally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\n\\nThe arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\",\n          \"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\n\\nTo the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\n\\nOn the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\n\\nThe backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. \\n\\nThe image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. \\n\\nOverall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\",\n          \"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_mscoco\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Closeup of bins of food that include broccoli and bread.\",\n          \"An oven with a stove on top of it in a kitchen.\",\n          \"A big airplane flying in the big blue sky\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_triples_ls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\\"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid.\\\"|\\\"The containers, two in pink and two in yellow, are arranged in a 2x2 grid. In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds.\\\"|\\\"In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\\"|\\\"The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit.\\\"|\\\"Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple.\\\"|\\\"Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\\"|\\\"The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli.\\\"|\\\"Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\\"|\\\"The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie.\\\"|\\\"Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\\"|\\\"The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface. The arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\\\" # \\\"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid. In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\\"|\\\"The containers, two in pink and two in yellow, are arranged in a 2x2 grid. In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit.\\\"|\\\"In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple.\\\"|\\\"The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\\"|\\\"Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli.\\\"|\\\"Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\\"|\\\"The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie.\\\"|\\\"Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\\"|\\\"The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface. The arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\\\"\",\n          \"\\\"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**.\\\"|\\\"The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel.\\\"|\\\"The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\\"|\\\"The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall.\\\"|\\\"To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\\"|\\\"Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\\"|\\\"On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen.\\\"|\\\"The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone.\\\"|\\\"The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. Overall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\\\" # \\\"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\\"|\\\"The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall.\\\"|\\\"The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\\"|\\\"The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\\"|\\\"To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen.\\\"|\\\"Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone.\\\"|\\\"On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. Overall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\\\"\",\n          \"\\\"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail.\\\"|\\\"The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image.\\\"|\\\"The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft.\\\"|\\\"The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\\\" # \\\"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft.\\\"|\\\"The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-352fbba1-25f8-47e7-b639-bd9b5f47c88b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>embedding</th>\n",
              "      <th>caption_triples_ls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>000000000009.jpg</td>\n",
              "      <td>In the center of the image, a vibrant blue lun...</td>\n",
              "      <td>Closeup of bins of food that include broccoli ...</td>\n",
              "      <td>[0.196618, -0.1124176, -0.16870016, 0.03273408...</td>\n",
              "      <td>\"In the center of the image, a vibrant blue lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>000000000025.jpg</td>\n",
              "      <td>This image captures a serene moment in a zoo e...</td>\n",
              "      <td>A giraffe eating food from the top of the tree.</td>\n",
              "      <td>[0.3378602, 0.00365863, -0.32199287, 0.1653291...</td>\n",
              "      <td>\"This image captures a serene moment in a zoo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>000000000030.jpg</td>\n",
              "      <td>The image presents a serene garden scene, cent...</td>\n",
              "      <td>A flower vase is sitting on a porch stand.</td>\n",
              "      <td>[-0.034444228, 0.29082185, -0.022862792, -0.42...</td>\n",
              "      <td>\"The image presents a serene garden scene, cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34</td>\n",
              "      <td>000000000034.jpg</td>\n",
              "      <td>This is a detailed description of the image:\\n...</td>\n",
              "      <td>A zebra grazing on lush green grass in a field.</td>\n",
              "      <td>[-0.12711053, -0.30761, 0.0056521297, -0.01875...</td>\n",
              "      <td>\"This is a detailed description of the image:-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>000000000036.jpg</td>\n",
              "      <td>In the image, there is a woman standing in fro...</td>\n",
              "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
              "      <td>[0.2885676, -0.18000656, -0.5650209, 0.0151512...</td>\n",
              "      <td>\"In the image, there is a woman standing in fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>42</td>\n",
              "      <td>000000000042.jpg</td>\n",
              "      <td>This image captures a serene moment of a light...</td>\n",
              "      <td>This wire metal rack holds several pairs of sh...</td>\n",
              "      <td>[-0.22629666, -0.2050178, 0.00043430924, -0.17...</td>\n",
              "      <td>\"This image captures a serene moment of a ligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>000000000049.jpg</td>\n",
              "      <td>The image showcases a captivating scene of a d...</td>\n",
              "      <td>A couple of men riding horses on top of a gree...</td>\n",
              "      <td>[-0.15934582, 0.088526934, -0.29948297, -0.145...</td>\n",
              "      <td>\"The image showcases a captivating scene of a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>61</td>\n",
              "      <td>000000000061.jpg</td>\n",
              "      <td>This image captures a fascinating scene in a d...</td>\n",
              "      <td>They are brave for riding in the jungle on tho...</td>\n",
              "      <td>[0.095304996, 0.022426754, -0.10571071, 0.1897...</td>\n",
              "      <td>\"This image captures a fascinating scene in a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "      <td>000000000064.jpg</td>\n",
              "      <td>This image captures a moment in an urban setti...</td>\n",
              "      <td>a black and silver clock tower at an intersect...</td>\n",
              "      <td>[-0.06783208, 0.14389609, -0.13291106, -0.0770...</td>\n",
              "      <td>\"This image captures a moment in an urban sett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>71</td>\n",
              "      <td>000000000071.jpg</td>\n",
              "      <td>This image captures a bustling scene at a trai...</td>\n",
              "      <td>A train coming to a stop on the tracks out side.</td>\n",
              "      <td>[0.0012004673, -0.093699, -0.09590492, 0.09248...</td>\n",
              "      <td>\"This image captures a bustling scene at a tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>72</td>\n",
              "      <td>000000000072.jpg</td>\n",
              "      <td>This image captures a serene moment in a fores...</td>\n",
              "      <td>A couple of giraffe snuggling each other in a ...</td>\n",
              "      <td>[0.13703077, -0.030081488, -0.287522, 0.172522...</td>\n",
              "      <td>\"This image captures a serene moment in a fore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>73</td>\n",
              "      <td>000000000073.jpg</td>\n",
              "      <td>This image captures a scene of tranquility and...</td>\n",
              "      <td>A motorcycle parked in a parking space next to...</td>\n",
              "      <td>[0.22309507, 0.08987352, 0.31194523, -0.271852...</td>\n",
              "      <td>\"This image captures a scene of tranquility an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>74</td>\n",
              "      <td>000000000074.jpg</td>\n",
              "      <td>This is a serene street scene, likely set in I...</td>\n",
              "      <td>A picture of a dog laying on the ground.</td>\n",
              "      <td>[0.07300411, 0.26804006, -0.4476019, -0.004406...</td>\n",
              "      <td>\"This is a serene street scene, likely set in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>77</td>\n",
              "      <td>000000000077.jpg</td>\n",
              "      <td>This image captures a vibrant scene at a skate...</td>\n",
              "      <td>A young man riding a skateboard into the air.</td>\n",
              "      <td>[0.16173431, 0.12761247, -0.1851144, -0.293259...</td>\n",
              "      <td>\"This image captures a vibrant scene at a skat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>78</td>\n",
              "      <td>000000000078.jpg</td>\n",
              "      <td>The image features two main objects placed on ...</td>\n",
              "      <td>A lighted owl candle sits next to a clock.</td>\n",
              "      <td>[-0.10221387, -0.1314347, -0.060042597, -0.043...</td>\n",
              "      <td>\"The image features two main objects placed on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>81</td>\n",
              "      <td>000000000081.jpg</td>\n",
              "      <td>This is a photo of an **Air France Airbus A380...</td>\n",
              "      <td>A big airplane flying in the big blue sky</td>\n",
              "      <td>[0.14504424, 0.04511755, -0.13050377, 0.081771...</td>\n",
              "      <td>\"This is a photo of an **Air France Airbus A38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>86</td>\n",
              "      <td>000000000086.jpg</td>\n",
              "      <td>The image is a black and white photograph capt...</td>\n",
              "      <td>A man riding a motor bike across a forest.</td>\n",
              "      <td>[-0.1248993, 0.15603076, 0.045981072, -0.04846...</td>\n",
              "      <td>\"The image is a black and white photograph cap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>89</td>\n",
              "      <td>000000000089.jpg</td>\n",
              "      <td>The image depicts a well-organized kitchen sce...</td>\n",
              "      <td>An oven with a stove on top of it in a kitchen.</td>\n",
              "      <td>[-0.107714385, -0.31135666, -0.15398192, -0.17...</td>\n",
              "      <td>\"The image depicts a well-organized kitchen sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>92</td>\n",
              "      <td>000000000092.jpg</td>\n",
              "      <td>The image presents a delightful scene of indul...</td>\n",
              "      <td>A white plate with a brownie and white frosting.</td>\n",
              "      <td>[0.02235657, 0.12525424, 0.20453936, 0.3898539...</td>\n",
              "      <td>\"The image presents a delightful scene of indu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>94</td>\n",
              "      <td>000000000094.jpg</td>\n",
              "      <td>This image captures a vibrant scene from a Mid...</td>\n",
              "      <td>There is a street lined with packed buildings</td>\n",
              "      <td>[0.026652284, 0.018176243, 0.22643599, -0.1045...</td>\n",
              "      <td>\"This image captures a vibrant scene from a Mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-352fbba1-25f8-47e7-b639-bd9b5f47c88b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-352fbba1-25f8-47e7-b639-bd9b5f47c88b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-352fbba1-25f8-47e7-b639-bd9b5f47c88b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-373c89c7-f084-4aae-82c4-b648b4114628\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-373c89c7-f084-4aae-82c4-b648b4114628')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-373c89c7-f084-4aae-82c4-b648b4114628 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ee724003-6a86-4df0-a770-4baeb564dcfc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ee724003-6a86-4df0-a770-4baeb564dcfc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id             image                                 caption_sharegpt4v  \\\n",
              "0    9  000000000009.jpg  In the center of the image, a vibrant blue lun...   \n",
              "1   25  000000000025.jpg  This image captures a serene moment in a zoo e...   \n",
              "2   30  000000000030.jpg  The image presents a serene garden scene, cent...   \n",
              "3   34  000000000034.jpg  This is a detailed description of the image:\\n...   \n",
              "4   36  000000000036.jpg  In the image, there is a woman standing in fro...   \n",
              "5   42  000000000042.jpg  This image captures a serene moment of a light...   \n",
              "6   49  000000000049.jpg  The image showcases a captivating scene of a d...   \n",
              "7   61  000000000061.jpg  This image captures a fascinating scene in a d...   \n",
              "8   64  000000000064.jpg  This image captures a moment in an urban setti...   \n",
              "9   71  000000000071.jpg  This image captures a bustling scene at a trai...   \n",
              "10  72  000000000072.jpg  This image captures a serene moment in a fores...   \n",
              "11  73  000000000073.jpg  This image captures a scene of tranquility and...   \n",
              "12  74  000000000074.jpg  This is a serene street scene, likely set in I...   \n",
              "13  77  000000000077.jpg  This image captures a vibrant scene at a skate...   \n",
              "14  78  000000000078.jpg  The image features two main objects placed on ...   \n",
              "15  81  000000000081.jpg  This is a photo of an **Air France Airbus A380...   \n",
              "16  86  000000000086.jpg  The image is a black and white photograph capt...   \n",
              "17  89  000000000089.jpg  The image depicts a well-organized kitchen sce...   \n",
              "18  92  000000000092.jpg  The image presents a delightful scene of indul...   \n",
              "19  94  000000000094.jpg  This image captures a vibrant scene from a Mid...   \n",
              "\n",
              "                                       caption_mscoco  \\\n",
              "0   Closeup of bins of food that include broccoli ...   \n",
              "1     A giraffe eating food from the top of the tree.   \n",
              "2          A flower vase is sitting on a porch stand.   \n",
              "3     A zebra grazing on lush green grass in a field.   \n",
              "4    Woman in swim suit holding parasol on sunny day.   \n",
              "5   This wire metal rack holds several pairs of sh...   \n",
              "6   A couple of men riding horses on top of a gree...   \n",
              "7   They are brave for riding in the jungle on tho...   \n",
              "8   a black and silver clock tower at an intersect...   \n",
              "9    A train coming to a stop on the tracks out side.   \n",
              "10  A couple of giraffe snuggling each other in a ...   \n",
              "11  A motorcycle parked in a parking space next to...   \n",
              "12           A picture of a dog laying on the ground.   \n",
              "13      A young man riding a skateboard into the air.   \n",
              "14         A lighted owl candle sits next to a clock.   \n",
              "15          A big airplane flying in the big blue sky   \n",
              "16         A man riding a motor bike across a forest.   \n",
              "17    An oven with a stove on top of it in a kitchen.   \n",
              "18   A white plate with a brownie and white frosting.   \n",
              "19      There is a street lined with packed buildings   \n",
              "\n",
              "                                            embedding  \\\n",
              "0   [0.196618, -0.1124176, -0.16870016, 0.03273408...   \n",
              "1   [0.3378602, 0.00365863, -0.32199287, 0.1653291...   \n",
              "2   [-0.034444228, 0.29082185, -0.022862792, -0.42...   \n",
              "3   [-0.12711053, -0.30761, 0.0056521297, -0.01875...   \n",
              "4   [0.2885676, -0.18000656, -0.5650209, 0.0151512...   \n",
              "5   [-0.22629666, -0.2050178, 0.00043430924, -0.17...   \n",
              "6   [-0.15934582, 0.088526934, -0.29948297, -0.145...   \n",
              "7   [0.095304996, 0.022426754, -0.10571071, 0.1897...   \n",
              "8   [-0.06783208, 0.14389609, -0.13291106, -0.0770...   \n",
              "9   [0.0012004673, -0.093699, -0.09590492, 0.09248...   \n",
              "10  [0.13703077, -0.030081488, -0.287522, 0.172522...   \n",
              "11  [0.22309507, 0.08987352, 0.31194523, -0.271852...   \n",
              "12  [0.07300411, 0.26804006, -0.4476019, -0.004406...   \n",
              "13  [0.16173431, 0.12761247, -0.1851144, -0.293259...   \n",
              "14  [-0.10221387, -0.1314347, -0.060042597, -0.043...   \n",
              "15  [0.14504424, 0.04511755, -0.13050377, 0.081771...   \n",
              "16  [-0.1248993, 0.15603076, 0.045981072, -0.04846...   \n",
              "17  [-0.107714385, -0.31135666, -0.15398192, -0.17...   \n",
              "18  [0.02235657, 0.12525424, 0.20453936, 0.3898539...   \n",
              "19  [0.026652284, 0.018176243, 0.22643599, -0.1045...   \n",
              "\n",
              "                                   caption_triples_ls  \n",
              "0   \"In the center of the image, a vibrant blue lu...  \n",
              "1   \"This image captures a serene moment in a zoo ...  \n",
              "2   \"The image presents a serene garden scene, cen...  \n",
              "3   \"This is a detailed description of the image:-...  \n",
              "4   \"In the image, there is a woman standing in fr...  \n",
              "5   \"This image captures a serene moment of a ligh...  \n",
              "6   \"The image showcases a captivating scene of a ...  \n",
              "7   \"This image captures a fascinating scene in a ...  \n",
              "8   \"This image captures a moment in an urban sett...  \n",
              "9   \"This image captures a bustling scene at a tra...  \n",
              "10  \"This image captures a serene moment in a fore...  \n",
              "11  \"This image captures a scene of tranquility an...  \n",
              "12  \"This is a serene street scene, likely set in ...  \n",
              "13  \"This image captures a vibrant scene at a skat...  \n",
              "14  \"The image features two main objects placed on...  \n",
              "15  \"This is a photo of an **Air France Airbus A38...  \n",
              "16  \"The image is a black and white photograph cap...  \n",
              "17  \"The image depicts a well-organized kitchen sc...  \n",
              "18  \"The image presents a delightful scene of indu...  \n",
              "19  \"This image captures a vibrant scene from a Mi...  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd7KUu5AupAE"
      },
      "source": [
        "Current 20 Queries:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTAeap0Eut3C"
      },
      "source": [
        "Paragraph level granularity for Sharegpt4v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "MEco6FFyvkno",
        "outputId": "00404bf9-837f-4ca8-d5c9-d0f73c97e655"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_paragraph\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 9,\n        \"max\": 94,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          9,\n          89,\n          81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"000000000009.jpg\",\n          \"000000000089.jpg\",\n          \"000000000081.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_sharegpt4v\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid.\\n\\nIn the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\n\\nAdjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\n\\nBelow these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\n\\nFinally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\n\\nThe arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\",\n          \"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\n\\nTo the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\n\\nOn the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\n\\nThe backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. \\n\\nThe image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. \\n\\nOverall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\",\n          \"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_mscoco\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Closeup of bins of food that include broccoli and bread.\",\n          \"An oven with a stove on top of it in a kitchen.\",\n          \"A big airplane flying in the big blue sky\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_triples_ls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\\"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid.\\\"|\\\"In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\\"|\\\"Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\\"|\\\"Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\\"|\\\"Finally, in the bottom right yellow container, there is a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookies lighter surface.\\\"\",\n          \"\\\"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\\"|\\\"To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there is a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\\"|\\\"On the left side of the range, there is a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\\"|\\\"The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen.\\\"|\\\"The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone.\\\"\",\n          \"\\\"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_paragraph"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-619574db-50d8-46e3-9683-157f47d72584\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>caption_triples_ls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>000000000009.jpg</td>\n",
              "      <td>In the center of the image, a vibrant blue lun...</td>\n",
              "      <td>Closeup of bins of food that include broccoli ...</td>\n",
              "      <td>\"In the center of the image, a vibrant blue lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>000000000025.jpg</td>\n",
              "      <td>This image captures a serene moment in a zoo e...</td>\n",
              "      <td>A giraffe eating food from the top of the tree.</td>\n",
              "      <td>\"This image captures a serene moment in a zoo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>000000000030.jpg</td>\n",
              "      <td>The image presents a serene garden scene, cent...</td>\n",
              "      <td>A flower vase is sitting on a porch stand.</td>\n",
              "      <td>\"The image presents a serene garden scene, cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34</td>\n",
              "      <td>000000000034.jpg</td>\n",
              "      <td>This is a detailed description of the image:\\n...</td>\n",
              "      <td>A zebra grazing on lush green grass in a field.</td>\n",
              "      <td>\"- The image captures a **single zebra** in it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>000000000036.jpg</td>\n",
              "      <td>In the image, there is a woman standing in fro...</td>\n",
              "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
              "      <td>\"In the image, there is a woman standing in fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>42</td>\n",
              "      <td>000000000042.jpg</td>\n",
              "      <td>This image captures a serene moment of a light...</td>\n",
              "      <td>This wire metal rack holds several pairs of sh...</td>\n",
              "      <td>\"This image captures a serene moment of a ligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>000000000049.jpg</td>\n",
              "      <td>The image showcases a captivating scene of a d...</td>\n",
              "      <td>A couple of men riding horses on top of a gree...</td>\n",
              "      <td>\"The image showcases a captivating scene of a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>61</td>\n",
              "      <td>000000000061.jpg</td>\n",
              "      <td>This image captures a fascinating scene in a d...</td>\n",
              "      <td>They are brave for riding in the jungle on tho...</td>\n",
              "      <td>\"This image captures a fascinating scene in a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "      <td>000000000064.jpg</td>\n",
              "      <td>This image captures a moment in an urban setti...</td>\n",
              "      <td>a black and silver clock tower at an intersect...</td>\n",
              "      <td>\"This image captures a moment in an urban sett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>71</td>\n",
              "      <td>000000000071.jpg</td>\n",
              "      <td>This image captures a bustling scene at a trai...</td>\n",
              "      <td>A train coming to a stop on the tracks out side.</td>\n",
              "      <td>\"This image captures a bustling scene at a tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>72</td>\n",
              "      <td>000000000072.jpg</td>\n",
              "      <td>This image captures a serene moment in a fores...</td>\n",
              "      <td>A couple of giraffe snuggling each other in a ...</td>\n",
              "      <td>\"This image captures a serene moment in a fore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>73</td>\n",
              "      <td>000000000073.jpg</td>\n",
              "      <td>This image captures a scene of tranquility and...</td>\n",
              "      <td>A motorcycle parked in a parking space next to...</td>\n",
              "      <td>\"This image captures a scene of tranquility an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>74</td>\n",
              "      <td>000000000074.jpg</td>\n",
              "      <td>This is a serene street scene, likely set in I...</td>\n",
              "      <td>A picture of a dog laying on the ground.</td>\n",
              "      <td>\"This is a serene street scene, likely set in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>77</td>\n",
              "      <td>000000000077.jpg</td>\n",
              "      <td>This image captures a vibrant scene at a skate...</td>\n",
              "      <td>A young man riding a skateboard into the air.</td>\n",
              "      <td>\"This image captures a vibrant scene at a skat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>78</td>\n",
              "      <td>000000000078.jpg</td>\n",
              "      <td>The image features two main objects placed on ...</td>\n",
              "      <td>A lighted owl candle sits next to a clock.</td>\n",
              "      <td>\"The image features two main objects placed on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>81</td>\n",
              "      <td>000000000081.jpg</td>\n",
              "      <td>This is a photo of an **Air France Airbus A380...</td>\n",
              "      <td>A big airplane flying in the big blue sky</td>\n",
              "      <td>\"This is a photo of an **Air France Airbus A38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>86</td>\n",
              "      <td>000000000086.jpg</td>\n",
              "      <td>The image is a black and white photograph capt...</td>\n",
              "      <td>A man riding a motor bike across a forest.</td>\n",
              "      <td>\"The image is a black and white photograph cap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>89</td>\n",
              "      <td>000000000089.jpg</td>\n",
              "      <td>The image depicts a well-organized kitchen sce...</td>\n",
              "      <td>An oven with a stove on top of it in a kitchen.</td>\n",
              "      <td>\"The image depicts a well-organized kitchen sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>92</td>\n",
              "      <td>000000000092.jpg</td>\n",
              "      <td>The image presents a delightful scene of indul...</td>\n",
              "      <td>A white plate with a brownie and white frosting.</td>\n",
              "      <td>\"The image presents a delightful scene of indu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>94</td>\n",
              "      <td>000000000094.jpg</td>\n",
              "      <td>This image captures a vibrant scene from a Mid...</td>\n",
              "      <td>There is a street lined with packed buildings</td>\n",
              "      <td>\"This image captures a vibrant scene from a Mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-619574db-50d8-46e3-9683-157f47d72584')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-619574db-50d8-46e3-9683-157f47d72584 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-619574db-50d8-46e3-9683-157f47d72584');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-509b0e4e-d7f9-428d-93ef-a374c0d45c83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-509b0e4e-d7f9-428d-93ef-a374c0d45c83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-509b0e4e-d7f9-428d-93ef-a374c0d45c83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_046c3a4e-4d15-4e00-b282-ca9d71cce3f6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_paragraph')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_046c3a4e-4d15-4e00-b282-ca9d71cce3f6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_paragraph');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id             image                                 caption_sharegpt4v  \\\n",
              "0    9  000000000009.jpg  In the center of the image, a vibrant blue lun...   \n",
              "1   25  000000000025.jpg  This image captures a serene moment in a zoo e...   \n",
              "2   30  000000000030.jpg  The image presents a serene garden scene, cent...   \n",
              "3   34  000000000034.jpg  This is a detailed description of the image:\\n...   \n",
              "4   36  000000000036.jpg  In the image, there is a woman standing in fro...   \n",
              "5   42  000000000042.jpg  This image captures a serene moment of a light...   \n",
              "6   49  000000000049.jpg  The image showcases a captivating scene of a d...   \n",
              "7   61  000000000061.jpg  This image captures a fascinating scene in a d...   \n",
              "8   64  000000000064.jpg  This image captures a moment in an urban setti...   \n",
              "9   71  000000000071.jpg  This image captures a bustling scene at a trai...   \n",
              "10  72  000000000072.jpg  This image captures a serene moment in a fores...   \n",
              "11  73  000000000073.jpg  This image captures a scene of tranquility and...   \n",
              "12  74  000000000074.jpg  This is a serene street scene, likely set in I...   \n",
              "13  77  000000000077.jpg  This image captures a vibrant scene at a skate...   \n",
              "14  78  000000000078.jpg  The image features two main objects placed on ...   \n",
              "15  81  000000000081.jpg  This is a photo of an **Air France Airbus A380...   \n",
              "16  86  000000000086.jpg  The image is a black and white photograph capt...   \n",
              "17  89  000000000089.jpg  The image depicts a well-organized kitchen sce...   \n",
              "18  92  000000000092.jpg  The image presents a delightful scene of indul...   \n",
              "19  94  000000000094.jpg  This image captures a vibrant scene from a Mid...   \n",
              "\n",
              "                                       caption_mscoco  \\\n",
              "0   Closeup of bins of food that include broccoli ...   \n",
              "1     A giraffe eating food from the top of the tree.   \n",
              "2          A flower vase is sitting on a porch stand.   \n",
              "3     A zebra grazing on lush green grass in a field.   \n",
              "4    Woman in swim suit holding parasol on sunny day.   \n",
              "5   This wire metal rack holds several pairs of sh...   \n",
              "6   A couple of men riding horses on top of a gree...   \n",
              "7   They are brave for riding in the jungle on tho...   \n",
              "8   a black and silver clock tower at an intersect...   \n",
              "9    A train coming to a stop on the tracks out side.   \n",
              "10  A couple of giraffe snuggling each other in a ...   \n",
              "11  A motorcycle parked in a parking space next to...   \n",
              "12           A picture of a dog laying on the ground.   \n",
              "13      A young man riding a skateboard into the air.   \n",
              "14         A lighted owl candle sits next to a clock.   \n",
              "15          A big airplane flying in the big blue sky   \n",
              "16         A man riding a motor bike across a forest.   \n",
              "17    An oven with a stove on top of it in a kitchen.   \n",
              "18   A white plate with a brownie and white frosting.   \n",
              "19      There is a street lined with packed buildings   \n",
              "\n",
              "                                   caption_triples_ls  \n",
              "0   \"In the center of the image, a vibrant blue lu...  \n",
              "1   \"This image captures a serene moment in a zoo ...  \n",
              "2   \"The image presents a serene garden scene, cen...  \n",
              "3   \"- The image captures a **single zebra** in it...  \n",
              "4   \"In the image, there is a woman standing in fr...  \n",
              "5   \"This image captures a serene moment of a ligh...  \n",
              "6   \"The image showcases a captivating scene of a ...  \n",
              "7   \"This image captures a fascinating scene in a ...  \n",
              "8   \"This image captures a moment in an urban sett...  \n",
              "9   \"This image captures a bustling scene at a tra...  \n",
              "10  \"This image captures a serene moment in a fore...  \n",
              "11  \"This image captures a scene of tranquility an...  \n",
              "12  \"This is a serene street scene, likely set in ...  \n",
              "13  \"This image captures a vibrant scene at a skat...  \n",
              "14  \"The image features two main objects placed on...  \n",
              "15  \"This is a photo of an **Air France Airbus A38...  \n",
              "16  \"The image is a black and white photograph cap...  \n",
              "17  \"The image depicts a well-organized kitchen sc...  \n",
              "18  \"The image presents a delightful scene of indu...  \n",
              "19  \"This image captures a vibrant scene from a Mi...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_caption_file_name = '/content/drive/MyDrive/sharegpt4v_imgpaths_paragraph_20queries.pkl'\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  df_paragraph = pickle.load(f)\n",
        "df_paragraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EC68TXNuwEC"
      },
      "source": [
        "Patches 2 and 4 granularity for Sharegpt4v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "c-Ub2KcXuzGo",
        "outputId": "27dd311e-9a41-4c3a-c0cc-25d5dd5bace4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_patch_24\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 9,\n        \"max\": 94,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          9,\n          89,\n          81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"000000000009.jpg\",\n          \"000000000089.jpg\",\n          \"000000000081.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_sharegpt4v\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid.\\n\\nIn the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\n\\nAdjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\n\\nBelow these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\n\\nFinally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\n\\nThe arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\",\n          \"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\n\\nTo the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\n\\nOn the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\n\\nThe backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. \\n\\nThe image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. \\n\\nOverall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\",\n          \"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_mscoco\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Closeup of bins of food that include broccoli and bread.\",\n          \"An oven with a stove on top of it in a kitchen.\",\n          \"A big airplane flying in the big blue sky\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_triples_ls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\\"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid.\\\"|\\\"The containers, two in pink and two in yellow, are arranged in a 2x2 grid. In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds.\\\"|\\\"In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\\"|\\\"The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit.\\\"|\\\"Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple.\\\"|\\\"Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\\"|\\\"The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli.\\\"|\\\"Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\\"|\\\"The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie.\\\"|\\\"Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\\"|\\\"The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface. The arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\\\" # \\\"In the center of the image, a vibrant blue lunch tray holds four containers, each brimming with a variety of food items. The containers, two in pink and two in yellow, are arranged in a 2x2 grid. In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface.\\\"|\\\"The containers, two in pink and two in yellow, are arranged in a 2x2 grid. In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit.\\\"|\\\"In the top left pink container, a slice of bread rests, lightly spread with butter and sprinkled with a handful of almonds. The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple.\\\"|\\\"The bread is cut into a rectangle, and the almonds are scattered across its buttery surface. Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container.\\\"|\\\"Adjacent to it in the top right corner, another pink container houses a mix of fruit. Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli.\\\"|\\\"Sliced apples with their fresh white interiors exposed share the space with juicy chunks of pineapple. The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets.\\\"|\\\"The colors of the apple slices and pineapple chunks contrast beautifully against the pink container. Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie.\\\"|\\\"Below these, in the bottom left corner of the tray, a yellow container holds a single meatball alongside some broccoli. The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface.\\\"|\\\"The meatball, round and browned, sits next to the vibrant green broccoli florets. Finally, in the bottom right yellow container, there's a sweet treat - a chocolate chip cookie. The golden-brown cookie is dotted with chocolate chips, their dark color standing out against the cookie's lighter surface. The arrangement of these containers on the blue tray creates a visually appealing and balanced meal, with each component neatly separated yet part of a cohesive whole.\\\"\",\n          \"\\\"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**.\\\"|\\\"The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel.\\\"|\\\"The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\\"|\\\"The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall.\\\"|\\\"To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\\"|\\\"Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\\"|\\\"On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen.\\\"|\\\"The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone.\\\"|\\\"The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. Overall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\\\" # \\\"The image depicts a well-organized kitchen scene. The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door.\\\"|\\\"The primary focus is a **white electric range and oven**. The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall.\\\"|\\\"The range features **four burners** and a **digital clock** on the back panel. The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal.\\\"|\\\"The oven below has a **window** and a **handle** on its door. To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting.\\\"|\\\"To the right of the range, a **set of knives** is neatly arranged, hanging on the wall. Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen.\\\"|\\\"Adjacent to it on the counter, there's a **cookbook** open, perhaps suggesting someone is preparing to cook a meal. On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone.\\\"|\\\"On the left side of the range, there's a **black telephone** mounted on the wall, adding a touch of vintage charm to the setting. The backdrop for these items is a **white tile backsplash**, providing a clean and bright atmosphere to the kitchen. The image also contains an OCR text reading \\\"**03 22 2010 13 21**\\\", but its relevance to the kitchen scene is not clear from the image alone. Overall, this kitchen scene suggests preparation for cooking, with tools and appliances neatly arranged and ready for use.\\\"\",\n          \"\\\"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail.\\\"|\\\"The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image.\\\"|\\\"The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft.\\\"|\\\"The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\\\" # \\\"This is a photo of an **Air France Airbus A380-800** in flight. The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft.\\\"|\\\"The aircraft is predominantly **white** with **blue and red stripes** on the tail. The aircraft has **four engines** and is captured flying from left to right in the image. The background is a cloudy sky, providing a stark contrast to the aircraft. The words \\\"**Air France**\\\" are visible on the aircraft, indicating its airline affiliation.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_patch_24"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5675341a-a575-41de-b96f-fc414649ccd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>caption_triples_ls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>000000000009.jpg</td>\n",
              "      <td>In the center of the image, a vibrant blue lun...</td>\n",
              "      <td>Closeup of bins of food that include broccoli ...</td>\n",
              "      <td>\"In the center of the image, a vibrant blue lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>000000000025.jpg</td>\n",
              "      <td>This image captures a serene moment in a zoo e...</td>\n",
              "      <td>A giraffe eating food from the top of the tree.</td>\n",
              "      <td>\"This image captures a serene moment in a zoo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>000000000030.jpg</td>\n",
              "      <td>The image presents a serene garden scene, cent...</td>\n",
              "      <td>A flower vase is sitting on a porch stand.</td>\n",
              "      <td>\"The image presents a serene garden scene, cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34</td>\n",
              "      <td>000000000034.jpg</td>\n",
              "      <td>This is a detailed description of the image:\\n...</td>\n",
              "      <td>A zebra grazing on lush green grass in a field.</td>\n",
              "      <td>\"This is a detailed description of the image:-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>000000000036.jpg</td>\n",
              "      <td>In the image, there is a woman standing in fro...</td>\n",
              "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
              "      <td>\"In the image, there is a woman standing in fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>42</td>\n",
              "      <td>000000000042.jpg</td>\n",
              "      <td>This image captures a serene moment of a light...</td>\n",
              "      <td>This wire metal rack holds several pairs of sh...</td>\n",
              "      <td>\"This image captures a serene moment of a ligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>000000000049.jpg</td>\n",
              "      <td>The image showcases a captivating scene of a d...</td>\n",
              "      <td>A couple of men riding horses on top of a gree...</td>\n",
              "      <td>\"The image showcases a captivating scene of a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>61</td>\n",
              "      <td>000000000061.jpg</td>\n",
              "      <td>This image captures a fascinating scene in a d...</td>\n",
              "      <td>They are brave for riding in the jungle on tho...</td>\n",
              "      <td>\"This image captures a fascinating scene in a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "      <td>000000000064.jpg</td>\n",
              "      <td>This image captures a moment in an urban setti...</td>\n",
              "      <td>a black and silver clock tower at an intersect...</td>\n",
              "      <td>\"This image captures a moment in an urban sett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>71</td>\n",
              "      <td>000000000071.jpg</td>\n",
              "      <td>This image captures a bustling scene at a trai...</td>\n",
              "      <td>A train coming to a stop on the tracks out side.</td>\n",
              "      <td>\"This image captures a bustling scene at a tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>72</td>\n",
              "      <td>000000000072.jpg</td>\n",
              "      <td>This image captures a serene moment in a fores...</td>\n",
              "      <td>A couple of giraffe snuggling each other in a ...</td>\n",
              "      <td>\"This image captures a serene moment in a fore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>73</td>\n",
              "      <td>000000000073.jpg</td>\n",
              "      <td>This image captures a scene of tranquility and...</td>\n",
              "      <td>A motorcycle parked in a parking space next to...</td>\n",
              "      <td>\"This image captures a scene of tranquility an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>74</td>\n",
              "      <td>000000000074.jpg</td>\n",
              "      <td>This is a serene street scene, likely set in I...</td>\n",
              "      <td>A picture of a dog laying on the ground.</td>\n",
              "      <td>\"This is a serene street scene, likely set in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>77</td>\n",
              "      <td>000000000077.jpg</td>\n",
              "      <td>This image captures a vibrant scene at a skate...</td>\n",
              "      <td>A young man riding a skateboard into the air.</td>\n",
              "      <td>\"This image captures a vibrant scene at a skat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>78</td>\n",
              "      <td>000000000078.jpg</td>\n",
              "      <td>The image features two main objects placed on ...</td>\n",
              "      <td>A lighted owl candle sits next to a clock.</td>\n",
              "      <td>\"The image features two main objects placed on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>81</td>\n",
              "      <td>000000000081.jpg</td>\n",
              "      <td>This is a photo of an **Air France Airbus A380...</td>\n",
              "      <td>A big airplane flying in the big blue sky</td>\n",
              "      <td>\"This is a photo of an **Air France Airbus A38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>86</td>\n",
              "      <td>000000000086.jpg</td>\n",
              "      <td>The image is a black and white photograph capt...</td>\n",
              "      <td>A man riding a motor bike across a forest.</td>\n",
              "      <td>\"The image is a black and white photograph cap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>89</td>\n",
              "      <td>000000000089.jpg</td>\n",
              "      <td>The image depicts a well-organized kitchen sce...</td>\n",
              "      <td>An oven with a stove on top of it in a kitchen.</td>\n",
              "      <td>\"The image depicts a well-organized kitchen sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>92</td>\n",
              "      <td>000000000092.jpg</td>\n",
              "      <td>The image presents a delightful scene of indul...</td>\n",
              "      <td>A white plate with a brownie and white frosting.</td>\n",
              "      <td>\"The image presents a delightful scene of indu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>94</td>\n",
              "      <td>000000000094.jpg</td>\n",
              "      <td>This image captures a vibrant scene from a Mid...</td>\n",
              "      <td>There is a street lined with packed buildings</td>\n",
              "      <td>\"This image captures a vibrant scene from a Mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5675341a-a575-41de-b96f-fc414649ccd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5675341a-a575-41de-b96f-fc414649ccd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5675341a-a575-41de-b96f-fc414649ccd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6292fab8-63d5-4a37-9542-2b5e878ce07e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6292fab8-63d5-4a37-9542-2b5e878ce07e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6292fab8-63d5-4a37-9542-2b5e878ce07e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_47bb52e6-08ed-4696-8096-28d3c637e3d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_patch_24')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_47bb52e6-08ed-4696-8096-28d3c637e3d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_patch_24');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id             image                                 caption_sharegpt4v  \\\n",
              "0    9  000000000009.jpg  In the center of the image, a vibrant blue lun...   \n",
              "1   25  000000000025.jpg  This image captures a serene moment in a zoo e...   \n",
              "2   30  000000000030.jpg  The image presents a serene garden scene, cent...   \n",
              "3   34  000000000034.jpg  This is a detailed description of the image:\\n...   \n",
              "4   36  000000000036.jpg  In the image, there is a woman standing in fro...   \n",
              "5   42  000000000042.jpg  This image captures a serene moment of a light...   \n",
              "6   49  000000000049.jpg  The image showcases a captivating scene of a d...   \n",
              "7   61  000000000061.jpg  This image captures a fascinating scene in a d...   \n",
              "8   64  000000000064.jpg  This image captures a moment in an urban setti...   \n",
              "9   71  000000000071.jpg  This image captures a bustling scene at a trai...   \n",
              "10  72  000000000072.jpg  This image captures a serene moment in a fores...   \n",
              "11  73  000000000073.jpg  This image captures a scene of tranquility and...   \n",
              "12  74  000000000074.jpg  This is a serene street scene, likely set in I...   \n",
              "13  77  000000000077.jpg  This image captures a vibrant scene at a skate...   \n",
              "14  78  000000000078.jpg  The image features two main objects placed on ...   \n",
              "15  81  000000000081.jpg  This is a photo of an **Air France Airbus A380...   \n",
              "16  86  000000000086.jpg  The image is a black and white photograph capt...   \n",
              "17  89  000000000089.jpg  The image depicts a well-organized kitchen sce...   \n",
              "18  92  000000000092.jpg  The image presents a delightful scene of indul...   \n",
              "19  94  000000000094.jpg  This image captures a vibrant scene from a Mid...   \n",
              "\n",
              "                                       caption_mscoco  \\\n",
              "0   Closeup of bins of food that include broccoli ...   \n",
              "1     A giraffe eating food from the top of the tree.   \n",
              "2          A flower vase is sitting on a porch stand.   \n",
              "3     A zebra grazing on lush green grass in a field.   \n",
              "4    Woman in swim suit holding parasol on sunny day.   \n",
              "5   This wire metal rack holds several pairs of sh...   \n",
              "6   A couple of men riding horses on top of a gree...   \n",
              "7   They are brave for riding in the jungle on tho...   \n",
              "8   a black and silver clock tower at an intersect...   \n",
              "9    A train coming to a stop on the tracks out side.   \n",
              "10  A couple of giraffe snuggling each other in a ...   \n",
              "11  A motorcycle parked in a parking space next to...   \n",
              "12           A picture of a dog laying on the ground.   \n",
              "13      A young man riding a skateboard into the air.   \n",
              "14         A lighted owl candle sits next to a clock.   \n",
              "15          A big airplane flying in the big blue sky   \n",
              "16         A man riding a motor bike across a forest.   \n",
              "17    An oven with a stove on top of it in a kitchen.   \n",
              "18   A white plate with a brownie and white frosting.   \n",
              "19      There is a street lined with packed buildings   \n",
              "\n",
              "                                   caption_triples_ls  \n",
              "0   \"In the center of the image, a vibrant blue lu...  \n",
              "1   \"This image captures a serene moment in a zoo ...  \n",
              "2   \"The image presents a serene garden scene, cen...  \n",
              "3   \"This is a detailed description of the image:-...  \n",
              "4   \"In the image, there is a woman standing in fr...  \n",
              "5   \"This image captures a serene moment of a ligh...  \n",
              "6   \"The image showcases a captivating scene of a ...  \n",
              "7   \"This image captures a fascinating scene in a ...  \n",
              "8   \"This image captures a moment in an urban sett...  \n",
              "9   \"This image captures a bustling scene at a tra...  \n",
              "10  \"This image captures a serene moment in a fore...  \n",
              "11  \"This image captures a scene of tranquility an...  \n",
              "12  \"This is a serene street scene, likely set in ...  \n",
              "13  \"This image captures a vibrant scene at a skat...  \n",
              "14  \"The image features two main objects placed on...  \n",
              "15  \"This is a photo of an **Air France Airbus A38...  \n",
              "16  \"The image is a black and white photograph cap...  \n",
              "17  \"The image depicts a well-organized kitchen sc...  \n",
              "18  \"The image presents a delightful scene of indu...  \n",
              "19  \"This image captures a vibrant scene from a Mi...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_caption_file_name = '/content/drive/MyDrive/sharegpt4v_imgpaths_patch_2_4_20queries.pkl'\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  df_patch_24 = pickle.load(f)\n",
        "df_patch_24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GTET_a0u1Ju"
      },
      "source": [
        "20 long MSCOCO original queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lHoPCictu4Ur",
        "outputId": "fecca485-25c6-462c-cf02-edb7f7a3b556"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_20_mscoco\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 162070,\n        \"min\": 39270,\n        \"max\": 581670,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          553992,\n          331186,\n          449517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"000000553992.jpg\",\n          \"000000331186.jpg\",\n          \"000000449517.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_sharegpt4v\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"In the image, a man and a woman are standing in a room with beige walls and a white ceiling. The man, dressed in a blue shirt and khaki pants, is pointing at a red exit sign. The woman, wearing a red shirt, is attentively looking at the man. In the background, there's a television mounted on the wall. On the floor next to the television, there's a stack of red chairs.\",\n          \"The image captures a dynamic sequence of a skateboarder in action. The skateboarder, dressed in a vibrant red plaid shirt and black pants, is the central figure in each of the three photos that make up this collage.\\n\\nIn the first photo, the skateboarder is in the midst of pushing off with their left foot, sending the skateboard into motion. The skateboard, with its green wheels and black deck, is clearly visible.\\n\\nThe second photo shows the skateboarder in the middle of a trick. They are balancing on one foot on the skateboard while the other foot is suspended in the air, adding an element of suspense to the scene.\\n\\nIn the third and final photo, the skateboarder has completed their trick. They are now balancing on both feet on the skateboard, demonstrating their skill and control.\\n\\nEach photo is taken from a low angle, looking up at the skateboarder, which adds a sense of scale and drama to the sequence. The background in all three photos is a clear blue sky, providing a stark contrast to the skateboarder's colorful attire and the green wheels of the skateboard.\",\n          \"This is a black and white photograph capturing a moment in a workshop. Two men are engaged in their work, surrounded by the tools of their trade. The man on the left is standing, donned in a black shirt and pants, holding a hammer in his hand. His gaze is directed towards the man on the right, who is kneeling on the ground. This man is wearing a white shirt and pants, and he is holding a pair of pliers. The horse, standing on the right side of the image, seems to be observing the scene. The workshop is filled with various tools and equipment, indicating a space dedicated to manual labor and craftsmanship.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_mscoco\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"An institutional looking room holds an exit sign, chairs, recording equipment and a man with one arm aloft that appears to be demonstrating something with a device in the held-up hand for the benefit of a woman behind him that is watching closely.  \",\n          \"In the first picture a boy is flipping his skateboard, in the second picture is skating and lifting the board slightly off the ground, and in the third he is jumping into the air onto the skateboard.\",\n          \"Black and white of a blacksmith interior with a horse, a man standing with arm out to it, and a man ducking under it's head and holding a long metal file in both hands, with horses on poles on the wall.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_triples_ls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\\"An institutional looking room holds an exit sign.\\\"|\\\"An institutional looking room has chairs.\\\"|\\\"An institutional looking room has recording equipment.\\\"|\\\"A man with one arm aloft appears to be demonstrating with a device in the held-up hand.\\\"|\\\"A woman behind a man is watching him closely.\\\"\",\n          \"\\\"A boy is flipping his skateboard.\\\"|\\\"A boy is skating and lifting the board slightly off the ground.\\\"|\\\"A boy is jumping into the air onto the skateboard.\\\"\",\n          \"\\\"Black and white of a blacksmith interior with a horse.\\\"|\\\"Black and white with a man standing with arm out to a horse.\\\"|\\\"Black and white of a man ducking under a horses head and holding a long metal file in both hands.\\\"|\\\"Black and white of a blacksmith interior with horses on poles on the wall.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_20_mscoco"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7e6720d4-3afb-4e96-826f-94f951bf0f73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>caption_sharegpt4v</th>\n",
              "      <th>caption_mscoco</th>\n",
              "      <th>caption_triples_ls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>553992</td>\n",
              "      <td>000000553992.jpg</td>\n",
              "      <td>In the image, a man and a woman are standing i...</td>\n",
              "      <td>An institutional looking room holds an exit si...</td>\n",
              "      <td>\"An institutional looking room holds an exit s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39270</td>\n",
              "      <td>000000039270.jpg</td>\n",
              "      <td>In the image, there is a man who is in the mid...</td>\n",
              "      <td>Black night, a blurry shot shows a tall fence ...</td>\n",
              "      <td>\"In a black night, a blurry shot shows a tall ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>277161</td>\n",
              "      <td>000000277161.jpg</td>\n",
              "      <td>In the center of the image, a vintage Apple II...</td>\n",
              "      <td>An older looking model computer components; tw...</td>\n",
              "      <td>\"An older looking model computer components.\"|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380070</td>\n",
              "      <td>000000380070.jpg</td>\n",
              "      <td>The image captures a cozy hotel room, bathed i...</td>\n",
              "      <td>A motel-like room  features all of its furnitu...</td>\n",
              "      <td>\"A motel-like room features all of its furnitu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>357272</td>\n",
              "      <td>000000357272.jpg</td>\n",
              "      <td>The image captures a room that exudes a vintag...</td>\n",
              "      <td>A room shows a twin bed, crib, double bed, and...</td>\n",
              "      <td>\"A twin bed.\"|\"A crib.\"|\"A double bed.\"|\"A rou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>480770</td>\n",
              "      <td>000000480770.jpg</td>\n",
              "      <td>In the heart of a bustling city, an elderly wo...</td>\n",
              "      <td>A street view shows a building entrance and tr...</td>\n",
              "      <td>\"A street view shows a building entrance.\"|\"A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>515241</td>\n",
              "      <td>000000515241.jpg</td>\n",
              "      <td>The image captures a dynamic moment in a baseb...</td>\n",
              "      <td>Off in the distance, a few people dot the stan...</td>\n",
              "      <td>\"Off in the distance, a few people dot the sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>560604</td>\n",
              "      <td>000000560604.jpg</td>\n",
              "      <td>In the center of the image, a black stuffed an...</td>\n",
              "      <td>A counter top with a plate with a fork and few...</td>\n",
              "      <td>\"A counter top with a plate with a fork and a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>158005</td>\n",
              "      <td>000000158005.jpg</td>\n",
              "      <td>In the dimly lit ambiance of the room, a dinne...</td>\n",
              "      <td>Indirect lighting in a darkened room plays acr...</td>\n",
              "      <td>\"Indirect lighting in a darkened room shines a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>449712</td>\n",
              "      <td>000000449712.jpg</td>\n",
              "      <td>In the image, a group of people are seen walki...</td>\n",
              "      <td>the long view of a parking lot shows a row of ...</td>\n",
              "      <td>\"The long view of a parking lot shows a row of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>132077</td>\n",
              "      <td>000000132077.jpg</td>\n",
              "      <td>In the center of the image, a person wearing a...</td>\n",
              "      <td>Corner view of a table with plaid cloth, red a...</td>\n",
              "      <td>\"Corner view of a table with plaid cloth.\"|\"A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>577590</td>\n",
              "      <td>000000577590.jpg</td>\n",
              "      <td>The image captures a serene and cozy bedroom s...</td>\n",
              "      <td>A room with natural, unfinished, pale wood wal...</td>\n",
              "      <td>\"A room with natural, unfinished, pale wood wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>441535</td>\n",
              "      <td>000000441535.jpg</td>\n",
              "      <td>The image captures a serene and cozy bedroom s...</td>\n",
              "      <td>A minimally furnished room shows small window ...</td>\n",
              "      <td>\"A minimally furnished room shows small window...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>421777</td>\n",
              "      <td>000000421777.jpg</td>\n",
              "      <td>The image captures a bustling night scene on a...</td>\n",
              "      <td>A blurry night-time street scene shows a highe...</td>\n",
              "      <td>\"A blurry night-time street scene shows a high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>130245</td>\n",
              "      <td>000000130245.jpg</td>\n",
              "      <td>The image captures a dynamic moment in a tenni...</td>\n",
              "      <td>Several people are standing, or sitting, in th...</td>\n",
              "      <td>\"Several people are standing, or sitting, in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>449517</td>\n",
              "      <td>000000449517.jpg</td>\n",
              "      <td>This is a black and white photograph capturing...</td>\n",
              "      <td>Black and white of a blacksmith interior with ...</td>\n",
              "      <td>\"Black and white of a blacksmith interior with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>278313</td>\n",
              "      <td>000000278313.jpg</td>\n",
              "      <td>The image captures a cozy living room scene, b...</td>\n",
              "      <td>A blurry living room scene suggests a wide scr...</td>\n",
              "      <td>\"A blurry living room scene suggests a wide sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>331186</td>\n",
              "      <td>000000331186.jpg</td>\n",
              "      <td>The image captures a dynamic sequence of a ska...</td>\n",
              "      <td>In the first picture a boy is flipping his ska...</td>\n",
              "      <td>\"A boy is flipping his skateboard.\"|\"A boy is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>581670</td>\n",
              "      <td>000000581670.jpg</td>\n",
              "      <td>The image captures a moment of tranquility at ...</td>\n",
              "      <td>A table with a person holding a sandwich in ha...</td>\n",
              "      <td>\"A table with a person holding a sandwich in h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>355967</td>\n",
              "      <td>000000355967.jpg</td>\n",
              "      <td>The image captures a vibrant scene on a sunny ...</td>\n",
              "      <td>An impressive array of motorcycles recedes int...</td>\n",
              "      <td>\"An impressive array of motorcycles recedes in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e6720d4-3afb-4e96-826f-94f951bf0f73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e6720d4-3afb-4e96-826f-94f951bf0f73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e6720d4-3afb-4e96-826f-94f951bf0f73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1ae25a5-56f4-4715-9a2e-8b83fc4baaba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1ae25a5-56f4-4715-9a2e-8b83fc4baaba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1ae25a5-56f4-4715-9a2e-8b83fc4baaba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_afa91461-a295-4d68-893f-a91a4f61c17a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_20_mscoco')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_afa91461-a295-4d68-893f-a91a4f61c17a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_20_mscoco');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        id             image  \\\n",
              "0   553992  000000553992.jpg   \n",
              "1    39270  000000039270.jpg   \n",
              "2   277161  000000277161.jpg   \n",
              "3   380070  000000380070.jpg   \n",
              "4   357272  000000357272.jpg   \n",
              "5   480770  000000480770.jpg   \n",
              "6   515241  000000515241.jpg   \n",
              "7   560604  000000560604.jpg   \n",
              "8   158005  000000158005.jpg   \n",
              "9   449712  000000449712.jpg   \n",
              "10  132077  000000132077.jpg   \n",
              "11  577590  000000577590.jpg   \n",
              "12  441535  000000441535.jpg   \n",
              "13  421777  000000421777.jpg   \n",
              "14  130245  000000130245.jpg   \n",
              "15  449517  000000449517.jpg   \n",
              "16  278313  000000278313.jpg   \n",
              "17  331186  000000331186.jpg   \n",
              "18  581670  000000581670.jpg   \n",
              "19  355967  000000355967.jpg   \n",
              "\n",
              "                                   caption_sharegpt4v  \\\n",
              "0   In the image, a man and a woman are standing i...   \n",
              "1   In the image, there is a man who is in the mid...   \n",
              "2   In the center of the image, a vintage Apple II...   \n",
              "3   The image captures a cozy hotel room, bathed i...   \n",
              "4   The image captures a room that exudes a vintag...   \n",
              "5   In the heart of a bustling city, an elderly wo...   \n",
              "6   The image captures a dynamic moment in a baseb...   \n",
              "7   In the center of the image, a black stuffed an...   \n",
              "8   In the dimly lit ambiance of the room, a dinne...   \n",
              "9   In the image, a group of people are seen walki...   \n",
              "10  In the center of the image, a person wearing a...   \n",
              "11  The image captures a serene and cozy bedroom s...   \n",
              "12  The image captures a serene and cozy bedroom s...   \n",
              "13  The image captures a bustling night scene on a...   \n",
              "14  The image captures a dynamic moment in a tenni...   \n",
              "15  This is a black and white photograph capturing...   \n",
              "16  The image captures a cozy living room scene, b...   \n",
              "17  The image captures a dynamic sequence of a ska...   \n",
              "18  The image captures a moment of tranquility at ...   \n",
              "19  The image captures a vibrant scene on a sunny ...   \n",
              "\n",
              "                                       caption_mscoco  \\\n",
              "0   An institutional looking room holds an exit si...   \n",
              "1   Black night, a blurry shot shows a tall fence ...   \n",
              "2   An older looking model computer components; tw...   \n",
              "3   A motel-like room  features all of its furnitu...   \n",
              "4   A room shows a twin bed, crib, double bed, and...   \n",
              "5   A street view shows a building entrance and tr...   \n",
              "6   Off in the distance, a few people dot the stan...   \n",
              "7   A counter top with a plate with a fork and few...   \n",
              "8   Indirect lighting in a darkened room plays acr...   \n",
              "9   the long view of a parking lot shows a row of ...   \n",
              "10  Corner view of a table with plaid cloth, red a...   \n",
              "11  A room with natural, unfinished, pale wood wal...   \n",
              "12  A minimally furnished room shows small window ...   \n",
              "13  A blurry night-time street scene shows a highe...   \n",
              "14  Several people are standing, or sitting, in th...   \n",
              "15  Black and white of a blacksmith interior with ...   \n",
              "16  A blurry living room scene suggests a wide scr...   \n",
              "17  In the first picture a boy is flipping his ska...   \n",
              "18  A table with a person holding a sandwich in ha...   \n",
              "19  An impressive array of motorcycles recedes int...   \n",
              "\n",
              "                                   caption_triples_ls  \n",
              "0   \"An institutional looking room holds an exit s...  \n",
              "1   \"In a black night, a blurry shot shows a tall ...  \n",
              "2   \"An older looking model computer components.\"|...  \n",
              "3   \"A motel-like room features all of its furnitu...  \n",
              "4   \"A twin bed.\"|\"A crib.\"|\"A double bed.\"|\"A rou...  \n",
              "5   \"A street view shows a building entrance.\"|\"A ...  \n",
              "6   \"Off in the distance, a few people dot the sta...  \n",
              "7   \"A counter top with a plate with a fork and a ...  \n",
              "8   \"Indirect lighting in a darkened room shines a...  \n",
              "9   \"The long view of a parking lot shows a row of...  \n",
              "10  \"Corner view of a table with plaid cloth.\"|\"A ...  \n",
              "11  \"A room with natural, unfinished, pale wood wa...  \n",
              "12  \"A minimally furnished room shows small window...  \n",
              "13  \"A blurry night-time street scene shows a high...  \n",
              "14  \"Several people are standing, or sitting, in t...  \n",
              "15  \"Black and white of a blacksmith interior with...  \n",
              "16  \"A blurry living room scene suggests a wide sc...  \n",
              "17  \"A boy is flipping his skateboard.\"|\"A boy is ...  \n",
              "18  \"A table with a person holding a sandwich in h...  \n",
              "19  \"An impressive array of motorcycles recedes in...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_caption_file_name = '/content/drive/MyDrive/mscoco_imgpaths_longest_20queries.pkl'\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  df_20_mscoco = pickle.load(f)\n",
        "df_20_mscoco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE1LxuqTu5i2"
      },
      "source": [
        "Example command on how to run the experiments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIRP1Io8u67D",
        "outputId": "a4c67caa-bb5d-422c-89ac-50c9e35d3222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:34:08.212386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:34:08.212421: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "config.json: 100% 4.52k/4.52k [00:00<00:00, 25.2MB/s]\n",
            "model.safetensors: 100% 1.71G/1.71G [00:04<00:00, 426MB/s]\n",
            "preprocessor_config.json: 100% 316/316 [00:00<00:00, 2.46MB/s]\n",
            "tokenizer_config.json: 100% 905/905 [00:00<00:00, 7.52MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "vocab.json: 100% 961k/961k [00:00<00:00, 4.01MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 49.5MB/s]\n",
            "tokenizer.json: 100% 2.22M/2.22M [00:01<00:00, 1.12MB/s]\n",
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.78MB/s]\n",
            "20it [00:02,  7.61it/s]\n",
            "20it [03:26, 10.33s/it]\n",
            "100% 20/20 [00:00<00:00, 769.61it/s]\n",
            "100% 20/20 [00:02<00:00,  7.43it/s]\n",
            "2024-06-03 16:38:41 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:38:41 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "modules.json: 100% 229/229 [00:00<00:00, 1.79MB/s]\n",
            "config_sentence_transformers.json: 100% 122/122 [00:00<00:00, 964kB/s]\n",
            "README.md: 100% 4.02k/4.02k [00:00<00:00, 31.5MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 372kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 548/548 [00:00<00:00, 4.23MB/s]\n",
            "model.safetensors: 100% 265M/265M [00:01<00:00, 251MB/s]\n",
            "tokenizer_config.json: 100% 547/547 [00:00<00:00, 4.27MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 33.7MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 57.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 934kB/s]\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.18MB/s]\n",
            "results with decomposition::\n",
            "2024-06-03 16:38:50 - Encoding Queries...\n",
            "2024-06-03 16:38:50 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:38:50 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:38:50 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:01<00:00, 10.04it/s]\n",
            "Time taken: 2.01s\n",
            "2024-06-03 16:38:52 - \n",
            "\n",
            "2024-06-03 16:38:52 - NDCG@1: 1.0000\n",
            "2024-06-03 16:38:52 - NDCG@3: 1.0000\n",
            "2024-06-03 16:38:52 - NDCG@5: 1.0000\n",
            "2024-06-03 16:38:52 - NDCG@10: 1.0000\n",
            "2024-06-03 16:38:52 - NDCG@100: 1.0000\n",
            "2024-06-03 16:38:52 - NDCG@1000: 1.0000\n",
            "2024-06-03 16:38:52 - \n",
            "\n",
            "2024-06-03 16:38:52 - MAP@1: 1.0000\n",
            "2024-06-03 16:38:52 - MAP@3: 1.0000\n",
            "2024-06-03 16:38:52 - MAP@5: 1.0000\n",
            "2024-06-03 16:38:52 - MAP@10: 1.0000\n",
            "2024-06-03 16:38:52 - MAP@100: 1.0000\n",
            "2024-06-03 16:38:52 - MAP@1000: 1.0000\n",
            "2024-06-03 16:38:52 - \n",
            "\n",
            "2024-06-03 16:38:52 - Recall@1: 1.0000\n",
            "2024-06-03 16:38:52 - Recall@3: 1.0000\n",
            "2024-06-03 16:38:52 - Recall@5: 1.0000\n",
            "2024-06-03 16:38:52 - Recall@10: 1.0000\n",
            "2024-06-03 16:38:52 - Recall@100: 1.0000\n",
            "2024-06-03 16:38:52 - Recall@1000: 1.0000\n",
            "2024-06-03 16:38:52 - \n",
            "\n",
            "2024-06-03 16:38:52 - P@1: 1.0000\n",
            "2024-06-03 16:38:52 - P@3: 0.3333\n",
            "2024-06-03 16:38:52 - P@5: 0.2000\n",
            "2024-06-03 16:38:52 - P@10: 0.1000\n",
            "2024-06-03 16:38:52 - P@100: 0.0100\n",
            "2024-06-03 16:38:52 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_sharegpt4v_4_8_16_32_64_128_subset_20_query_img.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name sharegpt4v --data_path /content/drive/MyDrive/sharegpt4v_imgpaths_patch_2_4_20queries.pkl --query_count -1 --total_count 20 --img_concept --query_concept --dataset_path /content/drive/MyDrive/mscoco_120k.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNzgobf46qVr",
        "outputId": "05284856-5951-4568-8a70-d9c16aeac779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:39:10.926204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:39:10.926235: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "20it [00:00, 243.59it/s]\n",
            "2024-06-03 16:39:21 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:39:21 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "results with decomposition::\n",
            "2024-06-03 16:39:23 - Encoding Queries...\n",
            "2024-06-03 16:39:23 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:39:23 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:39:23 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:00<00:00, 131.01it/s]\n",
            "Time taken: 0.26s\n",
            "2024-06-03 16:39:24 - \n",
            "\n",
            "2024-06-03 16:39:24 - NDCG@1: 0.9500\n",
            "2024-06-03 16:39:24 - NDCG@3: 0.9816\n",
            "2024-06-03 16:39:24 - NDCG@5: 0.9816\n",
            "2024-06-03 16:39:24 - NDCG@10: 0.9816\n",
            "2024-06-03 16:39:24 - NDCG@100: 0.9816\n",
            "2024-06-03 16:39:24 - NDCG@1000: 0.9816\n",
            "2024-06-03 16:39:24 - \n",
            "\n",
            "2024-06-03 16:39:24 - MAP@1: 0.9500\n",
            "2024-06-03 16:39:24 - MAP@3: 0.9750\n",
            "2024-06-03 16:39:24 - MAP@5: 0.9750\n",
            "2024-06-03 16:39:24 - MAP@10: 0.9750\n",
            "2024-06-03 16:39:24 - MAP@100: 0.9750\n",
            "2024-06-03 16:39:24 - MAP@1000: 0.9750\n",
            "2024-06-03 16:39:24 - \n",
            "\n",
            "2024-06-03 16:39:24 - Recall@1: 0.9500\n",
            "2024-06-03 16:39:24 - Recall@3: 1.0000\n",
            "2024-06-03 16:39:24 - Recall@5: 1.0000\n",
            "2024-06-03 16:39:24 - Recall@10: 1.0000\n",
            "2024-06-03 16:39:24 - Recall@100: 1.0000\n",
            "2024-06-03 16:39:24 - Recall@1000: 1.0000\n",
            "2024-06-03 16:39:24 - \n",
            "\n",
            "2024-06-03 16:39:24 - P@1: 0.9500\n",
            "2024-06-03 16:39:24 - P@3: 0.3333\n",
            "2024-06-03 16:39:24 - P@5: 0.2000\n",
            "2024-06-03 16:39:24 - P@10: 0.1000\n",
            "2024-06-03 16:39:24 - P@100: 0.0100\n",
            "2024-06-03 16:39:24 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_sharegpt4v_4_8_16_32_64_128_subset_20.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name sharegpt4v --data_path /content/drive/MyDrive/sharegpt4v_imgpaths_patch_2_4_20queries.pkl --query_count -1 --total_count 20 --dataset_path /content/drive/MyDrive/mscoco_120k.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Cr1fTB6y0_",
        "outputId": "28cf8048-eb40-4089-ee2d-389028e75ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:39:41.905367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:39:41.905402: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "20it [00:00, 246.85it/s]\n",
            "100% 20/20 [00:00<00:00, 1077.60it/s]\n",
            "closeness threshold:: 0.2\n",
            "Online clustering: 100% 3424/3424 [00:00<00:00, 5670.21it/s]\n",
            "Number of clusters: 156\n",
            "100% 156/156 [00:00<00:00, 1279.38it/s]\n",
            "100% 20/20 [00:03<00:00,  6.13it/s]\n",
            "2024-06-03 16:39:55 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:39:55 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "results with decomposition::\n",
            "2024-06-03 16:39:58 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:39:58 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:39:58 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:00<00:00, 25.14it/s]\n",
            "Time taken: 0.81s\n",
            "2024-06-03 16:39:58 - \n",
            "\n",
            "2024-06-03 16:39:58 - NDCG@1: 1.0000\n",
            "2024-06-03 16:39:58 - NDCG@3: 1.0000\n",
            "2024-06-03 16:39:58 - NDCG@5: 1.0000\n",
            "2024-06-03 16:39:58 - NDCG@10: 1.0000\n",
            "2024-06-03 16:39:58 - NDCG@100: 1.0000\n",
            "2024-06-03 16:39:58 - NDCG@1000: 1.0000\n",
            "2024-06-03 16:39:58 - \n",
            "\n",
            "2024-06-03 16:39:58 - MAP@1: 1.0000\n",
            "2024-06-03 16:39:58 - MAP@3: 1.0000\n",
            "2024-06-03 16:39:58 - MAP@5: 1.0000\n",
            "2024-06-03 16:39:58 - MAP@10: 1.0000\n",
            "2024-06-03 16:39:58 - MAP@100: 1.0000\n",
            "2024-06-03 16:39:58 - MAP@1000: 1.0000\n",
            "2024-06-03 16:39:58 - \n",
            "\n",
            "2024-06-03 16:39:58 - Recall@1: 1.0000\n",
            "2024-06-03 16:39:58 - Recall@3: 1.0000\n",
            "2024-06-03 16:39:58 - Recall@5: 1.0000\n",
            "2024-06-03 16:39:58 - Recall@10: 1.0000\n",
            "2024-06-03 16:39:58 - Recall@100: 1.0000\n",
            "2024-06-03 16:39:58 - Recall@1000: 1.0000\n",
            "2024-06-03 16:39:58 - \n",
            "\n",
            "2024-06-03 16:39:58 - P@1: 1.0000\n",
            "2024-06-03 16:39:58 - P@3: 0.3333\n",
            "2024-06-03 16:39:58 - P@5: 0.2000\n",
            "2024-06-03 16:39:58 - P@10: 0.1000\n",
            "2024-06-03 16:39:58 - P@100: 0.0100\n",
            "2024-06-03 16:39:58 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_sharegpt4v_4_8_16_32_64_128_subset_20_query_img_cluster.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name sharegpt4v --data_path /content/drive/MyDrive/sharegpt4v_imgpaths_patch_2_4_20queries.pkl --query_count -1 --total_count 20 --img_concept --query_concept --dataset_path /content/drive/MyDrive/mscoco_120k.pkl --search_by_cluster --closeness_threshold 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNztMkEA_xve",
        "outputId": "67a02895-2ec4-4dcc-8430-38e39dc62166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:47:12.810585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:47:12.810617: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "Loading cached patches\n",
            "4044c04745fcb7258b187ff44befb5aa1e0bcc5e420f0b76724340f0719d75fc\n",
            "20it [00:00, 254.69it/s]\n",
            "100% 20/20 [00:00<00:00, 904.14it/s]\n",
            "closeness threshold:: 0.2\n",
            "Online clustering: 100% 3424/3424 [00:00<00:00, 5065.06it/s]\n",
            "Number of clusters: 156\n",
            "100% 156/156 [00:00<00:00, 1441.93it/s]\n",
            "100% 20/20 [00:03<00:00,  5.98it/s]\n",
            "2024-06-03 16:47:26 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:47:26 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "results with decomposition::\n",
            "2024-06-03 16:47:28 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:47:28 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:47:28 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:00<00:00, 25.87it/s]\n",
            "Time taken: 0.79s\n",
            "2024-06-03 16:47:29 - \n",
            "\n",
            "2024-06-03 16:47:29 - NDCG@1: 1.0000\n",
            "2024-06-03 16:47:29 - NDCG@3: 1.0000\n",
            "2024-06-03 16:47:29 - NDCG@5: 1.0000\n",
            "2024-06-03 16:47:29 - NDCG@10: 1.0000\n",
            "2024-06-03 16:47:29 - NDCG@100: 1.0000\n",
            "2024-06-03 16:47:29 - NDCG@1000: 1.0000\n",
            "2024-06-03 16:47:29 - \n",
            "\n",
            "2024-06-03 16:47:29 - MAP@1: 1.0000\n",
            "2024-06-03 16:47:29 - MAP@3: 1.0000\n",
            "2024-06-03 16:47:29 - MAP@5: 1.0000\n",
            "2024-06-03 16:47:29 - MAP@10: 1.0000\n",
            "2024-06-03 16:47:29 - MAP@100: 1.0000\n",
            "2024-06-03 16:47:29 - MAP@1000: 1.0000\n",
            "2024-06-03 16:47:29 - \n",
            "\n",
            "2024-06-03 16:47:29 - Recall@1: 1.0000\n",
            "2024-06-03 16:47:29 - Recall@3: 1.0000\n",
            "2024-06-03 16:47:29 - Recall@5: 1.0000\n",
            "2024-06-03 16:47:29 - Recall@10: 1.0000\n",
            "2024-06-03 16:47:29 - Recall@100: 1.0000\n",
            "2024-06-03 16:47:29 - Recall@1000: 1.0000\n",
            "2024-06-03 16:47:29 - \n",
            "\n",
            "2024-06-03 16:47:29 - P@1: 1.0000\n",
            "2024-06-03 16:47:29 - P@3: 0.3333\n",
            "2024-06-03 16:47:29 - P@5: 0.2000\n",
            "2024-06-03 16:47:29 - P@10: 0.1000\n",
            "2024-06-03 16:47:29 - P@100: 0.0100\n",
            "2024-06-03 16:47:29 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_sharegpt4v_4_8_16_32_64_128_subset_20_query_img_cluster.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name sharegpt4v --data_path /content/drive/MyDrive/sharegpt4v_imgpaths_patch_2_4_20queries.pkl --query_count -1 --total_count 20 --img_concept --query_concept --dataset_path /content/drive/MyDrive/mscoco_40k_clustered.pkl --search_by_cluster --closeness_threshold 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCZiEQ5f53IX",
        "outputId": "5ddae023-0a79-4106-b0a2-7f0e897bfc5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:40:11.948101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:40:11.948133: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "20it [00:02,  9.99it/s]\n",
            "20it [03:34, 10.75s/it]\n",
            "100% 20/20 [00:00<00:00, 1060.01it/s]\n",
            "100% 20/20 [00:00<00:00, 20.24it/s]\n",
            "2024-06-03 16:44:20 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:44:20 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "results with decomposition::\n",
            "2024-06-03 16:44:23 - Encoding Queries...\n",
            "2024-06-03 16:44:23 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:44:23 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:44:23 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:00<00:00, 51.18it/s]\n",
            "Time taken: 0.39s\n",
            "2024-06-03 16:44:23 - \n",
            "\n",
            "2024-06-03 16:44:23 - NDCG@1: 1.0000\n",
            "2024-06-03 16:44:23 - NDCG@3: 1.0000\n",
            "2024-06-03 16:44:23 - NDCG@5: 1.0000\n",
            "2024-06-03 16:44:23 - NDCG@10: 1.0000\n",
            "2024-06-03 16:44:23 - NDCG@100: 1.0000\n",
            "2024-06-03 16:44:23 - NDCG@1000: 1.0000\n",
            "2024-06-03 16:44:23 - \n",
            "\n",
            "2024-06-03 16:44:23 - MAP@1: 1.0000\n",
            "2024-06-03 16:44:23 - MAP@3: 1.0000\n",
            "2024-06-03 16:44:23 - MAP@5: 1.0000\n",
            "2024-06-03 16:44:23 - MAP@10: 1.0000\n",
            "2024-06-03 16:44:23 - MAP@100: 1.0000\n",
            "2024-06-03 16:44:23 - MAP@1000: 1.0000\n",
            "2024-06-03 16:44:23 - \n",
            "\n",
            "2024-06-03 16:44:23 - Recall@1: 1.0000\n",
            "2024-06-03 16:44:23 - Recall@3: 1.0000\n",
            "2024-06-03 16:44:23 - Recall@5: 1.0000\n",
            "2024-06-03 16:44:23 - Recall@10: 1.0000\n",
            "2024-06-03 16:44:23 - Recall@100: 1.0000\n",
            "2024-06-03 16:44:23 - Recall@1000: 1.0000\n",
            "2024-06-03 16:44:23 - \n",
            "\n",
            "2024-06-03 16:44:23 - P@1: 1.0000\n",
            "2024-06-03 16:44:23 - P@3: 0.3333\n",
            "2024-06-03 16:44:23 - P@5: 0.2000\n",
            "2024-06-03 16:44:23 - P@10: 0.1000\n",
            "2024-06-03 16:44:23 - P@100: 0.0100\n",
            "2024-06-03 16:44:23 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_mscoco_4_8_16_32_64_128_subset_20_query_img.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name mscoco --data_path /content/drive/MyDrive/mscoco_imgpaths_longest_20queries.pkl --query_count -1 --total_count 20 --img_concept --query_concept --dataset_path /content/drive/MyDrive/mscoco_40k_clustered.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxPlCETk5-g2",
        "outputId": "d6921715-6374-4381-e084-f9718ce6545f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:44:27.791541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:44:27.791577: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "20it [00:00, 299.37it/s]\n",
            "2024-06-03 16:44:38 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:44:38 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "results with decomposition::\n",
            "2024-06-03 16:44:41 - Encoding Queries...\n",
            "2024-06-03 16:44:41 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:44:41 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:44:41 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:00<00:00, 148.67it/s]\n",
            "Time taken: 0.17s\n",
            "2024-06-03 16:44:41 - \n",
            "\n",
            "2024-06-03 16:44:41 - NDCG@1: 0.9500\n",
            "2024-06-03 16:44:41 - NDCG@3: 0.9816\n",
            "2024-06-03 16:44:41 - NDCG@5: 0.9816\n",
            "2024-06-03 16:44:41 - NDCG@10: 0.9816\n",
            "2024-06-03 16:44:41 - NDCG@100: 0.9816\n",
            "2024-06-03 16:44:41 - NDCG@1000: 0.9816\n",
            "2024-06-03 16:44:41 - \n",
            "\n",
            "2024-06-03 16:44:41 - MAP@1: 0.9500\n",
            "2024-06-03 16:44:41 - MAP@3: 0.9750\n",
            "2024-06-03 16:44:41 - MAP@5: 0.9750\n",
            "2024-06-03 16:44:41 - MAP@10: 0.9750\n",
            "2024-06-03 16:44:41 - MAP@100: 0.9750\n",
            "2024-06-03 16:44:41 - MAP@1000: 0.9750\n",
            "2024-06-03 16:44:41 - \n",
            "\n",
            "2024-06-03 16:44:41 - Recall@1: 0.9500\n",
            "2024-06-03 16:44:41 - Recall@3: 1.0000\n",
            "2024-06-03 16:44:41 - Recall@5: 1.0000\n",
            "2024-06-03 16:44:41 - Recall@10: 1.0000\n",
            "2024-06-03 16:44:41 - Recall@100: 1.0000\n",
            "2024-06-03 16:44:41 - Recall@1000: 1.0000\n",
            "2024-06-03 16:44:41 - \n",
            "\n",
            "2024-06-03 16:44:41 - P@1: 0.9500\n",
            "2024-06-03 16:44:41 - P@3: 0.3333\n",
            "2024-06-03 16:44:41 - P@5: 0.2000\n",
            "2024-06-03 16:44:41 - P@10: 0.1000\n",
            "2024-06-03 16:44:41 - P@100: 0.0100\n",
            "2024-06-03 16:44:41 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_mscoco_4_8_16_32_64_128_subset_20.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name mscoco --data_path /content/drive/MyDrive/mscoco_imgpaths_longest_20queries.pkl --query_count -1 --total_count 20 --dataset_path /content/drive/MyDrive/mscoco_40k_clustered.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-UmbL0M67qe",
        "outputId": "ab9ee5ac-eed3-453c-f700-ee7279d14ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-03 16:44:45.317107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-06-03 16:44:45.317138: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "Loading cached patches\n",
            "0d76f494e96e1e4afd38df52d193e9e46c352ea86205de371e08690f62b05c98\n",
            "20it [00:00, 305.33it/s]\n",
            "100% 20/20 [00:00<00:00, 1146.71it/s]\n",
            "closeness threshold:: 0.2\n",
            "Online clustering: 100% 3631/3631 [00:00<00:00, 5924.50it/s]\n",
            "Number of clusters: 204\n",
            "100% 204/204 [00:00<00:00, 1705.61it/s]\n",
            "100% 20/20 [00:01<00:00, 13.71it/s]\n",
            "2024-06-03 16:44:56 - Use pytorch device_name: cuda\n",
            "2024-06-03 16:44:56 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "results with decomposition::\n",
            "2024-06-03 16:44:59 - Sorting Corpus by document length (Longest first)...\n",
            "2024-06-03 16:44:59 - Encoding Corpus in batches... Warning: This might take a while!\n",
            "2024-06-03 16:44:59 - Scoring Function: Cosine Similarity (cos_sim)\n",
            "100% 20/20 [00:00<00:00, 40.64it/s]\n",
            "Time taken: 0.51s\n",
            "2024-06-03 16:44:59 - \n",
            "\n",
            "2024-06-03 16:44:59 - NDCG@1: 1.0000\n",
            "2024-06-03 16:44:59 - NDCG@3: 1.0000\n",
            "2024-06-03 16:44:59 - NDCG@5: 1.0000\n",
            "2024-06-03 16:44:59 - NDCG@10: 1.0000\n",
            "2024-06-03 16:44:59 - NDCG@100: 1.0000\n",
            "2024-06-03 16:44:59 - NDCG@1000: 1.0000\n",
            "2024-06-03 16:44:59 - \n",
            "\n",
            "2024-06-03 16:44:59 - MAP@1: 1.0000\n",
            "2024-06-03 16:44:59 - MAP@3: 1.0000\n",
            "2024-06-03 16:44:59 - MAP@5: 1.0000\n",
            "2024-06-03 16:44:59 - MAP@10: 1.0000\n",
            "2024-06-03 16:44:59 - MAP@100: 1.0000\n",
            "2024-06-03 16:44:59 - MAP@1000: 1.0000\n",
            "2024-06-03 16:44:59 - \n",
            "\n",
            "2024-06-03 16:44:59 - Recall@1: 1.0000\n",
            "2024-06-03 16:44:59 - Recall@3: 1.0000\n",
            "2024-06-03 16:44:59 - Recall@5: 1.0000\n",
            "2024-06-03 16:44:59 - Recall@10: 1.0000\n",
            "2024-06-03 16:44:59 - Recall@100: 1.0000\n",
            "2024-06-03 16:44:59 - Recall@1000: 1.0000\n",
            "2024-06-03 16:44:59 - \n",
            "\n",
            "2024-06-03 16:44:59 - P@1: 1.0000\n",
            "2024-06-03 16:44:59 - P@3: 0.3333\n",
            "2024-06-03 16:44:59 - P@5: 0.2000\n",
            "2024-06-03 16:44:59 - P@10: 0.1000\n",
            "2024-06-03 16:44:59 - P@100: 0.0100\n",
            "2024-06-03 16:44:59 - P@1000: 0.0010\n",
            "The results are stored at  output/saved_patches_mscoco_4_8_16_32_64_128_subset_20_query_img_cluster.pkl\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/concept_based_retrieval-main/main.py --dataset_name mscoco --data_path /content/drive/MyDrive/mscoco_imgpaths_longest_20queries.pkl --query_count -1 --total_count 20 --img_concept --query_concept --dataset_path /content/drive/MyDrive/mscoco_40k_clustered.pkl --search_by_cluster --closeness_threshold 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy_0INhN-Q7Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
