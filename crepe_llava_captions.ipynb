{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG7FXUrUXjXH",
        "outputId": "70d138bd-d455-4566-fd29-93b532ac5346"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "img_caption_file_name = '/content/drive/MyDrive/df_crepe_500_llava_captions.pkl'\n",
        "with open(img_caption_file_name, 'rb') as f:\n",
        "  caption_pd = pickle.load(f)"
      ],
      "metadata": {
        "id": "bo3KuerwrQOX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caption_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ISEIAfJHrTQ3",
        "outputId": "a1e4cce4-ec05-4178-feca-70f584d7c228"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id                                            caption   n  \\\n",
              "0           1  a car parked on a street next to a tree. the s...  11   \n",
              "1           5  computer and cables on a floor in a room with ...   9   \n",
              "2           6  a glass of water on a counter with an apple, a...  12   \n",
              "3           7  woman wearing a sweater with a wrist pad on he...  13   \n",
              "4           8  man with sleeves and a hand on a keyboard in f...  13   \n",
              "..        ...                                                ...  ..   \n",
              "495   2369764  a girl on a cell phone with a hat, holding a b...  12   \n",
              "496   2369881  photo of pants, another pants, a frisbee, and ...  14   \n",
              "497   2371219  pen, blue flowers, and almonds on a plate with...  11   \n",
              "498   2371708  gravel and stick by street, rooster in grass, ...  10   \n",
              "499       447  stad selling food, bags on step, child of step...  10   \n",
              "\n",
              "     n_objects  n_relations  n_attributes  n_connected_components  \\\n",
              "0            6            5             0                       1   \n",
              "1            5            4             0                       1   \n",
              "2            7            5             0                       2   \n",
              "3            7            5             1                       2   \n",
              "4            7            5             1                       2   \n",
              "..         ...          ...           ...                     ...   \n",
              "495          7            5             0                       2   \n",
              "496          7            5             2                       2   \n",
              "497          5            5             1                       1   \n",
              "498          6            4             0                       2   \n",
              "499          6            4             0                       2   \n",
              "\n",
              "                                             hard_negs      x      y  width  \\\n",
              "0    ['a car parked on a lamp post next to a tree. ...  249.0    0.0  550.0   \n",
              "1    ['computer and cables on a heater in a room wi...    0.0    2.0  795.0   \n",
              "2    ['a glass of water under a counter with an app...    0.0    0.0  799.0   \n",
              "3    ['woman wearing a sweater with a wrist pad on ...    2.0  255.0  390.0   \n",
              "4    ['man with sleeves and a hand next to a keyboa...    2.0   32.0  454.0   \n",
              "..                                                 ...    ...    ...    ...   \n",
              "495  ['a girl on a mirror with a hat, holding a bee...   59.0    0.0  261.0   \n",
              "496  ['photo of pants, another pants, a shoe, and a...    4.0    4.0  328.0   \n",
              "497  ['pen, blue pie, and almonds on a plate with a...    0.0   55.0  499.0   \n",
              "498  ['foot and stick by street, rooster in grass, ...    1.0    1.0  499.0   \n",
              "499  ['stad selling power lies, bags on step, child...  176.0   79.0  462.0   \n",
              "\n",
              "     height                                 caption_triples_ls     groups  \\\n",
              "0     516.0  a car parked on a street| a street next to a t...  0,1,2,3,4   \n",
              "1     597.0  computer on a floor| cables on a floor| a room...      0,1,2   \n",
              "2     531.0  a glass of water on a counter | an apple on a ...    0,1,2,3   \n",
              "3     341.0  woman wearing a sweater| a wrist pad on her ke...  0,1,2,3,4   \n",
              "4     566.0  man with sleeves on a keyboard| a hand on a ke...  0,1,2,3,4   \n",
              "..      ...                                                ...        ...   \n",
              "495   498.0  a girl on a cell phone| a girl with a hat| hol...    0,1,2,3   \n",
              "496   491.0  photo of pants| another pants| a frisbee| a br...  0,1,2,3,4   \n",
              "497   444.0   pen, blue flowers, almonds, and a pie on a plate          0   \n",
              "498   373.0  gravel by street| stick by street| rooster in ...    0,1,2,3   \n",
              "499   489.0  start selling food| bags on step| child of ste...  0,1,2 | 3   \n",
              "\n",
              "     elapsed_time                                      llava_caption  \\\n",
              "0        1.380812  (<PIL.Image.Image image mode=RGB size=800x600 ...   \n",
              "1        0.623626  (<PIL.Image.Image image mode=RGB size=800x600 ...   \n",
              "2        0.963344  (<PIL.Image.Image image mode=RGB size=800x600 ...   \n",
              "3        1.905799  (<PIL.Image.Image image mode=RGB size=800x600 ...   \n",
              "4        1.385885  (<PIL.Image.Image image mode=RGB size=800x600 ...   \n",
              "..            ...                                                ...   \n",
              "495      1.264356  (<PIL.Image.Image image mode=RGB size=375x500 ...   \n",
              "496      3.062753  (<PIL.Image.Image image mode=RGB size=333x500 ...   \n",
              "497      0.000009  (<PIL.Image.Image image mode=RGB size=500x500 ...   \n",
              "498      1.504835  (<PIL.Image.Image image mode=RGB size=500x375 ...   \n",
              "499      2.127802  (<PIL.Image.Image image mode=RGB size=800x600 ...   \n",
              "\n",
              "                                    llava_caption_text  \n",
              "0    The image depicts a city street scene. There a...  \n",
              "1    The image shows a small, cluttered room. The r...  \n",
              "2    The image shows a kitchen counter with various...  \n",
              "3    The image shows a person sitting at a desk in ...  \n",
              "4    The image shows a person sitting at a desk in ...  \n",
              "..                                                 ...  \n",
              "495  The image shows a person standing in a room. T...  \n",
              "496  The image depicts a lively scene of a group of...  \n",
              "497  The image shows a slice of cake on a white pla...  \n",
              "498  The image shows a single, large rooster standi...  \n",
              "499  The image depicts a bustling street scene in a...  \n",
              "\n",
              "[500 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-259a87cc-45e3-4fac-a528-6516c5ee9a09\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>caption</th>\n",
              "      <th>n</th>\n",
              "      <th>n_objects</th>\n",
              "      <th>n_relations</th>\n",
              "      <th>n_attributes</th>\n",
              "      <th>n_connected_components</th>\n",
              "      <th>hard_negs</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>caption_triples_ls</th>\n",
              "      <th>groups</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>llava_caption</th>\n",
              "      <th>llava_caption_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>a car parked on a street next to a tree. the s...</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['a car parked on a lamp post next to a tree. ...</td>\n",
              "      <td>249.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>516.0</td>\n",
              "      <td>a car parked on a street| a street next to a t...</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>1.380812</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=800x600 ...</td>\n",
              "      <td>The image depicts a city street scene. There a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>computer and cables on a floor in a room with ...</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['computer and cables on a heater in a room wi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>795.0</td>\n",
              "      <td>597.0</td>\n",
              "      <td>computer on a floor| cables on a floor| a room...</td>\n",
              "      <td>0,1,2</td>\n",
              "      <td>0.623626</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=800x600 ...</td>\n",
              "      <td>The image shows a small, cluttered room. The r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>a glass of water on a counter with an apple, a...</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['a glass of water under a counter with an app...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>799.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>a glass of water on a counter | an apple on a ...</td>\n",
              "      <td>0,1,2,3</td>\n",
              "      <td>0.963344</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=800x600 ...</td>\n",
              "      <td>The image shows a kitchen counter with various...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>woman wearing a sweater with a wrist pad on he...</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>['woman wearing a sweater with a wrist pad on ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>390.0</td>\n",
              "      <td>341.0</td>\n",
              "      <td>woman wearing a sweater| a wrist pad on her ke...</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>1.905799</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=800x600 ...</td>\n",
              "      <td>The image shows a person sitting at a desk in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>man with sleeves and a hand on a keyboard in f...</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>['man with sleeves and a hand next to a keyboa...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>man with sleeves on a keyboard| a hand on a ke...</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>1.385885</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=800x600 ...</td>\n",
              "      <td>The image shows a person sitting at a desk in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>2369764</td>\n",
              "      <td>a girl on a cell phone with a hat, holding a b...</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['a girl on a mirror with a hat, holding a bee...</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>a girl on a cell phone| a girl with a hat| hol...</td>\n",
              "      <td>0,1,2,3</td>\n",
              "      <td>1.264356</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=375x500 ...</td>\n",
              "      <td>The image shows a person standing in a room. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>2369881</td>\n",
              "      <td>photo of pants, another pants, a frisbee, and ...</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['photo of pants, another pants, a shoe, and a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>491.0</td>\n",
              "      <td>photo of pants| another pants| a frisbee| a br...</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>3.062753</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=333x500 ...</td>\n",
              "      <td>The image depicts a lively scene of a group of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>2371219</td>\n",
              "      <td>pen, blue flowers, and almonds on a plate with...</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['pen, blue pie, and almonds on a plate with a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>444.0</td>\n",
              "      <td>pen, blue flowers, almonds, and a pie on a plate</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=500x500 ...</td>\n",
              "      <td>The image shows a slice of cake on a white pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>2371708</td>\n",
              "      <td>gravel and stick by street, rooster in grass, ...</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['foot and stick by street, rooster in grass, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>gravel by street| stick by street| rooster in ...</td>\n",
              "      <td>0,1,2,3</td>\n",
              "      <td>1.504835</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=500x375 ...</td>\n",
              "      <td>The image shows a single, large rooster standi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>447</td>\n",
              "      <td>stad selling food, bags on step, child of step...</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['stad selling power lies, bags on step, child...</td>\n",
              "      <td>176.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>489.0</td>\n",
              "      <td>start selling food| bags on step| child of ste...</td>\n",
              "      <td>0,1,2 | 3</td>\n",
              "      <td>2.127802</td>\n",
              "      <td>(&lt;PIL.Image.Image image mode=RGB size=800x600 ...</td>\n",
              "      <td>The image depicts a bustling street scene in a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-259a87cc-45e3-4fac-a528-6516c5ee9a09')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-259a87cc-45e3-4fac-a528-6516c5ee9a09 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-259a87cc-45e3-4fac-a528-6516c5ee9a09');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15d94f91-dc0f-4d63-81f9-83d1d1c2cd34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15d94f91-dc0f-4d63-81f9-83d1d1c2cd34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15d94f91-dc0f-4d63-81f9-83d1d1c2cd34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5d4694de-46c7-4003-8b17-596271736a07\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('caption_pd')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5d4694de-46c7-4003-8b17-596271736a07 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('caption_pd');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "caption_pd",
              "summary": "{\n  \"name\": \"caption_pd\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1159631,\n        \"min\": 1,\n        \"max\": 2371708,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          2360526,\n          538,\n          2360832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"photo of statues, another statues, and another statues, with an angel next to a circle\",\n          \"books and bookcases with plants. the books are inside the bookcases and the plant has a leaf.\",\n          \"man on a beach wearing shorts with a string, and there is water and sand behind him\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 4,\n        \"max\": 20,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          6,\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_objects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          3,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_relations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_attributes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_connected_components\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_negs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"['photo of circle, another statues, and another statues, with an angel next to a statues', 'circle of statues, another statues, and another statues, with an angel next to a photo', 'angel of statues, another statues, and another statues, with an photo next to a circle', 'photo of angel, another angel, and another angel, with an statues next to a circle', 'statues of photo, another statues, and another statues, with an angel next to a circle']\",\n          \"['books and leafs with plants. the books are inside the bookcases and the plant has a bookcase.', 'books and plants with bookcases. the books are inside the plants and the bookcase has a leaf.', 'plant and bookcases with bookss. the plant are inside the bookcases and the books has a leaf.', 'bookcase and bookss with plants. the bookcase are inside the bookss and the plant has a leaf.', 'leaf and bookcases with plants. the books are inside the bookcases and the plant has a books.']\",\n          \"['sand on a beach wearing shorts with a string, and there is water and man behind him', 'shorts on a beach wearing man with a string, and there is water and sand behind him', 'man on a beach wearing water with a string, and there is shorts and sand behind him', 'water on a beach wearing shorts with a string, and there is man and sand behind him', 'man on a beach wearing sand with a string, and there is water and shorts behind him']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91.3124653739309,\n        \"min\": 0.0,\n        \"max\": 554.0,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          150.0,\n          265.0,\n          88.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67.92287551360052,\n        \"min\": 0.0,\n        \"max\": 439.0,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          155.0,\n          164.0,\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151.14538112847822,\n        \"min\": 148.0,\n        \"max\": 800.0,\n        \"num_unique_values\": 270,\n        \"samples\": [\n          797.0,\n          443.0,\n          712.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115.6246029251699,\n        \"min\": 160.0,\n        \"max\": 799.0,\n        \"num_unique_values\": 258,\n        \"samples\": [\n          659.0,\n          478.0,\n          599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_triples_ls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"photo of statues| another statues| another statues| an angel next to a circle\",\n          \"books| bookcases with plants| the books are inside the bookcases| the plants have leaves.\",\n          \"man on a beach| wearing shorts with a string| water behind him| sand behind him| sand and water behind him\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groups\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"0,1,2,3,4,5,6\",\n          \"0,1,2,3,4,5,6,7\",\n          \"0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elapsed_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.623477145696317,\n        \"min\": 8.821487426757812e-06,\n        \"max\": 192.671621799469,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          1.4647846221923828,\n          1.1153085231781006,\n          6.2073469161987305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llava_caption\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llava_caption_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"The image shows a large, ornate clock tower. The clock face is prominently displayed, with the hands indicating a specific time.\\nThe clock tower appears to be part of a larger building, as suggested by the presence of other architectural elements.\\nThe image is taken from a low angle, which emphasizes the height and grandeur of the clock tower.\\nThere are no visible texts or inscriptions in the image. The style of the image is a realistic photograph, capturing the scene with clarity and detail. \",\n          \"The image depicts a well-organized home office. The room features a desk with a computer monitor, keyboard, and mouse. The desk is positioned in front of a large window, which allows natural light to fill the room.\\nTo the right of the desk, there is a bookshelf filled with various books and decorative items. The bookshelf is made of wood and has a classic design.\\nIn the foreground of the image, there is a comfortable-looking couch with a blue blanket on it. The couch is positioned in front of the desk and bookshelf, creating a cozy and inviting home office environment. \",\n          \"The image shows a beach scene with two individuals. The person on the left is standing on the sandy beach, wearing a blue and white swimsuit. This person appears to be throwing an object, possibly a frisbee, towards the other person.\\nThe person on the right is standing on the sandy beach, wearing a blue swimsuit. This person appears to be waiting to catch the object being thrown by the person on the left.\\nThe background of the image shows a clear blue sky, suggesting a sunny day. The sandy beach appears to be relatively calm, with no visible waves or currents. The overall atmosphere of the image is one of leisure and enjoyment of a sunny day at the beach. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELZBzL6trT-A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}